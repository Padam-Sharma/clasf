{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "a826df3573774c08bfc8f4be58f45f03": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_effa28d55ca344e3ab10a312f691a8ef",
       "IPY_MODEL_f1429363a8924509831420fd480d69dc",
       "IPY_MODEL_bfd83fe3e1ee41878b3d0491743e4222"
      ],
      "layout": "IPY_MODEL_36e7bff09cb8497f8f4551d7af390667"
     }
    },
    "effa28d55ca344e3ab10a312f691a8ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c4e9da91de16440cbac798439b27e441",
      "placeholder": "​",
      "style": "IPY_MODEL_cd231bcf8354456cb53dbcf59ebd0aa3",
      "value": "100%"
     }
    },
    "f1429363a8924509831420fd480d69dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac872c036ff345f986a9b3f927c46cc9",
      "max": 2314,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_413d74215c234eb6a0c42fba1b010b26",
      "value": 2314
     }
    },
    "bfd83fe3e1ee41878b3d0491743e4222": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a9bf9612ebc04302983730c24b444faf",
      "placeholder": "​",
      "style": "IPY_MODEL_dad49d4260e447a7a9ba2d2dd95020a1",
      "value": " 2314/2314 [00:05&lt;00:00, 782.66it/s]"
     }
    },
    "36e7bff09cb8497f8f4551d7af390667": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4e9da91de16440cbac798439b27e441": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd231bcf8354456cb53dbcf59ebd0aa3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ac872c036ff345f986a9b3f927c46cc9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "413d74215c234eb6a0c42fba1b010b26": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a9bf9612ebc04302983730c24b444faf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dad49d4260e447a7a9ba2d2dd95020a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7563f1c7c6104000991f4812cf47e1a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_11ca7ddf0a774ba2b01fb3c33a55fedf",
       "IPY_MODEL_354f4daecce0417e9fd64c7999228390",
       "IPY_MODEL_6d0222547f0f43f189d6e237c3a1fe5b"
      ],
      "layout": "IPY_MODEL_1acb8b84e0f54f689648272b9c131370"
     }
    },
    "11ca7ddf0a774ba2b01fb3c33a55fedf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65b4d594a5864659b671fe011afd6294",
      "placeholder": "​",
      "style": "IPY_MODEL_67ff48d8bf744bf4be8a42a8da4960c4",
      "value": "100%"
     }
    },
    "354f4daecce0417e9fd64c7999228390": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_87d88a8c8082489da1acfb3ca475a42f",
      "max": 2217,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e3beba975f5746109b7774618390d9bf",
      "value": 2217
     }
    },
    "6d0222547f0f43f189d6e237c3a1fe5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4cb81be94b8341f48d5c49e118b72101",
      "placeholder": "​",
      "style": "IPY_MODEL_4ff638d364824a10ac358bf81567125f",
      "value": " 2217/2217 [00:02&lt;00:00, 690.57it/s]"
     }
    },
    "1acb8b84e0f54f689648272b9c131370": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65b4d594a5864659b671fe011afd6294": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67ff48d8bf744bf4be8a42a8da4960c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "87d88a8c8082489da1acfb3ca475a42f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3beba975f5746109b7774618390d9bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4cb81be94b8341f48d5c49e118b72101": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ff638d364824a10ac358bf81567125f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "924f6cb774e344e7aab933ef4cee9556": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_589b38974e8f4ea2b1c038c1beb01e27",
       "IPY_MODEL_1d4f7d1d2ebd41efbc74757d6b905aa6",
       "IPY_MODEL_1e05dc29fec84523814d60b18e363b06"
      ],
      "layout": "IPY_MODEL_74aba6e2a9ef4387bb58427c88133f11"
     }
    },
    "589b38974e8f4ea2b1c038c1beb01e27": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14ad2a11d1864dbc8bc9265c4ecb9143",
      "placeholder": "​",
      "style": "IPY_MODEL_cab6384de7f44e2382015133a2352595",
      "value": "100%"
     }
    },
    "1d4f7d1d2ebd41efbc74757d6b905aa6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c697b2cfd8341ab8941f2300e12dcf0",
      "max": 634,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f9638f3adac04d2c973a2a3574a747b1",
      "value": 634
     }
    },
    "1e05dc29fec84523814d60b18e363b06": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cba23d4291284004ba5b3d4029cf55c9",
      "placeholder": "​",
      "style": "IPY_MODEL_1e4c61012cd144c2bf2334f03472e577",
      "value": " 634/634 [00:00&lt;00:00, 683.80it/s]"
     }
    },
    "74aba6e2a9ef4387bb58427c88133f11": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14ad2a11d1864dbc8bc9265c4ecb9143": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cab6384de7f44e2382015133a2352595": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4c697b2cfd8341ab8941f2300e12dcf0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9638f3adac04d2c973a2a3574a747b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cba23d4291284004ba5b3d4029cf55c9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e4c61012cd144c2bf2334f03472e577": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "88069c4ca1944110a3a9f5f0fea913c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_963583e6ced7446193ade6fb76d94a83",
       "IPY_MODEL_b0bb9dd148f14d948403557f10316ffc",
       "IPY_MODEL_6af1bf93081447cda63e1cbe845bd6ad"
      ],
      "layout": "IPY_MODEL_93fd4ed08fe24c5d97635b9051b9ca9b"
     }
    },
    "963583e6ced7446193ade6fb76d94a83": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_107979947aca4fdf9269114224d798b3",
      "placeholder": "​",
      "style": "IPY_MODEL_4ee857f56a084cb89c14db52376cedd3",
      "value": "100%"
     }
    },
    "b0bb9dd148f14d948403557f10316ffc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d5c38cf6c95481d98ddf00f52421b64",
      "max": 317,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8b2b3178784b4981877462c42f63a764",
      "value": 317
     }
    },
    "6af1bf93081447cda63e1cbe845bd6ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a91f2c8b7e264c3fae3d915a8559432e",
      "placeholder": "​",
      "style": "IPY_MODEL_d561d13b7af4441f9614e60ef5fc1277",
      "value": " 317/317 [00:00&lt;00:00, 672.25it/s]"
     }
    },
    "93fd4ed08fe24c5d97635b9051b9ca9b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "107979947aca4fdf9269114224d798b3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ee857f56a084cb89c14db52376cedd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2d5c38cf6c95481d98ddf00f52421b64": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b2b3178784b4981877462c42f63a764": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a91f2c8b7e264c3fae3d915a8559432e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d561d13b7af4441f9614e60ef5fc1277": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2e389c411eb944df93cee2d5384f4903": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2b0ba81a6f6c4c6c87eb96581fb0d77a",
       "IPY_MODEL_5efc679a14ab4fddb628988bf33d4cd5",
       "IPY_MODEL_fd5325290ef04823b59077c28ca78cdc"
      ],
      "layout": "IPY_MODEL_5b7bd5f4ef60414cb7f1bf177fb9a231"
     }
    },
    "2b0ba81a6f6c4c6c87eb96581fb0d77a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4267efb97fa2443080bc9873b90ce30d",
      "placeholder": "​",
      "style": "IPY_MODEL_3dfdda29eca943b5a28f330636703ffa",
      "value": "100%"
     }
    },
    "5efc679a14ab4fddb628988bf33d4cd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef66922bf46346cd9e042a023be6e13d",
      "max": 334,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_88835753a67f4da5bdee08fe38a66591",
      "value": 334
     }
    },
    "fd5325290ef04823b59077c28ca78cdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d4d4a4ee69b148f691f608ca6e8871df",
      "placeholder": "​",
      "style": "IPY_MODEL_9aa6936c53ff499d9406d0cf15ce5696",
      "value": " 334/334 [01:23&lt;00:00,  4.62it/s]"
     }
    },
    "5b7bd5f4ef60414cb7f1bf177fb9a231": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4267efb97fa2443080bc9873b90ce30d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3dfdda29eca943b5a28f330636703ffa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef66922bf46346cd9e042a023be6e13d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88835753a67f4da5bdee08fe38a66591": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d4d4a4ee69b148f691f608ca6e8871df": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9aa6936c53ff499d9406d0cf15ce5696": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9f5608aae68d43219d6a1329d591673b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fd62410c1d274177979c6c9e60521426",
       "IPY_MODEL_146834835352472b817d54aaf82fe755",
       "IPY_MODEL_8e1126593cf3442e86207585fe443680"
      ],
      "layout": "IPY_MODEL_c9806a4939bb411e9957613d7be373bf"
     }
    },
    "fd62410c1d274177979c6c9e60521426": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_420ea132c57748008bf7d5fb7e4eb1fe",
      "placeholder": "​",
      "style": "IPY_MODEL_325c23b89f68417f8f83938262d276e2",
      "value": "100%"
     }
    },
    "146834835352472b817d54aaf82fe755": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e1a9960618a94ddd8b3dee2586131914",
      "max": 628,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2b2b2bd7b0744b0eada907ce7522fb6c",
      "value": 628
     }
    },
    "8e1126593cf3442e86207585fe443680": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82fe47c2c0c246588202fc4c12ccab71",
      "placeholder": "​",
      "style": "IPY_MODEL_b14b25d194d94599a9ec166baa8e4fe3",
      "value": " 628/628 [02:36&lt;00:00,  3.57it/s]"
     }
    },
    "c9806a4939bb411e9957613d7be373bf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "420ea132c57748008bf7d5fb7e4eb1fe": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "325c23b89f68417f8f83938262d276e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e1a9960618a94ddd8b3dee2586131914": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b2b2bd7b0744b0eada907ce7522fb6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "82fe47c2c0c246588202fc4c12ccab71": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b14b25d194d94599a9ec166baa8e4fe3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u9KRIvtFmLZ1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!cp '/content/drive/MyDrive/corrected data.csv' '/content'\n",
    "!cp -r '/content/drive/MyDrive/property classf data' '/content'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/corrected data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(len(set(list(df['oid']))), len(list(df['oid'])))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zjyDrjdumkUG",
    "outputId": "18791388-7d1a-4798-c96b-d21c8621ebee",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2254 2314\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "(list(df['Duplicate'])).count(2)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K0TuZnMHsFNP",
    "outputId": "1d41a7e4-4f20-467b-999e-32b974d858f1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def mdir(path):\n",
    "  os.makedirs(path, exist_ok = True)\n",
    "def rmdir(path):\n",
    "  shutil.rmtree(path)"
   ],
   "metadata": {
    "id": "kveURtaAsfXS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Move all images from train, val, test to single folder with classes"
   ],
   "metadata": {
    "id": "mdEZwqjVgfAs",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# rmdir('images')\n",
    "mdir('all_images')\n",
    "mdir('images')\n",
    "mdir('images/com')\n",
    "mdir('images/hoa')\n",
    "mdir('images/res')\n",
    "# rmdir('images')"
   ],
   "metadata": {
    "id": "PXJgkLcXsdri",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_pth = glob('/content/property classf data/test/*/*')\n",
    "train_pth = glob('/content/property classf data/train/*/*')\n",
    "val_pth = glob('/content/property classf data/val/*/*')\n",
    "\n",
    "print(len(test_pth) + len(train_pth) + len(val_pth))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oqx_ES0UtLut",
    "outputId": "39a76b4b-9bc2-40e3-954a-90d181a0cf33",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2314\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "all_pth = test_pth + train_pth + val_pth\n",
    "for i in tqdm(all_pth):\n",
    "  src = i\n",
    "  dst = '/content/all_images/'+i.split('/')[-1]\n",
    "  shutil.copy(src, dst)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "a826df3573774c08bfc8f4be58f45f03",
      "effa28d55ca344e3ab10a312f691a8ef",
      "f1429363a8924509831420fd480d69dc",
      "bfd83fe3e1ee41878b3d0491743e4222",
      "36e7bff09cb8497f8f4551d7af390667",
      "c4e9da91de16440cbac798439b27e441",
      "cd231bcf8354456cb53dbcf59ebd0aa3",
      "ac872c036ff345f986a9b3f927c46cc9",
      "413d74215c234eb6a0c42fba1b010b26",
      "a9bf9612ebc04302983730c24b444faf",
      "dad49d4260e447a7a9ba2d2dd95020a1"
     ]
    },
    "id": "XEJQF2xEyWx9",
    "outputId": "f58ea35c-0915-4b17-ab77-8625836acb19",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/2314 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a826df3573774c08bfc8f4be58f45f03"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(len(glob('/content/all_images/*')))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tkov7kluyvCY",
    "outputId": "e8ca70f1-cbff-4080-c7af-79cc5acef7e0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2254\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dups = []\n",
    "cls_map = {'Comm':'com', 'HOA':'hoa', 'Resi':'res'}\n",
    "for i in df.iterrows():\n",
    "  oid = i[1]['oid']\n",
    "  dup = i[1]['Duplicate']\n",
    "  cls = i[1]['correct_class']\n",
    "  if(oid not in dups):\n",
    "    dups.append(oid)\n",
    "    src = '/content/all_images/'+oid+'.png'\n",
    "    dst = '/content/images/'+cls_map[cls]+'/'+oid+'.png'\n",
    "    shutil.copy(src, dst)\n",
    "  else:\n",
    "    pass"
   ],
   "metadata": {
    "id": "A1CIiaBBzpbp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(len(glob('/content/images/*/*')))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iOsChVsNztvX",
    "outputId": "e1b32594-1ae0-4ef5-a0d0-afd0597d23c7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2254\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Correcting class labels for Feb month"
   ],
   "metadata": {
    "id": "SHrUQ1SlgsOZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!cp -r '/content/drive/MyDrive/property classf data/additional data for feb month/png_clipped' '/content'"
   ],
   "metadata": {
    "id": "QMgRcGMU076Q",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!cp '/content/drive/MyDrive/property classf data/additional data for feb month/Classification activity_2 - Sheet1.csv' '/content'"
   ],
   "metadata": {
    "id": "sIB-2oSE1w_l",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "feb_df = pd.read_csv('/content/Classification activity_2 - Sheet1.csv')"
   ],
   "metadata": {
    "id": "49Pnv2PM12YW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "feb_df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "VUEXWZbJ18SH",
    "outputId": "38eca9d9-8f66-4d59-c0eb-3ae809901d23",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     S.No                       oid      actual class/es correct class Remarks\n",
       "0       1  63d440516407576a1d098f61              ['HoA']           HOA     NaN\n",
       "1       2  63d484706407576a1d098f73  ['Industrial unit']          COMM     NaN\n",
       "2       3  63d4ede46ba37bea43f6f359              ['HoA']           HOA     NaN\n",
       "3       4  63d51a756407576a1d0990f1              ['HoA']           HOA     NaN\n",
       "4       5  63d5217e6407576a1d0990ff              ['HoA']           HOA     NaN\n",
       "..    ...                       ...                  ...           ...     ...\n",
       "910   911  64001e8e74e20d4f7b5cd0ef      ['Residential']           RES     NaN\n",
       "911   912  64002310b6e513fcbfe80a53              ['HoA']           HOA     NaN\n",
       "912   913  6400322842a6ea491be1a7dc              ['HoA']           HOA     NaN\n",
       "913   914  64003269b6e513fcbfe80a55           ['Office']          COMM     NaN\n",
       "914   915  640032d374e20d4f7b5cd113              ['HoA']           HOA     NaN\n",
       "\n",
       "[915 rows x 5 columns]"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-7afe4d9c-c0f3-4442-8e3e-bf45383aef72\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>oid</th>\n",
       "      <th>actual class/es</th>\n",
       "      <th>correct class</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>63d440516407576a1d098f61</td>\n",
       "      <td>['HoA']</td>\n",
       "      <td>HOA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>63d484706407576a1d098f73</td>\n",
       "      <td>['Industrial unit']</td>\n",
       "      <td>COMM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>63d4ede46ba37bea43f6f359</td>\n",
       "      <td>['HoA']</td>\n",
       "      <td>HOA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>63d51a756407576a1d0990f1</td>\n",
       "      <td>['HoA']</td>\n",
       "      <td>HOA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>63d5217e6407576a1d0990ff</td>\n",
       "      <td>['HoA']</td>\n",
       "      <td>HOA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>911</td>\n",
       "      <td>64001e8e74e20d4f7b5cd0ef</td>\n",
       "      <td>['Residential']</td>\n",
       "      <td>RES</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>912</td>\n",
       "      <td>64002310b6e513fcbfe80a53</td>\n",
       "      <td>['HoA']</td>\n",
       "      <td>HOA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>913</td>\n",
       "      <td>6400322842a6ea491be1a7dc</td>\n",
       "      <td>['HoA']</td>\n",
       "      <td>HOA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>914</td>\n",
       "      <td>64003269b6e513fcbfe80a55</td>\n",
       "      <td>['Office']</td>\n",
       "      <td>COMM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>915</td>\n",
       "      <td>640032d374e20d4f7b5cd113</td>\n",
       "      <td>['HoA']</td>\n",
       "      <td>HOA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>915 rows × 5 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7afe4d9c-c0f3-4442-8e3e-bf45383aef72')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-7afe4d9c-c0f3-4442-8e3e-bf45383aef72 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-7afe4d9c-c0f3-4442-8e3e-bf45383aef72');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dups = []\n",
    "cls_map = {'COMM':'com', 'HOA':'hoa', 'RES':'res'}\n",
    "for i in feb_df.iterrows():\n",
    "  oid = i[1]['oid']\n",
    "  cls = i[1]['correct class']\n",
    "  if(oid not in dups):\n",
    "    dups.append(oid)\n",
    "    src = '/content/png_clipped/'+oid+'.png'\n",
    "    dst = '/content/images/'+cls_map[cls]+'/'+oid+'.png'\n",
    "    shutil.copy(src, dst)\n",
    "  else:\n",
    "    pass"
   ],
   "metadata": {
    "id": "An2btAaR19lM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(len(glob('/content/images/*/*')))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fsi3KOIx2XBa",
    "outputId": "0c929531-0d71-44ce-b3ab-0d56f76c4190",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3168\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "for i in glob('/content/images/*'):\n",
    "  print(i.split('/')[-1], len(glob(i+'/*')))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iZpw2KT02YyS",
    "outputId": "d402b978-adcf-463a-f7cf-6e6d22729dd5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "res 470\n",
      "hoa 899\n",
      "com 1799\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "pth = glob('/content/images/*/*')"
   ],
   "metadata": {
    "id": "hFFj1p0c3E3R",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "random.shuffle(pth)"
   ],
   "metadata": {
    "id": "4waJWHhY3pc4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Splitting data into train, val and test with 70:20:10 split"
   ],
   "metadata": {
    "id": "wwNrzFQUhCm8",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "total_len = len(pth)\n",
    "train_len = int(total_len*0.7)\n",
    "rem_len = total_len - train_len\n",
    "val_len = int(rem_len*2.0/3.0)\n",
    "test_len = int(rem_len/3)\n",
    "\n",
    "print(100*train_len/total_len, 100*val_len/total_len, 100*test_len/total_len)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a_vNc4yQ3yI9",
    "outputId": "32f7ae7d-b09a-4461-9fd8-5693d5f4f1ff",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "69.98106060606061 20.012626262626263 10.006313131313131\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "mdir('train')\n",
    "mdir('train/com')\n",
    "mdir('train/hoa')\n",
    "mdir('train/res')\n",
    "\n",
    "mdir('test')\n",
    "mdir('test/com')\n",
    "mdir('test/hoa')\n",
    "mdir('test/res')\n",
    "\n",
    "mdir('val')\n",
    "mdir('val/com')\n",
    "mdir('val/hoa')\n",
    "mdir('val/res')"
   ],
   "metadata": {
    "id": "STvOQ2vz5ES8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_pth = pth[0:train_len]\n",
    "val_pth = pth[train_len:train_len+val_len]\n",
    "test_pth = pth[train_len+val_len:]"
   ],
   "metadata": {
    "id": "aA6fXTZL0gPq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "len(train_pth)+len(val_pth)+len(test_pth)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tMfJyuwR4uGW",
    "outputId": "923d9327-ead3-4e14-ffbc-cb0b89876793",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3168"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Move to train, test and val folders"
   ],
   "metadata": {
    "id": "uiyflQyhhN24",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def movettv(pth, type):\n",
    "  for i in tqdm(pth):\n",
    "    cls = i.split('/')[-2]\n",
    "    img = i.split('/')[-1]\n",
    "    src = i\n",
    "    dst = '/content/'+type+'/'+cls+'/'+img\n",
    "    shutil.copy(src, dst)"
   ],
   "metadata": {
    "id": "P1E4SZlP5aWZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "movettv(train_pth, 'train')\n",
    "movettv(val_pth, 'val')\n",
    "movettv(test_pth, 'test')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "7563f1c7c6104000991f4812cf47e1a0",
      "11ca7ddf0a774ba2b01fb3c33a55fedf",
      "354f4daecce0417e9fd64c7999228390",
      "6d0222547f0f43f189d6e237c3a1fe5b",
      "1acb8b84e0f54f689648272b9c131370",
      "65b4d594a5864659b671fe011afd6294",
      "67ff48d8bf744bf4be8a42a8da4960c4",
      "87d88a8c8082489da1acfb3ca475a42f",
      "e3beba975f5746109b7774618390d9bf",
      "4cb81be94b8341f48d5c49e118b72101",
      "4ff638d364824a10ac358bf81567125f",
      "924f6cb774e344e7aab933ef4cee9556",
      "589b38974e8f4ea2b1c038c1beb01e27",
      "1d4f7d1d2ebd41efbc74757d6b905aa6",
      "1e05dc29fec84523814d60b18e363b06",
      "74aba6e2a9ef4387bb58427c88133f11",
      "14ad2a11d1864dbc8bc9265c4ecb9143",
      "cab6384de7f44e2382015133a2352595",
      "4c697b2cfd8341ab8941f2300e12dcf0",
      "f9638f3adac04d2c973a2a3574a747b1",
      "cba23d4291284004ba5b3d4029cf55c9",
      "1e4c61012cd144c2bf2334f03472e577",
      "88069c4ca1944110a3a9f5f0fea913c6",
      "963583e6ced7446193ade6fb76d94a83",
      "b0bb9dd148f14d948403557f10316ffc",
      "6af1bf93081447cda63e1cbe845bd6ad",
      "93fd4ed08fe24c5d97635b9051b9ca9b",
      "107979947aca4fdf9269114224d798b3",
      "4ee857f56a084cb89c14db52376cedd3",
      "2d5c38cf6c95481d98ddf00f52421b64",
      "8b2b3178784b4981877462c42f63a764",
      "a91f2c8b7e264c3fae3d915a8559432e",
      "d561d13b7af4441f9614e60ef5fc1277"
     ]
    },
    "id": "WU7dZztO6UqB",
    "outputId": "fd8f0650-0246-447e-f0c5-29c24fb0259a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/2217 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7563f1c7c6104000991f4812cf47e1a0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/634 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "924f6cb774e344e7aab933ef4cee9556"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/317 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "88069c4ca1944110a3a9f5f0fea913c6"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Applying augmentations"
   ],
   "metadata": {
    "id": "1-w0hmSxAH4a",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "total_data = glob('/content/train/*/*')"
   ],
   "metadata": {
    "id": "JBJrxclCAHhS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!rm -r train_aug\n",
    "!mkdir train_aug\n",
    "!mkdir train_aug/res\n",
    "!mkdir train_aug/com\n",
    "!mkdir train_aug/hoa"
   ],
   "metadata": {
    "id": "fJaLKXM_ANyH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i in total_data:\n",
    "  src = i\n",
    "  cls = i.split('/')[-2]\n",
    "  img = i.split('/')[-1]\n",
    "  dst = '/content/train_aug/' + cls + '/' + img\n",
    "  shutil.copy(src, dst)"
   ],
   "metadata": {
    "id": "d7ieYUDOAT2W",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ],
   "metadata": {
    "id": "cy_AFD-iAXv0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "Resize_Transformation = transforms.Compose([\n",
    "   transforms.ToPILImage(), # the transform usually work with PIL images\n",
    "   transforms.Resize(size=(512, 512)),\n",
    "])\n",
    "Horizontal_Flipping_Transformation = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(p=1) \n",
    "])\n",
    "Vertical_Flipping_Transformation = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomVerticalFlip(p=1) \n",
    "])\n",
    "Color_Transformation = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ColorJitter(brightness=(0.1,0.6), contrast=1,saturation=0, hue=0.4)\n",
    "])\n",
    "Contrast_Transformation = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomAutocontrast(p=1)\n",
    "])\n",
    "Rotate_Transformation = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomRotation(degrees=66)\n",
    "])"
   ],
   "metadata": {
    "id": "r38lhFjtAcB8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def prob():\n",
    "  return random.choice([0, 1, 2])\n",
    "def augment(img_pth):\n",
    "  img = Image.open(img_pth)\n",
    "  # display(img)\n",
    "  img = np.array(img)\n",
    "  # save_pth = img_pth.replace('clswise', 'clswise_aug')\n",
    "  save_pth = img_pth\n",
    "  save_pth = save_pth[:-4]+'_'+'.png'\n",
    "  x=0\n",
    "  if(prob()):\n",
    "    aug_img = Resize_Transformation(img)\n",
    "    save_pth = save_pth.split('.')[0]+str(x)+'.png'\n",
    "    x+=1\n",
    "    aug_img.save(save_pth)\n",
    "    # display(aug_img)\n",
    "  if(prob()):\n",
    "    aug_img = Horizontal_Flipping_Transformation(img)\n",
    "    save_pth = save_pth.split('.')[0]+str(x)+'.png'\n",
    "    x+=1\n",
    "    aug_img.save(save_pth)\n",
    "    # display(aug_img)\n",
    "  if(prob()):\n",
    "    aug_img = Vertical_Flipping_Transformation(img)\n",
    "    save_pth = save_pth.split('.')[0]+str(x)+'.png'\n",
    "    x+=1\n",
    "    aug_img.save(save_pth)\n",
    "    # display(aug_img)\n",
    "  if(prob()):\n",
    "    aug_img = Color_Transformation(img)\n",
    "    save_pth = save_pth.split('.')[0]+str(x)+'.png'\n",
    "    x+=1\n",
    "    aug_img.save(save_pth)\n",
    "    # display(aug_img)\n",
    "  if(prob()):\n",
    "    aug_img = Rotate_Transformation(img)\n",
    "    save_pth = save_pth.split('.')[0]+str(x)+'.png'\n",
    "    x+=1\n",
    "    aug_img.save(save_pth)\n",
    "    # display(aug_img)\n",
    "  if(prob()):\n",
    "    aug_img = Contrast_Transformation(img)\n",
    "    save_pth = save_pth.split('.')[0]+str(x)+'.png'\n",
    "    x+=1\n",
    "    aug_img.save(save_pth)\n",
    "    # display(aug_img)"
   ],
   "metadata": {
    "id": "psgJaT_mAcAj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_len_aug(type):\n",
    "  print(len(glob('/content/train_aug/'+type+'/*')))\n",
    "\n",
    "def get_len(type):\n",
    "  print(len(glob('/content/train/'+type+'/*')))"
   ],
   "metadata": {
    "id": "PDfjwt-VA8yW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "cls_ = ['com', 'hoa', 'res']\n",
    "\n",
    "for i in cls_:\n",
    "  get_len_aug(i)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TfMT9FdUAuEE",
    "outputId": "a5f070be-2a25-43c5-8eef-601e59cdc504",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1255\n",
      "628\n",
      "334\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "for i in tqdm(glob('/content/train_aug/res/*')):\n",
    "  augment(i)\n",
    "\n",
    "for i in tqdm(glob('/content/train_aug/hoa/*')):\n",
    "  augment(i)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "2e389c411eb944df93cee2d5384f4903",
      "2b0ba81a6f6c4c6c87eb96581fb0d77a",
      "5efc679a14ab4fddb628988bf33d4cd5",
      "fd5325290ef04823b59077c28ca78cdc",
      "5b7bd5f4ef60414cb7f1bf177fb9a231",
      "4267efb97fa2443080bc9873b90ce30d",
      "3dfdda29eca943b5a28f330636703ffa",
      "ef66922bf46346cd9e042a023be6e13d",
      "88835753a67f4da5bdee08fe38a66591",
      "d4d4a4ee69b148f691f608ca6e8871df",
      "9aa6936c53ff499d9406d0cf15ce5696",
      "9f5608aae68d43219d6a1329d591673b",
      "fd62410c1d274177979c6c9e60521426",
      "146834835352472b817d54aaf82fe755",
      "8e1126593cf3442e86207585fe443680",
      "c9806a4939bb411e9957613d7be373bf",
      "420ea132c57748008bf7d5fb7e4eb1fe",
      "325c23b89f68417f8f83938262d276e2",
      "e1a9960618a94ddd8b3dee2586131914",
      "2b2b2bd7b0744b0eada907ce7522fb6c",
      "82fe47c2c0c246588202fc4c12ccab71",
      "b14b25d194d94599a9ec166baa8e4fe3"
     ]
    },
    "id": "GPH3pn-qA62v",
    "outputId": "ff2193de-66aa-4b72-80ad-4b221dff530e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e389c411eb944df93cee2d5384f4903"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/628 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9f5608aae68d43219d6a1329d591673b"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "cls_ = ['com', 'hoa', 'res']\n",
    "\n",
    "for i in cls_:\n",
    "  get_len_aug(i)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gpnMzZ8kBoJb",
    "outputId": "db1dbe57-8fe7-4ccf-cbce-4576c0a9466f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1255\n",
      "3180\n",
      "1671\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dl_hoa = glob('/content/train_aug/hoa/*')\n",
    "random.shuffle(dl_hoa)\n",
    "\n",
    "dl_res = glob('/content/train_aug/res/*')\n",
    "random.shuffle(dl_res)"
   ],
   "metadata": {
    "id": "N-i_lFRMC5oJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i in dl_hoa[0:1400]:\n",
    "  os.remove(i)"
   ],
   "metadata": {
    "id": "eWyzVbrTDhv9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "cls_ = ['com', 'hoa', 'res']\n",
    "\n",
    "for i in cls_:\n",
    "  get_len_aug(i)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "poUihDvKEjft",
    "outputId": "d9953748-8cc0-4eb5-f90a-01911911bb9e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1255\n",
      "1780\n",
      "1671\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training on EfficientNet-B0"
   ],
   "metadata": {
    "id": "hvoJlzTM74_N",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# !pip install timm\n",
    "!git clone https://github.com/Padam-Sharma/pytorch-image-models.git"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gHTJ4QPk7Ja2",
    "outputId": "089d14ce-87b1-4ec3-a3bf-270fc5879f68",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'pytorch-image-models'...\n",
      "remote: Enumerating objects: 11630, done.\u001B[K\n",
      "remote: Counting objects: 100% (3/3), done.\u001B[K\n",
      "remote: Compressing objects: 100% (3/3), done.\u001B[K\n",
      "remote: Total 11630 (delta 0), reused 0 (delta 0), pack-reused 11627\u001B[K\n",
      "Receiving objects: 100% (11630/11630), 20.98 MiB | 28.11 MiB/s, done.\n",
      "Resolving deltas: 100% (8579/8579), done.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%cd pytorch-image-models"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jeLHOck779Cm",
    "outputId": "8078b59e-2cfb-462b-cc14-b110c34d84bb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/pytorch-image-models\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -q -e ."
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ibH-xNIv7_LX",
    "outputId": "053ff7dc-9971-4bf6-a123-570ba4fd165e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  Installing build dependencies ... \u001B[?25l\u001B[?25hdone\n",
      "  Checking if build backend supports build_editable ... \u001B[?25l\u001B[?25hdone\n",
      "  Getting requirements to build editable ... \u001B[?25l\u001B[?25hdone\n",
      "  Preparing editable metadata (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m18.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m224.5/224.5 kB\u001B[0m \u001B[31m25.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Building editable for timm (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -q focal_loss_torch"
   ],
   "metadata": {
    "id": "mFFviUKD8d6U",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pop_len = len(glob('/content/train/*/*'))\n",
    "weights = [pop_len/(3*len(glob(i+'/*'))) for i in sorted(glob('/content/train/*'))]"
   ],
   "metadata": {
    "id": "7_JjSTOr8o9a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "weights"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vvAbw5T_8wvt",
    "outputId": "cd2c2780-0421-40b1-b411-112019f5a2e7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.5888446215139442, 1.1767515923566878, 2.212574850299401]"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!python train.py --data-dir '/content/train_aug' --model 'tf_efficientnet_b0' --pretrained --batch-size 8 --img-size 512 --val-split 0.2 --epochs 30 --num-classes 3"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N6Nit78S8BMc",
    "outputId": "e4769e49-49a3-4e90-def2-c9a831837483",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1;30;43mStreaming output truncated to the last 5000 lines.\u001B[0m\n",
      "   macro avg       0.95      0.95      0.95      4008\n",
      "weighted avg       0.95      0.95      0.95      4008\n",
      "\n",
      "Train: 12 [ 500/588 ( 85%)]  Loss: 0.1535 (0.0961)  Time: 0.264s,   30.30/s  (0.224s,   35.75/s)  LR: 2.045e-03  \n",
      "Conf Mat:\n",
      " [[ 961   27    6]\n",
      " [  70 1461   11]\n",
      " [  52   31 1389]]\n",
      "Data: 0.034 (0.020)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92      1188\n",
      "           1       0.95      0.96      0.96      1659\n",
      "           2       0.94      0.99      0.96      1561\n",
      "\n",
      "    accuracy                           0.95      4408\n",
      "   macro avg       0.95      0.94      0.95      4408\n",
      "weighted avg       0.95      0.95      0.95      4408\n",
      "\n",
      "Train: 12 [ 550/588 ( 94%)]  Loss: 0.02180 (0.101)  Time: 0.193s,   41.41/s  (0.222s,   36.01/s)  LR: 2.045e-03  \n",
      "Conf Mat:\n",
      " [[1055   30   11]\n",
      " [  74 1595   12]\n",
      " [  59   34 1538]]\n",
      "Data: 0.006 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92      1255\n",
      "           1       0.95      0.96      0.96      1779\n",
      "           2       0.94      0.99      0.96      1670\n",
      "\n",
      "    accuracy                           0.95      4704\n",
      "   macro avg       0.95      0.94      0.95      4704\n",
      "weighted avg       0.95      0.95      0.95      4704\n",
      "\n",
      "Train: 12 [ 587/588 (100%)]  Loss: 0.06546 (0.102)  Time: 0.187s,   42.80/s  (0.223s,   35.90/s)  LR: 2.045e-03  \n",
      "Conf Mat:\n",
      " [[1113   32   11]\n",
      " [  78 1709   12]\n",
      " [  64   38 1647]]\n",
      "Data: 0.000 (0.019)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         8\n",
      "   macro avg       0.33      0.33      0.33         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Test: [   0/79]  Time: 0.595 (0.595)  Loss:  0.5591 (0.5591)  \n",
      "Conf Mat:\n",
      " [[8 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95       369\n",
      "           1       0.63      1.00      0.77        39\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       408\n",
      "   macro avg       0.54      0.63      0.57       408\n",
      "weighted avg       0.96      0.91      0.93       408\n",
      "\n",
      "Test: [  50/79]  Time: 0.078 (0.150)  Loss:  0.5529 (0.6440)  \n",
      "Conf Mat:\n",
      " [[333   0   0]\n",
      " [ 23  39   0]\n",
      " [ 13   0   0]]\n",
      "Acc@1: 100.0000 (91.1765)  Acc@5: 100.0000 (100.0000)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93       369\n",
      "           1       0.86      0.92      0.89       169\n",
      "           2       0.88      0.95      0.91        96\n",
      "\n",
      "    accuracy                           0.91       634\n",
      "   macro avg       0.90      0.92      0.91       634\n",
      "weighted avg       0.92      0.91      0.92       634\n",
      "\n",
      "Test: [  79/79]  Time: 0.017 (0.163)  Loss:  0.5561 (0.6376)  \n",
      "Conf Mat:\n",
      " [[333  13   2]\n",
      " [ 23 156   3]\n",
      " [ 13   0  91]]\n",
      "Acc@1: 100.0000 (91.4826)  Acc@5: 100.0000 (100.0000)\n",
      "Current checkpoints:\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-11.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-12.pth.tar', 91.4826498422713)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-8.pth.tar', 91.32492113564669)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-6.pth.tar', 90.53627760252365)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-7.pth.tar', 90.22082018927445)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-5.pth.tar', 89.74763406940063)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-10.pth.tar', 89.58990536277602)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-9.pth.tar', 88.9589905362776)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-4.pth.tar', 86.27760252365931)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-3.pth.tar', 85.96214511041009)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         8\n",
      "   macro avg       1.00      1.00      1.00         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Train: 13 [   0/588 (  0%)]  Loss: 0.005371 (0.00537)  Time: 0.792s,   10.11/s  (0.792s,   10.11/s)  LR: 1.887e-03  \n",
      "Conf Mat:\n",
      " [[1 0 0]\n",
      " [0 5 0]\n",
      " [0 0 2]]\n",
      "Data: 0.601 (0.601)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.91       103\n",
      "           1       0.94      0.96      0.95       167\n",
      "           2       0.92      0.96      0.94       138\n",
      "\n",
      "    accuracy                           0.94       408\n",
      "   macro avg       0.94      0.93      0.93       408\n",
      "weighted avg       0.94      0.94      0.94       408\n",
      "\n",
      "Train: 13 [  50/588 (  9%)]  Loss: 0.2341 (0.107)  Time: 0.241s,   33.18/s  (0.221s,   36.13/s)  LR: 1.887e-03  \n",
      "Conf Mat:\n",
      " [[ 89   1   2]\n",
      " [  8 160   3]\n",
      " [  6   6 133]]\n",
      "Data: 0.013 (0.026)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.87      0.91       210\n",
      "           1       0.94      0.94      0.94       324\n",
      "           2       0.91      0.97      0.94       274\n",
      "\n",
      "    accuracy                           0.93       808\n",
      "   macro avg       0.93      0.93      0.93       808\n",
      "weighted avg       0.93      0.93      0.93       808\n",
      "\n",
      "Train: 13 [ 100/588 ( 17%)]  Loss: 0.4918 (0.127)  Time: 0.204s,   39.13/s  (0.221s,   36.25/s)  LR: 1.887e-03  \n",
      "Conf Mat:\n",
      " [[182   7   3]\n",
      " [ 14 306   6]\n",
      " [ 14  11 265]]\n",
      "Data: 0.009 (0.021)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92       333\n",
      "           1       0.95      0.95      0.95       474\n",
      "           2       0.92      0.98      0.95       401\n",
      "\n",
      "    accuracy                           0.94      1208\n",
      "   macro avg       0.94      0.93      0.94      1208\n",
      "weighted avg       0.94      0.94      0.94      1208\n",
      "\n",
      "Train: 13 [ 150/588 ( 26%)]  Loss: 0.03271 (0.110)  Time: 0.213s,   37.54/s  (0.222s,   36.04/s)  LR: 1.887e-03  \n",
      "Conf Mat:\n",
      " [[293  10   3]\n",
      " [ 20 449   6]\n",
      " [ 20  15 392]]\n",
      "Data: 0.022 (0.020)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91       448\n",
      "           1       0.94      0.95      0.94       619\n",
      "           2       0.92      0.98      0.95       541\n",
      "\n",
      "    accuracy                           0.94      1608\n",
      "   macro avg       0.94      0.93      0.94      1608\n",
      "weighted avg       0.94      0.94      0.94      1608\n",
      "\n",
      "Train: 13 [ 200/588 ( 34%)]  Loss: 0.2251 (0.113)  Time: 0.221s,   36.20/s  (0.221s,   36.21/s)  LR: 1.887e-03  \n",
      "Conf Mat:\n",
      " [[391  14   4]\n",
      " [ 30 586   7]\n",
      " [ 27  19 530]]\n",
      "Data: 0.017 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92       561\n",
      "           1       0.95      0.95      0.95       761\n",
      "           2       0.92      0.98      0.95       686\n",
      "\n",
      "    accuracy                           0.94      2008\n",
      "   macro avg       0.94      0.94      0.94      2008\n",
      "weighted avg       0.94      0.94      0.94      2008\n",
      "\n",
      "Train: 13 [ 250/588 ( 43%)]  Loss: 0.01615 (0.107)  Time: 0.200s,   40.00/s  (0.219s,   36.54/s)  LR: 1.887e-03  \n",
      "Conf Mat:\n",
      " [[492  15   4]\n",
      " [ 33 723   8]\n",
      " [ 36  23 674]]\n",
      "Data: 0.014 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92       649\n",
      "           1       0.95      0.95      0.95       911\n",
      "           2       0.93      0.98      0.95       848\n",
      "\n",
      "    accuracy                           0.94      2408\n",
      "   macro avg       0.95      0.94      0.94      2408\n",
      "weighted avg       0.95      0.94      0.94      2408\n",
      "\n",
      "Train: 13 [ 300/588 ( 51%)]  Loss: 0.01174 (0.106)  Time: 0.204s,   39.16/s  (0.220s,   36.31/s)  LR: 1.887e-03  \n",
      "Conf Mat:\n",
      " [[572  15   6]\n",
      " [ 38 868   8]\n",
      " [ 39  28 834]]\n",
      "Data: 0.015 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92       744\n",
      "           1       0.95      0.95      0.95      1080\n",
      "           2       0.93      0.98      0.96       984\n",
      "\n",
      "    accuracy                           0.95      2808\n",
      "   macro avg       0.95      0.94      0.94      2808\n",
      "weighted avg       0.95      0.95      0.95      2808\n",
      "\n",
      "Train: 13 [ 350/588 ( 60%)]  Loss: 0.005975 (0.102)  Time: 0.217s,   36.89/s  (0.221s,   36.23/s)  LR: 1.887e-03  \n",
      "Conf Mat:\n",
      " [[ 657   18    6]\n",
      " [  44 1031    9]\n",
      " [  43   31  969]]\n",
      "Data: 0.020 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92       846\n",
      "           1       0.95      0.96      0.95      1231\n",
      "           2       0.93      0.99      0.96      1131\n",
      "\n",
      "    accuracy                           0.95      3208\n",
      "   macro avg       0.95      0.94      0.95      3208\n",
      "weighted avg       0.95      0.95      0.95      3208\n",
      "\n",
      "Train: 13 [ 400/588 ( 68%)]  Loss: 0.02316 (0.0981)  Time: 0.252s,   31.75/s  (0.219s,   36.53/s)  LR: 1.887e-03  \n",
      "Conf Mat:\n",
      " [[ 748   20    6]\n",
      " [  52 1179    9]\n",
      " [  46   32 1116]]\n",
      "Data: 0.014 (0.017)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92       944\n",
      "           1       0.95      0.96      0.95      1398\n",
      "           2       0.93      0.98      0.96      1266\n",
      "\n",
      "    accuracy                           0.95      3608\n",
      "   macro avg       0.95      0.94      0.94      3608\n",
      "weighted avg       0.95      0.95      0.95      3608\n",
      "\n",
      "Train: 13 [ 450/588 ( 77%)]  Loss: 0.1870 (0.0990)  Time: 0.209s,   38.29/s  (0.219s,   36.55/s)  LR: 1.887e-03  \n",
      "Conf Mat:\n",
      " [[ 832   22    7]\n",
      " [  58 1339   12]\n",
      " [  54   37 1247]]\n",
      "Data: 0.015 (0.017)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93      1060\n",
      "           1       0.95      0.96      0.96      1538\n",
      "           2       0.94      0.99      0.96      1410\n",
      "\n",
      "    accuracy                           0.95      4008\n",
      "   macro avg       0.95      0.94      0.95      4008\n",
      "weighted avg       0.95      0.95      0.95      4008\n",
      "\n",
      "Train: 13 [ 500/588 ( 85%)]  Loss: 0.06256 (0.0950)  Time: 0.200s,   40.04/s  (0.220s,   36.36/s)  LR: 1.887e-03  \n",
      "Conf Mat:\n",
      " [[ 943   24    7]\n",
      " [  62 1474   12]\n",
      " [  55   40 1391]]\n",
      "Data: 0.012 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93      1167\n",
      "           1       0.95      0.96      0.96      1679\n",
      "           2       0.94      0.99      0.96      1562\n",
      "\n",
      "    accuracy                           0.95      4408\n",
      "   macro avg       0.95      0.95      0.95      4408\n",
      "weighted avg       0.95      0.95      0.95      4408\n",
      "\n",
      "Train: 13 [ 550/588 ( 94%)]  Loss: 0.04388 (0.0958)  Time: 0.268s,   29.84/s  (0.220s,   36.32/s)  LR: 1.887e-03  \n",
      "Conf Mat:\n",
      " [[1039   25    7]\n",
      " [  69 1611   13]\n",
      " [  59   43 1542]]\n",
      "Data: 0.022 (0.017)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93      1255\n",
      "           1       0.95      0.96      0.95      1780\n",
      "           2       0.94      0.99      0.96      1669\n",
      "\n",
      "    accuracy                           0.95      4704\n",
      "   macro avg       0.95      0.94      0.95      4704\n",
      "weighted avg       0.95      0.95      0.95      4704\n",
      "\n",
      "Train: 13 [ 587/588 (100%)]  Loss: 0.1494 (0.100)  Time: 0.187s,   42.81/s  (0.219s,   36.52/s)  LR: 1.887e-03  \n",
      "Conf Mat:\n",
      " [[1115   30    8]\n",
      " [  75 1703   13]\n",
      " [  65   47 1648]]\n",
      "Data: 0.000 (0.017)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         8\n",
      "   macro avg       0.33      0.33      0.33         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Test: [   0/79]  Time: 0.749 (0.749)  Loss:  0.5524 (0.5524)  \n",
      "Conf Mat:\n",
      " [[8 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96       369\n",
      "           1       0.68      0.97      0.80        39\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       408\n",
      "   macro avg       0.56      0.63      0.59       408\n",
      "weighted avg       0.97      0.93      0.94       408\n",
      "\n",
      "Test: [  50/79]  Time: 0.063 (0.190)  Loss:  0.5535 (0.6203)  \n",
      "Conf Mat:\n",
      " [[340   1   0]\n",
      " [ 18  38   0]\n",
      " [ 11   0   0]]\n",
      "Acc@1: 100.0000 (92.6471)  Acc@5: 100.0000 (100.0000)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       369\n",
      "           1       0.88      0.89      0.88       169\n",
      "           2       0.89      0.95      0.92        96\n",
      "\n",
      "    accuracy                           0.92       634\n",
      "   macro avg       0.90      0.92      0.91       634\n",
      "weighted avg       0.92      0.92      0.92       634\n",
      "\n",
      "Test: [  79/79]  Time: 0.015 (0.165)  Loss:  0.5595 (0.6321)  \n",
      "Conf Mat:\n",
      " [[340  19   2]\n",
      " [ 18 150   3]\n",
      " [ 11   0  91]]\n",
      "Acc@1: 100.0000 (91.6404)  Acc@5: 100.0000 (100.0000)\n",
      "Current checkpoints:\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-11.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-13.pth.tar', 91.6403785488959)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-12.pth.tar', 91.4826498422713)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-8.pth.tar', 91.32492113564669)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-6.pth.tar', 90.53627760252365)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-7.pth.tar', 90.22082018927445)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-5.pth.tar', 89.74763406940063)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-10.pth.tar', 89.58990536277602)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-9.pth.tar', 88.9589905362776)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-4.pth.tar', 86.27760252365931)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      0.75      0.86         4\n",
      "           2       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.88         8\n",
      "   macro avg       0.83      0.92      0.84         8\n",
      "weighted avg       0.94      0.88      0.89         8\n",
      "\n",
      "Train: 14 [   0/588 (  0%)]  Loss: 0.2258 (0.226)  Time: 0.817s,    9.79/s  (0.817s,    9.79/s)  LR: 1.726e-03  \n",
      "Conf Mat:\n",
      " [[3 0 0]\n",
      " [0 3 0]\n",
      " [0 1 1]]\n",
      "Data: 0.617 (0.617)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94       101\n",
      "           1       0.94      0.96      0.95       156\n",
      "           2       0.95      0.98      0.97       151\n",
      "\n",
      "    accuracy                           0.95       408\n",
      "   macro avg       0.96      0.95      0.95       408\n",
      "weighted avg       0.95      0.95      0.95       408\n",
      "\n",
      "Train: 14 [  50/588 (  9%)]  Loss: 0.01789 (0.0982)  Time: 0.202s,   39.57/s  (0.245s,   32.66/s)  LR: 1.726e-03  \n",
      "Conf Mat:\n",
      " [[ 91   1   1]\n",
      " [  8 150   2]\n",
      " [  2   5 148]]\n",
      "Data: 0.015 (0.034)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94       223\n",
      "           1       0.95      0.96      0.95       292\n",
      "           2       0.95      0.99      0.97       293\n",
      "\n",
      "    accuracy                           0.96       808\n",
      "   macro avg       0.96      0.95      0.95       808\n",
      "weighted avg       0.96      0.96      0.96       808\n",
      "\n",
      "Train: 14 [ 100/588 ( 17%)]  Loss: 0.04004 (0.0817)  Time: 0.243s,   32.92/s  (0.229s,   34.86/s)  LR: 1.726e-03  \n",
      "Conf Mat:\n",
      " [[202   3   1]\n",
      " [ 14 280   2]\n",
      " [  7   9 290]]\n",
      "Data: 0.027 (0.024)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.95       320\n",
      "           1       0.95      0.96      0.96       453\n",
      "           2       0.95      0.99      0.97       435\n",
      "\n",
      "    accuracy                           0.96      1208\n",
      "   macro avg       0.96      0.95      0.96      1208\n",
      "weighted avg       0.96      0.96      0.96      1208\n",
      "\n",
      "Train: 14 [ 150/588 ( 26%)]  Loss: 0.09282 (0.0894)  Time: 0.204s,   39.13/s  (0.224s,   35.64/s)  LR: 1.726e-03  \n",
      "Conf Mat:\n",
      " [[292   4   1]\n",
      " [ 18 436   4]\n",
      " [ 10  13 430]]\n",
      "Data: 0.012 (0.022)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94       428\n",
      "           1       0.95      0.96      0.96       598\n",
      "           2       0.95      0.98      0.96       582\n",
      "\n",
      "    accuracy                           0.96      1608\n",
      "   macro avg       0.96      0.95      0.96      1608\n",
      "weighted avg       0.96      0.96      0.96      1608\n",
      "\n",
      "Train: 14 [ 200/588 ( 34%)]  Loss: 0.01834 (0.0895)  Time: 0.202s,   39.67/s  (0.225s,   35.59/s)  LR: 1.726e-03  \n",
      "Conf Mat:\n",
      " [[389   5   2]\n",
      " [ 22 577   7]\n",
      " [ 17  16 573]]\n",
      "Data: 0.012 (0.021)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94       545\n",
      "           1       0.95      0.97      0.96       742\n",
      "           2       0.95      0.99      0.97       721\n",
      "\n",
      "    accuracy                           0.96      2008\n",
      "   macro avg       0.96      0.95      0.96      2008\n",
      "weighted avg       0.96      0.96      0.96      2008\n",
      "\n",
      "Train: 14 [ 250/588 ( 43%)]  Loss: 0.3345 (0.0890)  Time: 0.240s,   33.36/s  (0.224s,   35.65/s)  LR: 1.726e-03  \n",
      "Conf Mat:\n",
      " [[496   8   2]\n",
      " [ 26 717   8]\n",
      " [ 23  17 711]]\n",
      "Data: 0.012 (0.020)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.95       653\n",
      "           1       0.96      0.97      0.96       900\n",
      "           2       0.95      0.99      0.97       855\n",
      "\n",
      "    accuracy                           0.96      2408\n",
      "   macro avg       0.96      0.96      0.96      2408\n",
      "weighted avg       0.96      0.96      0.96      2408\n",
      "\n",
      "Train: 14 [ 300/588 ( 51%)]  Loss: 0.1055 (0.0850)  Time: 0.196s,   40.81/s  (0.221s,   36.22/s)  LR: 1.726e-03  \n",
      "Conf Mat:\n",
      " [[595   9   2]\n",
      " [ 32 871   8]\n",
      " [ 26  20 845]]\n",
      "Data: 0.006 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94       751\n",
      "           1       0.96      0.97      0.96      1066\n",
      "           2       0.95      0.99      0.97       991\n",
      "\n",
      "    accuracy                           0.96      2808\n",
      "   macro avg       0.96      0.96      0.96      2808\n",
      "weighted avg       0.96      0.96      0.96      2808\n",
      "\n",
      "Train: 14 [ 350/588 ( 60%)]  Loss: 0.006149 (0.0829)  Time: 0.201s,   39.73/s  (0.221s,   36.13/s)  LR: 1.726e-03  \n",
      "Conf Mat:\n",
      " [[ 686   14    2]\n",
      " [  37 1029    9]\n",
      " [  28   23  980]]\n",
      "Data: 0.012 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94       864\n",
      "           1       0.96      0.97      0.96      1220\n",
      "           2       0.95      0.99      0.97      1124\n",
      "\n",
      "    accuracy                           0.96      3208\n",
      "   macro avg       0.96      0.95      0.96      3208\n",
      "weighted avg       0.96      0.96      0.96      3208\n",
      "\n",
      "Train: 14 [ 400/588 ( 68%)]  Loss: 0.01143 (0.0856)  Time: 0.226s,   35.38/s  (0.222s,   36.04/s)  LR: 1.726e-03  \n",
      "Conf Mat:\n",
      " [[ 782   16    3]\n",
      " [  44 1179   10]\n",
      " [  38   25 1111]]\n",
      "Data: 0.033 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94       956\n",
      "           1       0.96      0.97      0.96      1363\n",
      "           2       0.95      0.99      0.97      1289\n",
      "\n",
      "    accuracy                           0.96      3608\n",
      "   macro avg       0.96      0.95      0.96      3608\n",
      "weighted avg       0.96      0.96      0.96      3608\n",
      "\n",
      "Train: 14 [ 450/588 ( 77%)]  Loss: 0.2615 (0.0870)  Time: 0.281s,   28.43/s  (0.221s,   36.26/s)  LR: 1.726e-03  \n",
      "Conf Mat:\n",
      " [[ 865   17    4]\n",
      " [  48 1316   12]\n",
      " [  43   30 1273]]\n",
      "Data: 0.029 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94      1057\n",
      "           1       0.96      0.97      0.96      1514\n",
      "           2       0.95      0.99      0.97      1437\n",
      "\n",
      "    accuracy                           0.96      4008\n",
      "   macro avg       0.96      0.95      0.96      4008\n",
      "weighted avg       0.96      0.96      0.96      4008\n",
      "\n",
      "Train: 14 [ 500/588 ( 85%)]  Loss: 0.01428 (0.0860)  Time: 0.213s,   37.51/s  (0.220s,   36.37/s)  LR: 1.726e-03  \n",
      "Conf Mat:\n",
      " [[ 955   18    4]\n",
      " [  56 1462   12]\n",
      " [  46   34 1421]]\n",
      "Data: 0.013 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.94      1161\n",
      "           1       0.95      0.96      0.96      1668\n",
      "           2       0.95      0.99      0.97      1579\n",
      "\n",
      "    accuracy                           0.96      4408\n",
      "   macro avg       0.96      0.95      0.96      4408\n",
      "weighted avg       0.96      0.96      0.96      4408\n",
      "\n",
      "Train: 14 [ 550/588 ( 94%)]  Loss: 0.03091 (0.0868)  Time: 0.200s,   39.98/s  (0.221s,   36.22/s)  LR: 1.726e-03  \n",
      "Conf Mat:\n",
      " [[1049   22    6]\n",
      " [  64 1609   12]\n",
      " [  48   37 1561]]\n",
      "Data: 0.014 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94      1254\n",
      "           1       0.95      0.97      0.96      1780\n",
      "           2       0.95      0.99      0.97      1670\n",
      "\n",
      "    accuracy                           0.96      4704\n",
      "   macro avg       0.96      0.95      0.95      4704\n",
      "weighted avg       0.96      0.96      0.96      4704\n",
      "\n",
      "Train: 14 [ 587/588 (100%)]  Loss: 0.2908 (0.0865)  Time: 0.188s,   42.48/s  (0.220s,   36.43/s)  LR: 1.726e-03  \n",
      "Conf Mat:\n",
      " [[1131   22    6]\n",
      " [  69 1718   13]\n",
      " [  54   40 1651]]\n",
      "Data: 0.000 (0.017)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         8\n",
      "   macro avg       0.33      0.33      0.33         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Test: [   0/79]  Time: 1.244 (1.244)  Loss:  0.5531 (0.5531)  \n",
      "Conf Mat:\n",
      " [[8 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       369\n",
      "           1       0.64      0.95      0.76        39\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       408\n",
      "   macro avg       0.54      0.62      0.57       408\n",
      "weighted avg       0.96      0.91      0.93       408\n",
      "\n",
      "Test: [  50/79]  Time: 0.070 (0.167)  Loss:  0.5532 (0.6357)  \n",
      "Conf Mat:\n",
      " [[336   2   0]\n",
      " [ 21  37   0]\n",
      " [ 12   0   0]]\n",
      "Acc@1: 100.0000 (91.4216)  Acc@5: 100.0000 (100.0000)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93       369\n",
      "           1       0.86      0.88      0.87       169\n",
      "           2       0.89      0.97      0.93        96\n",
      "\n",
      "    accuracy                           0.91       634\n",
      "   macro avg       0.90      0.92      0.91       634\n",
      "weighted avg       0.91      0.91      0.91       634\n",
      "\n",
      "Test: [  79/79]  Time: 0.015 (0.152)  Loss:  0.5525 (0.6403)  \n",
      "Conf Mat:\n",
      " [[336  21   0]\n",
      " [ 21 148   3]\n",
      " [ 12   0  93]]\n",
      "Acc@1: 100.0000 (91.0095)  Acc@5: 100.0000 (100.0000)\n",
      "Current checkpoints:\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-11.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-13.pth.tar', 91.6403785488959)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-12.pth.tar', 91.4826498422713)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-8.pth.tar', 91.32492113564669)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-14.pth.tar', 91.00946372239747)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-6.pth.tar', 90.53627760252365)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-7.pth.tar', 90.22082018927445)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-5.pth.tar', 89.74763406940063)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-10.pth.tar', 89.58990536277602)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-9.pth.tar', 88.9589905362776)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.50      0.67         4\n",
      "           2       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           0.75         8\n",
      "   macro avg       0.67      0.50      0.56         8\n",
      "weighted avg       1.00      0.75      0.83         8\n",
      "\n",
      "Train: 15 [   0/588 (  0%)]  Loss: 0.4695 (0.469)  Time: 0.832s,    9.62/s  (0.832s,    9.62/s)  LR: 1.563e-03  \n",
      "Conf Mat:\n",
      " [[0 2 0]\n",
      " [0 2 0]\n",
      " [0 0 4]]\n",
      "Data: 0.633 (0.633)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95       110\n",
      "           1       0.95      0.96      0.95       141\n",
      "           2       0.98      1.00      0.99       157\n",
      "\n",
      "    accuracy                           0.97       408\n",
      "   macro avg       0.97      0.96      0.97       408\n",
      "weighted avg       0.97      0.97      0.97       408\n",
      "\n",
      "Train: 15 [  50/588 (  9%)]  Loss: 0.008872 (0.0826)  Time: 0.202s,   39.56/s  (0.251s,   31.83/s)  LR: 1.563e-03  \n",
      "Conf Mat:\n",
      " [[103   3   0]\n",
      " [  7 135   0]\n",
      " [  0   3 157]]\n",
      "Data: 0.011 (0.044)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       203\n",
      "           1       0.96      0.95      0.96       298\n",
      "           2       0.96      0.99      0.97       307\n",
      "\n",
      "    accuracy                           0.96       808\n",
      "   macro avg       0.96      0.96      0.96       808\n",
      "weighted avg       0.96      0.96      0.96       808\n",
      "\n",
      "Train: 15 [ 100/588 ( 17%)]  Loss: 0.008322 (0.0902)  Time: 0.219s,   36.54/s  (0.239s,   33.49/s)  LR: 1.563e-03  \n",
      "Conf Mat:\n",
      " [[188   6   0]\n",
      " [  9 284   2]\n",
      " [  6   8 305]]\n",
      "Data: 0.017 (0.032)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94       316\n",
      "           1       0.95      0.96      0.95       453\n",
      "           2       0.95      0.99      0.97       439\n",
      "\n",
      "    accuracy                           0.95      1208\n",
      "   macro avg       0.96      0.95      0.95      1208\n",
      "weighted avg       0.95      0.95      0.95      1208\n",
      "\n",
      "Train: 15 [ 150/588 ( 26%)]  Loss: 0.04844 (0.0953)  Time: 0.241s,   33.20/s  (0.230s,   34.85/s)  LR: 1.563e-03  \n",
      "Conf Mat:\n",
      " [[284   7   0]\n",
      " [ 20 433   4]\n",
      " [ 12  13 435]]\n",
      "Data: 0.020 (0.026)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.94       424\n",
      "           1       0.95      0.95      0.95       591\n",
      "           2       0.94      0.99      0.97       593\n",
      "\n",
      "    accuracy                           0.95      1608\n",
      "   macro avg       0.96      0.95      0.95      1608\n",
      "weighted avg       0.95      0.95      0.95      1608\n",
      "\n",
      "Train: 15 [ 200/588 ( 34%)]  Loss: 0.003569 (0.0951)  Time: 0.206s,   38.74/s  (0.227s,   35.30/s)  LR: 1.563e-03  \n",
      "Conf Mat:\n",
      " [[382   9   1]\n",
      " [ 24 564   5]\n",
      " [ 18  18 587]]\n",
      "Data: 0.015 (0.023)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94       514\n",
      "           1       0.95      0.96      0.96       761\n",
      "           2       0.95      0.99      0.97       733\n",
      "\n",
      "    accuracy                           0.96      2008\n",
      "   macro avg       0.96      0.95      0.95      2008\n",
      "weighted avg       0.96      0.96      0.96      2008\n",
      "\n",
      "Train: 15 [ 250/588 ( 43%)]  Loss: 0.008962 (0.0914)  Time: 0.212s,   37.68/s  (0.227s,   35.26/s)  LR: 1.563e-03  \n",
      "Conf Mat:\n",
      " [[465   9   2]\n",
      " [ 30 730   5]\n",
      " [ 19  22 726]]\n",
      "Data: 0.017 (0.022)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.95       632\n",
      "           1       0.96      0.96      0.96       907\n",
      "           2       0.95      0.99      0.97       869\n",
      "\n",
      "    accuracy                           0.96      2408\n",
      "   macro avg       0.96      0.95      0.96      2408\n",
      "weighted avg       0.96      0.96      0.96      2408\n",
      "\n",
      "Train: 15 [ 300/588 ( 51%)]  Loss: 0.006056 (0.0869)  Time: 0.241s,   33.20/s  (0.226s,   35.38/s)  LR: 1.563e-03  \n",
      "Conf Mat:\n",
      " [[576   9   2]\n",
      " [ 34 873   6]\n",
      " [ 22  25 861]]\n",
      "Data: 0.026 (0.022)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94       736\n",
      "           1       0.96      0.96      0.96      1055\n",
      "           2       0.95      0.99      0.97      1017\n",
      "\n",
      "    accuracy                           0.96      2808\n",
      "   macro avg       0.96      0.96      0.96      2808\n",
      "weighted avg       0.96      0.96      0.96      2808\n",
      "\n",
      "Train: 15 [ 350/588 ( 60%)]  Loss: 0.1505 (0.0834)  Time: 0.198s,   40.47/s  (0.223s,   35.91/s)  LR: 1.563e-03  \n",
      "Conf Mat:\n",
      " [[ 673   13    3]\n",
      " [  35 1017    6]\n",
      " [  28   25 1008]]\n",
      "Data: 0.012 (0.021)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95       844\n",
      "           1       0.96      0.96      0.96      1201\n",
      "           2       0.95      0.99      0.97      1163\n",
      "\n",
      "    accuracy                           0.96      3208\n",
      "   macro avg       0.96      0.96      0.96      3208\n",
      "weighted avg       0.96      0.96      0.96      3208\n",
      "\n",
      "Train: 15 [ 400/588 ( 68%)]  Loss: 0.1487 (0.0852)  Time: 0.205s,   39.03/s  (0.224s,   35.79/s)  LR: 1.563e-03  \n",
      "Conf Mat:\n",
      " [[ 774   16    3]\n",
      " [  37 1156    8]\n",
      " [  33   29 1152]]\n",
      "Data: 0.019 (0.020)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94       970\n",
      "           1       0.96      0.96      0.96      1354\n",
      "           2       0.95      0.99      0.97      1284\n",
      "\n",
      "    accuracy                           0.96      3608\n",
      "   macro avg       0.96      0.96      0.96      3608\n",
      "weighted avg       0.96      0.96      0.96      3608\n",
      "\n",
      "Train: 15 [ 450/588 ( 77%)]  Loss: 0.1967 (0.0873)  Time: 0.209s,   38.28/s  (0.224s,   35.72/s)  LR: 1.563e-03  \n",
      "Conf Mat:\n",
      " [[ 888   19    4]\n",
      " [  45 1302    8]\n",
      " [  37   33 1272]]\n",
      "Data: 0.017 (0.020)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94      1068\n",
      "           1       0.96      0.96      0.96      1513\n",
      "           2       0.95      0.99      0.97      1427\n",
      "\n",
      "    accuracy                           0.96      4008\n",
      "   macro avg       0.96      0.96      0.96      4008\n",
      "weighted avg       0.96      0.96      0.96      4008\n",
      "\n",
      "Train: 15 [ 500/588 ( 85%)]  Loss: 0.007796 (0.0860)  Time: 0.255s,   31.37/s  (0.222s,   35.96/s)  LR: 1.563e-03  \n",
      "Conf Mat:\n",
      " [[ 976   21    5]\n",
      " [  51 1456    8]\n",
      " [  41   36 1414]]\n",
      "Data: 0.029 (0.020)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94      1178\n",
      "           1       0.96      0.96      0.96      1670\n",
      "           2       0.95      0.99      0.97      1560\n",
      "\n",
      "    accuracy                           0.96      4408\n",
      "   macro avg       0.96      0.95      0.96      4408\n",
      "weighted avg       0.96      0.96      0.96      4408\n",
      "\n",
      "Train: 15 [ 550/588 ( 94%)]  Loss: 0.1067 (0.0867)  Time: 0.218s,   36.78/s  (0.222s,   36.09/s)  LR: 1.563e-03  \n",
      "Conf Mat:\n",
      " [[1072   22    5]\n",
      " [  56 1609    9]\n",
      " [  50   39 1546]]\n",
      "Data: 0.027 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94      1255\n",
      "           1       0.96      0.96      0.96      1779\n",
      "           2       0.95      0.99      0.97      1670\n",
      "\n",
      "    accuracy                           0.96      4704\n",
      "   macro avg       0.96      0.96      0.96      4704\n",
      "weighted avg       0.96      0.96      0.96      4704\n",
      "\n",
      "Train: 15 [ 587/588 (100%)]  Loss: 0.07381 (0.0860)  Time: 0.187s,   42.67/s  (0.222s,   36.00/s)  LR: 1.563e-03  \n",
      "Conf Mat:\n",
      " [[1142   24    6]\n",
      " [  61 1715    9]\n",
      " [  52   40 1655]]\n",
      "Data: 0.000 (0.019)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         8\n",
      "   macro avg       0.33      0.33      0.33         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Test: [   0/79]  Time: 0.749 (0.749)  Loss:  0.5551 (0.5551)  \n",
      "Conf Mat:\n",
      " [[8 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95       369\n",
      "           1       0.61      0.95      0.74        39\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92       408\n",
      "   macro avg       0.53      0.62      0.56       408\n",
      "weighted avg       0.96      0.92      0.93       408\n",
      "\n",
      "Test: [  50/79]  Time: 0.091 (0.139)  Loss:  0.5547 (0.6399)  \n",
      "Conf Mat:\n",
      " [[338   2   0]\n",
      " [ 24  37   0]\n",
      " [  7   0   0]]\n",
      "Acc@1: 100.0000 (91.9118)  Acc@5: 100.0000 (100.0000)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93       369\n",
      "           1       0.85      0.90      0.87       169\n",
      "           2       0.93      0.96      0.94        96\n",
      "\n",
      "    accuracy                           0.92       634\n",
      "   macro avg       0.91      0.92      0.92       634\n",
      "weighted avg       0.92      0.92      0.92       634\n",
      "\n",
      "Test: [  79/79]  Time: 0.015 (0.155)  Loss:  0.5550 (0.6385)  \n",
      "Conf Mat:\n",
      " [[338  17   1]\n",
      " [ 24 152   3]\n",
      " [  7   0  92]]\n",
      "Acc@1: 100.0000 (91.7981)  Acc@5: 100.0000 (100.0000)\n",
      "Current checkpoints:\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-11.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-15.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-13.pth.tar', 91.6403785488959)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-12.pth.tar', 91.4826498422713)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-8.pth.tar', 91.32492113564669)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-14.pth.tar', 91.00946372239747)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-6.pth.tar', 90.53627760252365)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-7.pth.tar', 90.22082018927445)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-5.pth.tar', 89.74763406940063)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-10.pth.tar', 89.58990536277602)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         8\n",
      "   macro avg       1.00      1.00      1.00         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Train: 16 [   0/588 (  0%)]  Loss: 0.01389 (0.0139)  Time: 1.195s,    6.69/s  (1.195s,    6.69/s)  LR: 1.399e-03  \n",
      "Conf Mat:\n",
      " [[2 0 0]\n",
      " [0 3 0]\n",
      " [0 0 3]]\n",
      "Data: 0.948 (0.948)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96       106\n",
      "           1       0.97      0.97      0.97       160\n",
      "           2       0.97      1.00      0.99       142\n",
      "\n",
      "    accuracy                           0.97       408\n",
      "   macro avg       0.97      0.97      0.97       408\n",
      "weighted avg       0.97      0.97      0.97       408\n",
      "\n",
      "Train: 16 [  50/588 (  9%)]  Loss: 0.007614 (0.0589)  Time: 0.204s,   39.26/s  (0.226s,   35.41/s)  LR: 1.399e-03  \n",
      "Conf Mat:\n",
      " [[100   3   0]\n",
      " [  4 155   0]\n",
      " [  2   2 142]]\n",
      "Data: 0.013 (0.033)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94       219\n",
      "           1       0.96      0.97      0.96       326\n",
      "           2       0.95      1.00      0.97       263\n",
      "\n",
      "    accuracy                           0.96       808\n",
      "   macro avg       0.96      0.96      0.96       808\n",
      "weighted avg       0.96      0.96      0.96       808\n",
      "\n",
      "Train: 16 [ 100/588 ( 17%)]  Loss: 0.1608 (0.0713)  Time: 0.194s,   41.25/s  (0.227s,   35.31/s)  LR: 1.399e-03  \n",
      "Conf Mat:\n",
      " [[199   5   0]\n",
      " [ 12 315   0]\n",
      " [  8   6 263]]\n",
      "Data: 0.006 (0.025)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.95       334\n",
      "           1       0.95      0.97      0.96       465\n",
      "           2       0.95      0.99      0.97       409\n",
      "\n",
      "    accuracy                           0.96      1208\n",
      "   macro avg       0.96      0.96      0.96      1208\n",
      "weighted avg       0.96      0.96      0.96      1208\n",
      "\n",
      "Train: 16 [ 150/588 ( 26%)]  Loss: 0.01830 (0.0702)  Time: 0.200s,   40.07/s  (0.226s,   35.37/s)  LR: 1.399e-03  \n",
      "Conf Mat:\n",
      " [[304   5   0]\n",
      " [ 18 451   4]\n",
      " [ 12   9 405]]\n",
      "Data: 0.008 (0.023)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95       441\n",
      "           1       0.96      0.97      0.96       617\n",
      "           2       0.95      0.99      0.97       550\n",
      "\n",
      "    accuracy                           0.96      1608\n",
      "   macro avg       0.96      0.96      0.96      1608\n",
      "weighted avg       0.96      0.96      0.96      1608\n",
      "\n",
      "Train: 16 [ 200/588 ( 34%)]  Loss: 0.2639 (0.0741)  Time: 0.283s,   28.27/s  (0.222s,   36.06/s)  LR: 1.399e-03  \n",
      "Conf Mat:\n",
      " [[405   8   1]\n",
      " [ 21 596   4]\n",
      " [ 15  13 545]]\n",
      "Data: 0.023 (0.021)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.95       540\n",
      "           1       0.96      0.97      0.96       777\n",
      "           2       0.95      0.99      0.97       691\n",
      "\n",
      "    accuracy                           0.96      2008\n",
      "   macro avg       0.96      0.96      0.96      2008\n",
      "weighted avg       0.96      0.96      0.96      2008\n",
      "\n",
      "Train: 16 [ 250/588 ( 43%)]  Loss: 0.002791 (0.0737)  Time: 0.211s,   38.00/s  (0.221s,   36.12/s)  LR: 1.399e-03  \n",
      "Conf Mat:\n",
      " [[494  10   1]\n",
      " [ 26 751   5]\n",
      " [ 20  16 685]]\n",
      "Data: 0.019 (0.020)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.95       644\n",
      "           1       0.96      0.97      0.96       917\n",
      "           2       0.95      0.99      0.97       847\n",
      "\n",
      "    accuracy                           0.96      2408\n",
      "   macro avg       0.96      0.96      0.96      2408\n",
      "weighted avg       0.96      0.96      0.96      2408\n",
      "\n",
      "Train: 16 [ 300/588 ( 51%)]  Loss: 0.1462 (0.0716)  Time: 0.204s,   39.23/s  (0.222s,   35.99/s)  LR: 1.399e-03  \n",
      "Conf Mat:\n",
      " [[588  10   1]\n",
      " [ 34 889   7]\n",
      " [ 22  18 839]]\n",
      "Data: 0.006 (0.020)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.95       756\n",
      "           1       0.96      0.97      0.96      1048\n",
      "           2       0.95      0.99      0.97      1004\n",
      "\n",
      "    accuracy                           0.96      2808\n",
      "   macro avg       0.96      0.96      0.96      2808\n",
      "weighted avg       0.96      0.96      0.96      2808\n",
      "\n",
      "Train: 16 [ 350/588 ( 60%)]  Loss: 0.05177 (0.0766)  Time: 0.280s,   28.57/s  (0.222s,   36.00/s)  LR: 1.399e-03  \n",
      "Conf Mat:\n",
      " [[ 690   11    3]\n",
      " [  37 1013   10]\n",
      " [  29   24  991]]\n",
      "Data: 0.028 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94       862\n",
      "           1       0.96      0.96      0.96      1191\n",
      "           2       0.95      0.99      0.97      1155\n",
      "\n",
      "    accuracy                           0.96      3208\n",
      "   macro avg       0.96      0.96      0.96      3208\n",
      "weighted avg       0.96      0.96      0.96      3208\n",
      "\n",
      "Train: 16 [ 400/588 ( 68%)]  Loss: 0.01410 (0.0770)  Time: 0.195s,   41.12/s  (0.220s,   36.33/s)  LR: 1.399e-03  \n",
      "Conf Mat:\n",
      " [[ 787   16    4]\n",
      " [  40 1149   10]\n",
      " [  35   26 1141]]\n",
      "Data: 0.006 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94       972\n",
      "           1       0.96      0.96      0.96      1350\n",
      "           2       0.95      0.99      0.97      1286\n",
      "\n",
      "    accuracy                           0.96      3608\n",
      "   macro avg       0.96      0.95      0.96      3608\n",
      "weighted avg       0.96      0.96      0.96      3608\n",
      "\n",
      "Train: 16 [ 450/588 ( 77%)]  Loss: 0.03120 (0.0785)  Time: 0.203s,   39.37/s  (0.221s,   36.21/s)  LR: 1.399e-03  \n",
      "Conf Mat:\n",
      " [[ 886   19    4]\n",
      " [  47 1302   11]\n",
      " [  39   29 1271]]\n",
      "Data: 0.012 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94      1076\n",
      "           1       0.96      0.97      0.96      1509\n",
      "           2       0.95      0.99      0.97      1423\n",
      "\n",
      "    accuracy                           0.96      4008\n",
      "   macro avg       0.96      0.95      0.96      4008\n",
      "weighted avg       0.96      0.96      0.96      4008\n",
      "\n",
      "Train: 16 [ 500/588 ( 85%)]  Loss: 0.3896 (0.0782)  Time: 0.194s,   41.30/s  (0.222s,   36.11/s)  LR: 1.399e-03  \n",
      "Conf Mat:\n",
      " [[ 979   22    4]\n",
      " [  52 1457   11]\n",
      " [  45   30 1408]]\n",
      "Data: 0.004 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94      1180\n",
      "           1       0.96      0.97      0.96      1667\n",
      "           2       0.95      0.99      0.97      1561\n",
      "\n",
      "    accuracy                           0.96      4408\n",
      "   macro avg       0.96      0.96      0.96      4408\n",
      "weighted avg       0.96      0.96      0.96      4408\n",
      "\n",
      "Train: 16 [ 550/588 ( 94%)]  Loss: 0.03595 (0.0778)  Time: 0.332s,   24.07/s  (0.221s,   36.26/s)  LR: 1.399e-03  \n",
      "Conf Mat:\n",
      " [[1076   22    4]\n",
      " [  56 1611   12]\n",
      " [  48   34 1545]]\n",
      "Data: 0.061 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.94      1254\n",
      "           1       0.96      0.97      0.96      1780\n",
      "           2       0.95      0.99      0.97      1670\n",
      "\n",
      "    accuracy                           0.96      4704\n",
      "   macro avg       0.96      0.96      0.96      4704\n",
      "weighted avg       0.96      0.96      0.96      4704\n",
      "\n",
      "Train: 16 [ 587/588 (100%)]  Loss: 0.3989 (0.0774)  Time: 0.187s,   42.68/s  (0.220s,   36.33/s)  LR: 1.399e-03  \n",
      "Conf Mat:\n",
      " [[1148   24    4]\n",
      " [  57 1720   12]\n",
      " [  49   36 1654]]\n",
      "Data: 0.000 (0.018)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         8\n",
      "   macro avg       0.33      0.33      0.33         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Test: [   0/79]  Time: 0.742 (0.742)  Loss:  0.5529 (0.5529)  \n",
      "Conf Mat:\n",
      " [[8 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95       369\n",
      "           1       0.59      0.97      0.74        39\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       408\n",
      "   macro avg       0.53      0.62      0.56       408\n",
      "weighted avg       0.96      0.91      0.93       408\n",
      "\n",
      "Test: [  50/79]  Time: 0.099 (0.172)  Loss:  0.5531 (0.6382)  \n",
      "Conf Mat:\n",
      " [[332   1   0]\n",
      " [ 26  38   0]\n",
      " [ 11   0   0]]\n",
      "Acc@1: 100.0000 (90.6863)  Acc@5: 100.0000 (100.0000)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93       369\n",
      "           1       0.84      0.91      0.88       169\n",
      "           2       0.89      0.97      0.93        96\n",
      "\n",
      "    accuracy                           0.91       634\n",
      "   macro avg       0.90      0.93      0.91       634\n",
      "weighted avg       0.92      0.91      0.91       634\n",
      "\n",
      "Test: [  79/79]  Time: 0.014 (0.166)  Loss:  0.5539 (0.6361)  \n",
      "Conf Mat:\n",
      " [[332  15   0]\n",
      " [ 26 154   3]\n",
      " [ 11   0  93]]\n",
      "Acc@1: 100.0000 (91.3249)  Acc@5: 100.0000 (100.0000)\n",
      "Current checkpoints:\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-11.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-15.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-13.pth.tar', 91.6403785488959)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-12.pth.tar', 91.4826498422713)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-8.pth.tar', 91.32492113564669)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-16.pth.tar', 91.32492113564669)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-14.pth.tar', 91.00946372239747)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-6.pth.tar', 90.53627760252365)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-7.pth.tar', 90.22082018927445)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-5.pth.tar', 89.74763406940063)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00         8\n",
      "   macro avg       1.00      1.00      1.00         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Train: 17 [   0/588 (  0%)]  Loss: 0.005375 (0.00538)  Time: 0.840s,    9.52/s  (0.840s,    9.52/s)  LR: 1.238e-03  \n",
      "Conf Mat:\n",
      " [[1 0 0]\n",
      " [0 2 0]\n",
      " [0 0 5]]\n",
      "Data: 0.647 (0.647)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95       111\n",
      "           1       0.96      0.98      0.97       146\n",
      "           2       0.96      1.00      0.98       151\n",
      "\n",
      "    accuracy                           0.97       408\n",
      "   macro avg       0.97      0.96      0.97       408\n",
      "weighted avg       0.97      0.97      0.97       408\n",
      "\n",
      "Train: 17 [  50/588 (  9%)]  Loss: 0.04309 (0.0671)  Time: 0.264s,   30.25/s  (0.237s,   33.70/s)  LR: 1.238e-03  \n",
      "Conf Mat:\n",
      " [[101   0   0]\n",
      " [  6 143   0]\n",
      " [  4   3 151]]\n",
      "Data: 0.023 (0.032)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       216\n",
      "           1       0.96      0.98      0.97       311\n",
      "           2       0.95      0.99      0.97       281\n",
      "\n",
      "    accuracy                           0.96       808\n",
      "   macro avg       0.97      0.96      0.96       808\n",
      "weighted avg       0.96      0.96      0.96       808\n",
      "\n",
      "Train: 17 [ 100/588 ( 17%)]  Loss: 0.001912 (0.0717)  Time: 0.202s,   39.52/s  (0.223s,   35.83/s)  LR: 1.238e-03  \n",
      "Conf Mat:\n",
      " [[197   1   1]\n",
      " [ 11 304   2]\n",
      " [  8   6 278]]\n",
      "Data: 0.009 (0.023)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95       324\n",
      "           1       0.96      0.98      0.97       464\n",
      "           2       0.96      0.99      0.98       420\n",
      "\n",
      "    accuracy                           0.97      1208\n",
      "   macro avg       0.97      0.96      0.97      1208\n",
      "weighted avg       0.97      0.97      0.97      1208\n",
      "\n",
      "Train: 17 [ 150/588 ( 26%)]  Loss: 0.05945 (0.0643)  Time: 0.209s,   38.33/s  (0.224s,   35.64/s)  LR: 1.238e-03  \n",
      "Conf Mat:\n",
      " [[300   3   2]\n",
      " [ 15 453   2]\n",
      " [  9   8 416]]\n",
      "Data: 0.010 (0.022)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       427\n",
      "           1       0.97      0.98      0.98       618\n",
      "           2       0.96      0.99      0.98       563\n",
      "\n",
      "    accuracy                           0.97      1608\n",
      "   macro avg       0.97      0.97      0.97      1608\n",
      "weighted avg       0.97      0.97      0.97      1608\n",
      "\n",
      "Train: 17 [ 200/588 ( 34%)]  Loss: 0.1426 (0.0604)  Time: 0.210s,   38.17/s  (0.225s,   35.56/s)  LR: 1.238e-03  \n",
      "Conf Mat:\n",
      " [[396   4   2]\n",
      " [ 17 606   2]\n",
      " [ 14   8 559]]\n",
      "Data: 0.005 (0.021)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       541\n",
      "           1       0.97      0.98      0.97       749\n",
      "           2       0.96      0.99      0.98       718\n",
      "\n",
      "    accuracy                           0.97      2008\n",
      "   macro avg       0.97      0.97      0.97      2008\n",
      "weighted avg       0.97      0.97      0.97      2008\n",
      "\n",
      "Train: 17 [ 250/588 ( 43%)]  Loss: 0.002964 (0.0603)  Time: 0.288s,   27.74/s  (0.224s,   35.64/s)  LR: 1.238e-03  \n",
      "Conf Mat:\n",
      " [[503   4   2]\n",
      " [ 22 734   2]\n",
      " [ 16  11 714]]\n",
      "Data: 0.041 (0.020)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       643\n",
      "           1       0.97      0.98      0.97       903\n",
      "           2       0.96      0.99      0.98       862\n",
      "\n",
      "    accuracy                           0.97      2408\n",
      "   macro avg       0.97      0.97      0.97      2408\n",
      "weighted avg       0.97      0.97      0.97      2408\n",
      "\n",
      "Train: 17 [ 300/588 ( 51%)]  Loss: 0.002419 (0.0619)  Time: 0.202s,   39.53/s  (0.223s,   35.94/s)  LR: 1.238e-03  \n",
      "Conf Mat:\n",
      " [[599   5   3]\n",
      " [ 25 882   2]\n",
      " [ 19  16 857]]\n",
      "Data: 0.011 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96       759\n",
      "           1       0.97      0.97      0.97      1046\n",
      "           2       0.96      0.99      0.97      1003\n",
      "\n",
      "    accuracy                           0.97      2808\n",
      "   macro avg       0.97      0.96      0.97      2808\n",
      "weighted avg       0.97      0.97      0.97      2808\n",
      "\n",
      "Train: 17 [ 350/588 ( 60%)]  Loss: 0.05957 (0.0721)  Time: 0.209s,   38.28/s  (0.224s,   35.77/s)  LR: 1.238e-03  \n",
      "Conf Mat:\n",
      " [[ 708    9    4]\n",
      " [  29 1016    7]\n",
      " [  22   21  992]]\n",
      "Data: 0.015 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95       858\n",
      "           1       0.96      0.97      0.97      1215\n",
      "           2       0.96      0.99      0.97      1135\n",
      "\n",
      "    accuracy                           0.97      3208\n",
      "   macro avg       0.97      0.96      0.96      3208\n",
      "weighted avg       0.97      0.97      0.97      3208\n",
      "\n",
      "Train: 17 [ 400/588 ( 68%)]  Loss: 0.1524 (0.0729)  Time: 0.243s,   32.95/s  (0.223s,   35.81/s)  LR: 1.238e-03  \n",
      "Conf Mat:\n",
      " [[ 795   11    4]\n",
      " [  35 1180    8]\n",
      " [  28   24 1123]]\n",
      "Data: 0.023 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95       974\n",
      "           1       0.96      0.97      0.97      1371\n",
      "           2       0.95      0.99      0.97      1263\n",
      "\n",
      "    accuracy                           0.97      3608\n",
      "   macro avg       0.97      0.96      0.96      3608\n",
      "weighted avg       0.97      0.97      0.96      3608\n",
      "\n",
      "Train: 17 [ 450/588 ( 77%)]  Loss: 0.1228 (0.0715)  Time: 0.221s,   36.22/s  (0.221s,   36.17/s)  LR: 1.238e-03  \n",
      "Conf Mat:\n",
      " [[ 900   14    4]\n",
      " [  41 1331    8]\n",
      " [  33   26 1251]]\n",
      "Data: 0.020 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95      1084\n",
      "           1       0.96      0.97      0.97      1504\n",
      "           2       0.96      0.99      0.97      1420\n",
      "\n",
      "    accuracy                           0.96      4008\n",
      "   macro avg       0.97      0.96      0.96      4008\n",
      "weighted avg       0.96      0.96      0.96      4008\n",
      "\n",
      "Train: 17 [ 500/588 ( 85%)]  Loss: 0.003763 (0.0741)  Time: 0.193s,   41.38/s  (0.221s,   36.14/s)  LR: 1.238e-03  \n",
      "Conf Mat:\n",
      " [[ 999   17    4]\n",
      " [  49 1458    9]\n",
      " [  36   29 1407]]\n",
      "Data: 0.006 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95      1183\n",
      "           1       0.96      0.97      0.97      1652\n",
      "           2       0.96      0.99      0.97      1573\n",
      "\n",
      "    accuracy                           0.96      4408\n",
      "   macro avg       0.97      0.96      0.96      4408\n",
      "weighted avg       0.96      0.96      0.96      4408\n",
      "\n",
      "Train: 17 [ 550/588 ( 94%)]  Loss: 0.006911 (0.0735)  Time: 0.207s,   38.65/s  (0.222s,   36.05/s)  LR: 1.238e-03  \n",
      "Conf Mat:\n",
      " [[1091   18    5]\n",
      " [  50 1603   10]\n",
      " [  42   31 1558]]\n",
      "Data: 0.010 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95      1255\n",
      "           1       0.96      0.97      0.97      1778\n",
      "           2       0.96      0.99      0.97      1671\n",
      "\n",
      "    accuracy                           0.97      4704\n",
      "   macro avg       0.97      0.96      0.96      4704\n",
      "weighted avg       0.97      0.97      0.96      4704\n",
      "\n",
      "Train: 17 [ 587/588 (100%)]  Loss: 0.05141 (0.0720)  Time: 0.188s,   42.66/s  (0.220s,   36.29/s)  LR: 1.238e-03  \n",
      "Conf Mat:\n",
      " [[1157   19    5]\n",
      " [  53 1727   10]\n",
      " [  45   32 1656]]\n",
      "Data: 0.000 (0.018)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         8\n",
      "   macro avg       0.33      0.33      0.33         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Test: [   0/79]  Time: 1.271 (1.271)  Loss:  0.5532 (0.5532)  \n",
      "Conf Mat:\n",
      " [[8 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       369\n",
      "           1       0.62      0.92      0.74        39\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       408\n",
      "   macro avg       0.54      0.61      0.56       408\n",
      "weighted avg       0.96      0.91      0.93       408\n",
      "\n",
      "Test: [  50/79]  Time: 0.066 (0.182)  Loss:  0.5572 (0.6364)  \n",
      "Conf Mat:\n",
      " [[336   2   0]\n",
      " [ 22  36   0]\n",
      " [ 11   1   0]]\n",
      "Acc@1: 100.0000 (91.1765)  Acc@5: 100.0000 (100.0000)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92       369\n",
      "           1       0.86      0.88      0.87       169\n",
      "           2       0.88      0.95      0.91        96\n",
      "\n",
      "    accuracy                           0.91       634\n",
      "   macro avg       0.89      0.91      0.90       634\n",
      "weighted avg       0.91      0.91      0.91       634\n",
      "\n",
      "Test: [  79/79]  Time: 0.015 (0.162)  Loss:  0.5517 (0.6408)  \n",
      "Conf Mat:\n",
      " [[336  20   2]\n",
      " [ 22 148   3]\n",
      " [ 11   1  91]]\n",
      "Acc@1: 100.0000 (90.6940)  Acc@5: 100.0000 (100.0000)\n",
      "Current checkpoints:\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-11.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-15.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-13.pth.tar', 91.6403785488959)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-12.pth.tar', 91.4826498422713)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-8.pth.tar', 91.32492113564669)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-16.pth.tar', 91.32492113564669)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-14.pth.tar', 91.00946372239747)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-17.pth.tar', 90.69400630914826)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-6.pth.tar', 90.53627760252365)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-7.pth.tar', 90.22082018927445)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "           2       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00         8\n",
      "   macro avg       1.00      1.00      1.00         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Train: 18 [   0/588 (  0%)]  Loss: 0.005428 (0.00543)  Time: 0.834s,    9.59/s  (0.834s,    9.59/s)  LR: 1.080e-03  \n",
      "Conf Mat:\n",
      " [[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 6]]\n",
      "Data: 0.648 (0.648)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       108\n",
      "           1       0.97      0.98      0.98       151\n",
      "           2       0.97      1.00      0.98       149\n",
      "\n",
      "    accuracy                           0.98       408\n",
      "   macro avg       0.98      0.97      0.97       408\n",
      "weighted avg       0.98      0.98      0.98       408\n",
      "\n",
      "Train: 18 [  50/588 (  9%)]  Loss: 0.02973 (0.0437)  Time: 0.200s,   39.97/s  (0.251s,   31.86/s)  LR: 1.080e-03  \n",
      "Conf Mat:\n",
      " [[101   1   0]\n",
      " [  4 148   0]\n",
      " [  3   2 149]]\n",
      "Data: 0.009 (0.044)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       207\n",
      "           1       0.98      0.98      0.98       311\n",
      "           2       0.97      1.00      0.98       290\n",
      "\n",
      "    accuracy                           0.98       808\n",
      "   macro avg       0.98      0.97      0.97       808\n",
      "weighted avg       0.98      0.98      0.98       808\n",
      "\n",
      "Train: 18 [ 100/588 ( 17%)]  Loss: 0.02769 (0.0503)  Time: 0.225s,   35.59/s  (0.239s,   33.48/s)  LR: 1.080e-03  \n",
      "Conf Mat:\n",
      " [[195   3   1]\n",
      " [  6 304   0]\n",
      " [  6   4 289]]\n",
      "Data: 0.019 (0.031)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       301\n",
      "           1       0.98      0.98      0.98       475\n",
      "           2       0.97      1.00      0.98       432\n",
      "\n",
      "    accuracy                           0.98      1208\n",
      "   macro avg       0.98      0.97      0.98      1208\n",
      "weighted avg       0.98      0.98      0.98      1208\n",
      "\n",
      "Train: 18 [ 150/588 ( 26%)]  Loss: 0.06958 (0.0454)  Time: 0.301s,   26.58/s  (0.229s,   34.88/s)  LR: 1.080e-03  \n",
      "Conf Mat:\n",
      " [[284   3   1]\n",
      " [  8 467   0]\n",
      " [  9   5 431]]\n",
      "Data: 0.036 (0.026)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       409\n",
      "           1       0.98      0.98      0.98       623\n",
      "           2       0.97      1.00      0.98       576\n",
      "\n",
      "    accuracy                           0.98      1608\n",
      "   macro avg       0.98      0.97      0.97      1608\n",
      "weighted avg       0.98      0.98      0.98      1608\n",
      "\n",
      "Train: 18 [ 200/588 ( 34%)]  Loss: 0.01452 (0.0466)  Time: 0.200s,   40.08/s  (0.227s,   35.20/s)  LR: 1.080e-03  \n",
      "Conf Mat:\n",
      " [[383   5   1]\n",
      " [ 15 612   0]\n",
      " [ 11   6 575]]\n",
      "Data: 0.012 (0.024)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95       527\n",
      "           1       0.97      0.98      0.97       774\n",
      "           2       0.97      1.00      0.98       707\n",
      "\n",
      "    accuracy                           0.97      2008\n",
      "   macro avg       0.97      0.97      0.97      2008\n",
      "weighted avg       0.97      0.97      0.97      2008\n",
      "\n",
      "Train: 18 [ 250/588 ( 43%)]  Loss: 0.04287 (0.0523)  Time: 0.210s,   38.13/s  (0.227s,   35.20/s)  LR: 1.080e-03  \n",
      "Conf Mat:\n",
      " [[491  10   1]\n",
      " [ 22 757   0]\n",
      " [ 14   7 706]]\n",
      "Data: 0.012 (0.023)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95       622\n",
      "           1       0.97      0.98      0.98       923\n",
      "           2       0.97      1.00      0.99       863\n",
      "\n",
      "    accuracy                           0.97      2408\n",
      "   macro avg       0.97      0.97      0.97      2408\n",
      "weighted avg       0.97      0.97      0.97      2408\n",
      "\n",
      "Train: 18 [ 300/588 ( 51%)]  Loss: 0.009496 (0.0519)  Time: 0.285s,   28.07/s  (0.226s,   35.45/s)  LR: 1.080e-03  \n",
      "Conf Mat:\n",
      " [[580  12   2]\n",
      " [ 26 904   0]\n",
      " [ 16   7 861]]\n",
      "Data: 0.025 (0.022)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95       736\n",
      "           1       0.97      0.98      0.98      1069\n",
      "           2       0.97      1.00      0.98      1003\n",
      "\n",
      "    accuracy                           0.97      2808\n",
      "   macro avg       0.97      0.97      0.97      2808\n",
      "weighted avg       0.97      0.97      0.97      2808\n",
      "\n",
      "Train: 18 [ 350/588 ( 60%)]  Loss: 0.01701 (0.0547)  Time: 0.193s,   41.47/s  (0.223s,   35.86/s)  LR: 1.080e-03  \n",
      "Conf Mat:\n",
      " [[ 684   13    2]\n",
      " [  30 1046    0]\n",
      " [  22   10 1001]]\n",
      "Data: 0.006 (0.020)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95       852\n",
      "           1       0.97      0.97      0.97      1209\n",
      "           2       0.97      1.00      0.98      1147\n",
      "\n",
      "    accuracy                           0.97      3208\n",
      "   macro avg       0.97      0.96      0.97      3208\n",
      "weighted avg       0.97      0.97      0.97      3208\n",
      "\n",
      "Train: 18 [ 400/588 ( 68%)]  Loss: 0.07852 (0.0630)  Time: 0.203s,   39.44/s  (0.224s,   35.76/s)  LR: 1.080e-03  \n",
      "Conf Mat:\n",
      " [[ 788   17    3]\n",
      " [  38 1178    2]\n",
      " [  26   14 1142]]\n",
      "Data: 0.019 (0.020)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95       957\n",
      "           1       0.97      0.98      0.97      1366\n",
      "           2       0.97      1.00      0.98      1285\n",
      "\n",
      "    accuracy                           0.97      3608\n",
      "   macro avg       0.97      0.97      0.97      3608\n",
      "weighted avg       0.97      0.97      0.97      3608\n",
      "\n",
      "Train: 18 [ 450/588 ( 77%)]  Loss: 0.1339 (0.0619)  Time: 0.211s,   37.87/s  (0.224s,   35.67/s)  LR: 1.080e-03  \n",
      "Conf Mat:\n",
      " [[ 888   18    3]\n",
      " [  43 1332    3]\n",
      " [  26   16 1279]]\n",
      "Data: 0.021 (0.020)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95      1063\n",
      "           1       0.97      0.97      0.97      1519\n",
      "           2       0.97      1.00      0.98      1426\n",
      "\n",
      "    accuracy                           0.97      4008\n",
      "   macro avg       0.97      0.97      0.97      4008\n",
      "weighted avg       0.97      0.97      0.97      4008\n",
      "\n",
      "Train: 18 [ 500/588 ( 85%)]  Loss: 0.05403 (0.0645)  Time: 0.263s,   30.40/s  (0.222s,   35.96/s)  LR: 1.080e-03  \n",
      "Conf Mat:\n",
      " [[ 985   21    3]\n",
      " [  48 1479    4]\n",
      " [  30   19 1419]]\n",
      "Data: 0.022 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95      1169\n",
      "           1       0.96      0.97      0.97      1678\n",
      "           2       0.96      0.99      0.98      1561\n",
      "\n",
      "    accuracy                           0.97      4408\n",
      "   macro avg       0.97      0.96      0.96      4408\n",
      "weighted avg       0.97      0.97      0.97      4408\n",
      "\n",
      "Train: 18 [ 550/588 ( 94%)]  Loss: 0.01955 (0.0668)  Time: 0.217s,   36.87/s  (0.222s,   36.08/s)  LR: 1.080e-03  \n",
      "Conf Mat:\n",
      " [[1078   23    3]\n",
      " [  57 1631    6]\n",
      " [  34   24 1552]]\n",
      "Data: 0.014 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95      1254\n",
      "           1       0.96      0.97      0.97      1780\n",
      "           2       0.96      0.99      0.98      1670\n",
      "\n",
      "    accuracy                           0.97      4704\n",
      "   macro avg       0.97      0.96      0.96      4704\n",
      "weighted avg       0.97      0.97      0.97      4704\n",
      "\n",
      "Train: 18 [ 587/588 (100%)]  Loss: 0.09334 (0.0673)  Time: 0.187s,   42.82/s  (0.222s,   35.99/s)  LR: 1.080e-03  \n",
      "Conf Mat:\n",
      " [[1158   24    3]\n",
      " [  59 1727    7]\n",
      " [  37   29 1660]]\n",
      "Data: 0.000 (0.019)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         8\n",
      "   macro avg       0.33      0.33      0.33         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Test: [   0/79]  Time: 0.770 (0.770)  Loss:  0.5523 (0.5523)  \n",
      "Conf Mat:\n",
      " [[8 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96       369\n",
      "           1       0.65      1.00      0.79        39\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       408\n",
      "   macro avg       0.55      0.64      0.58       408\n",
      "weighted avg       0.97      0.93      0.94       408\n",
      "\n",
      "Test: [  50/79]  Time: 0.060 (0.146)  Loss:  0.5543 (0.6294)  \n",
      "Conf Mat:\n",
      " [[339   0   0]\n",
      " [ 21  39   0]\n",
      " [  9   0   0]]\n",
      "Acc@1: 100.0000 (92.6471)  Acc@5: 100.0000 (100.0000)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94       369\n",
      "           1       0.87      0.91      0.89       169\n",
      "           2       0.91      0.95      0.93        96\n",
      "\n",
      "    accuracy                           0.92       634\n",
      "   macro avg       0.91      0.93      0.92       634\n",
      "weighted avg       0.92      0.92      0.92       634\n",
      "\n",
      "Test: [  79/79]  Time: 0.018 (0.150)  Loss:  0.5521 (0.6332)  \n",
      "Conf Mat:\n",
      " [[339  15   2]\n",
      " [ 21 154   3]\n",
      " [  9   0  91]]\n",
      "Acc@1: 100.0000 (92.1136)  Acc@5: 100.0000 (100.0000)\n",
      "Current checkpoints:\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-18.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-11.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-15.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-13.pth.tar', 91.6403785488959)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-12.pth.tar', 91.4826498422713)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-8.pth.tar', 91.32492113564669)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-16.pth.tar', 91.32492113564669)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-14.pth.tar', 91.00946372239747)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-17.pth.tar', 90.69400630914826)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-6.pth.tar', 90.53627760252365)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         4\n",
      "           2       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         8\n",
      "   macro avg       1.00      1.00      1.00         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Train: 19 [   0/588 (  0%)]  Loss: 0.006303 (0.00630)  Time: 1.381s,    5.79/s  (1.381s,    5.79/s)  LR: 9.270e-04  \n",
      "Conf Mat:\n",
      " [[2 0 0]\n",
      " [0 4 0]\n",
      " [0 0 2]]\n",
      "Data: 1.158 (1.158)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        98\n",
      "           1       1.00      0.99      1.00       150\n",
      "           2       0.96      1.00      0.98       160\n",
      "\n",
      "    accuracy                           0.98       408\n",
      "   macro avg       0.99      0.98      0.98       408\n",
      "weighted avg       0.98      0.98      0.98       408\n",
      "\n",
      "Train: 19 [  50/588 (  9%)]  Loss: 0.04144 (0.0425)  Time: 0.205s,   38.95/s  (0.235s,   34.11/s)  LR: 9.270e-04  \n",
      "Conf Mat:\n",
      " [[ 92   0   0]\n",
      " [  0 149   0]\n",
      " [  6   1 160]]\n",
      "Data: 0.015 (0.039)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       190\n",
      "           1       0.98      0.98      0.98       318\n",
      "           2       0.96      1.00      0.98       300\n",
      "\n",
      "    accuracy                           0.97       808\n",
      "   macro avg       0.98      0.96      0.97       808\n",
      "weighted avg       0.97      0.97      0.97       808\n",
      "\n",
      "Train: 19 [ 100/588 ( 17%)]  Loss: 0.03341 (0.0549)  Time: 0.212s,   37.72/s  (0.232s,   34.54/s)  LR: 9.270e-04  \n",
      "Conf Mat:\n",
      " [[173   2   0]\n",
      " [  6 313   0]\n",
      " [ 11   3 300]]\n",
      "Data: 0.020 (0.030)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       295\n",
      "           1       0.99      0.98      0.98       481\n",
      "           2       0.95      1.00      0.98       432\n",
      "\n",
      "    accuracy                           0.97      1208\n",
      "   macro avg       0.98      0.97      0.97      1208\n",
      "weighted avg       0.97      0.97      0.97      1208\n",
      "\n",
      "Train: 19 [ 150/588 ( 26%)]  Loss: 0.009680 (0.0550)  Time: 0.218s,   36.78/s  (0.230s,   34.79/s)  LR: 9.270e-04  \n",
      "Conf Mat:\n",
      " [[273   3   0]\n",
      " [  7 471   0]\n",
      " [ 15   7 432]]\n",
      "Data: 0.023 (0.026)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       397\n",
      "           1       0.98      0.98      0.98       636\n",
      "           2       0.95      0.99      0.97       575\n",
      "\n",
      "    accuracy                           0.97      1608\n",
      "   macro avg       0.97      0.97      0.97      1608\n",
      "weighted avg       0.97      0.97      0.97      1608\n",
      "\n",
      "Train: 19 [ 200/588 ( 34%)]  Loss: 0.03003 (0.0650)  Time: 0.288s,   27.78/s  (0.225s,   35.62/s)  LR: 9.270e-04  \n",
      "Conf Mat:\n",
      " [[368   4   0]\n",
      " [  9 623   5]\n",
      " [ 20   9 570]]\n",
      "Data: 0.031 (0.023)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95       511\n",
      "           1       0.98      0.98      0.98       778\n",
      "           2       0.95      0.99      0.97       719\n",
      "\n",
      "    accuracy                           0.97      2008\n",
      "   macro avg       0.97      0.97      0.97      2008\n",
      "weighted avg       0.97      0.97      0.97      2008\n",
      "\n",
      "Train: 19 [ 250/588 ( 43%)]  Loss: 0.04906 (0.0650)  Time: 0.204s,   39.19/s  (0.223s,   35.85/s)  LR: 9.270e-04  \n",
      "Conf Mat:\n",
      " [[471   5   0]\n",
      " [ 13 763   5]\n",
      " [ 27  10 714]]\n",
      "Data: 0.015 (0.022)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95       620\n",
      "           1       0.98      0.98      0.98       937\n",
      "           2       0.95      0.99      0.97       851\n",
      "\n",
      "    accuracy                           0.97      2408\n",
      "   macro avg       0.97      0.97      0.97      2408\n",
      "weighted avg       0.97      0.97      0.97      2408\n",
      "\n",
      "Train: 19 [ 300/588 ( 51%)]  Loss: 0.02752 (0.0631)  Time: 0.190s,   42.05/s  (0.224s,   35.68/s)  LR: 9.270e-04  \n",
      "Conf Mat:\n",
      " [[573  10   0]\n",
      " [ 17 916   5]\n",
      " [ 30  11 846]]\n",
      "Data: 0.006 (0.021)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95       736\n",
      "           1       0.97      0.98      0.97      1080\n",
      "           2       0.96      0.99      0.98       992\n",
      "\n",
      "    accuracy                           0.97      2808\n",
      "   macro avg       0.97      0.96      0.97      2808\n",
      "weighted avg       0.97      0.97      0.97      2808\n",
      "\n",
      "Train: 19 [ 350/588 ( 60%)]  Loss: 0.05368 (0.0623)  Time: 0.272s,   29.44/s  (0.223s,   35.82/s)  LR: 9.270e-04  \n",
      "Conf Mat:\n",
      " [[ 679   12    0]\n",
      " [  25 1055    5]\n",
      " [  32   13  987]]\n",
      "Data: 0.025 (0.020)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95       838\n",
      "           1       0.97      0.98      0.97      1210\n",
      "           2       0.96      0.99      0.98      1160\n",
      "\n",
      "    accuracy                           0.97      3208\n",
      "   macro avg       0.97      0.96      0.97      3208\n",
      "weighted avg       0.97      0.97      0.97      3208\n",
      "\n",
      "Train: 19 [ 400/588 ( 68%)]  Loss: 0.02328 (0.0621)  Time: 0.195s,   40.99/s  (0.221s,   36.19/s)  LR: 9.270e-04  \n",
      "Conf Mat:\n",
      " [[ 774   14    0]\n",
      " [  31 1181    6]\n",
      " [  33   15 1154]]\n",
      "Data: 0.006 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96       949\n",
      "           1       0.97      0.97      0.97      1368\n",
      "           2       0.96      1.00      0.98      1291\n",
      "\n",
      "    accuracy                           0.97      3608\n",
      "   macro avg       0.97      0.97      0.97      3608\n",
      "weighted avg       0.97      0.97      0.97      3608\n",
      "\n",
      "Train: 19 [ 450/588 ( 77%)]  Loss: 0.01450 (0.0634)  Time: 0.206s,   38.84/s  (0.222s,   36.08/s)  LR: 9.270e-04  \n",
      "Conf Mat:\n",
      " [[ 882   15    0]\n",
      " [  33 1333    6]\n",
      " [  34   20 1285]]\n",
      "Data: 0.012 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96      1062\n",
      "           1       0.97      0.98      0.97      1523\n",
      "           2       0.96      1.00      0.98      1423\n",
      "\n",
      "    accuracy                           0.97      4008\n",
      "   macro avg       0.97      0.97      0.97      4008\n",
      "weighted avg       0.97      0.97      0.97      4008\n",
      "\n",
      "Train: 19 [ 500/588 ( 85%)]  Loss: 0.009150 (0.0620)  Time: 0.220s,   36.35/s  (0.222s,   36.01/s)  LR: 9.270e-04  \n",
      "Conf Mat:\n",
      " [[ 990   16    0]\n",
      " [  34 1486    7]\n",
      " [  38   21 1416]]\n",
      "Data: 0.011 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96      1180\n",
      "           1       0.97      0.98      0.98      1672\n",
      "           2       0.96      0.99      0.98      1556\n",
      "\n",
      "    accuracy                           0.97      4408\n",
      "   macro avg       0.97      0.97      0.97      4408\n",
      "weighted avg       0.97      0.97      0.97      4408\n",
      "\n",
      "Train: 19 [ 550/588 ( 94%)]  Loss: 0.004703 (0.0618)  Time: 0.260s,   30.80/s  (0.221s,   36.17/s)  LR: 9.270e-04  \n",
      "Conf Mat:\n",
      " [[1099   16    1]\n",
      " [  35 1633    7]\n",
      " [  46   23 1548]]\n",
      "Data: 0.022 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96      1254\n",
      "           1       0.98      0.98      0.98      1779\n",
      "           2       0.96      0.99      0.98      1671\n",
      "\n",
      "    accuracy                           0.97      4704\n",
      "   macro avg       0.97      0.97      0.97      4704\n",
      "weighted avg       0.97      0.97      0.97      4704\n",
      "\n",
      "Train: 19 [ 587/588 (100%)]  Loss: 0.1971 (0.0620)  Time: 0.186s,   42.93/s  (0.221s,   36.27/s)  LR: 9.270e-04  \n",
      "Conf Mat:\n",
      " [[1170   19    1]\n",
      " [  36 1736    8]\n",
      " [  48   24 1662]]\n",
      "Data: 0.000 (0.018)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         8\n",
      "   macro avg       0.33      0.33      0.33         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Test: [   0/79]  Time: 0.651 (0.651)  Loss:  0.5523 (0.5523)  \n",
      "Conf Mat:\n",
      " [[8 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       369\n",
      "           1       0.69      0.97      0.81        39\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       408\n",
      "   macro avg       0.56      0.63      0.59       408\n",
      "weighted avg       0.97      0.93      0.95       408\n",
      "\n",
      "Test: [  50/79]  Time: 0.080 (0.180)  Loss:  0.5577 (0.6232)  \n",
      "Conf Mat:\n",
      " [[342   1   0]\n",
      " [ 17  38   0]\n",
      " [ 10   0   0]]\n",
      "Acc@1: 100.0000 (93.1373)  Acc@5: 100.0000 (100.0000)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       369\n",
      "           1       0.88      0.89      0.89       169\n",
      "           2       0.89      0.95      0.92        96\n",
      "\n",
      "    accuracy                           0.92       634\n",
      "   macro avg       0.91      0.92      0.91       634\n",
      "weighted avg       0.92      0.92      0.92       634\n",
      "\n",
      "Test: [  79/79]  Time: 0.014 (0.165)  Loss:  0.5519 (0.6301)  \n",
      "Conf Mat:\n",
      " [[342  17   2]\n",
      " [ 17 151   3]\n",
      " [ 10   1  91]]\n",
      "Acc@1: 100.0000 (92.1136)  Acc@5: 100.0000 (100.0000)\n",
      "Current checkpoints:\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-18.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-19.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-11.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-15.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-13.pth.tar', 91.6403785488959)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-12.pth.tar', 91.4826498422713)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-8.pth.tar', 91.32492113564669)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-16.pth.tar', 91.32492113564669)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-14.pth.tar', 91.00946372239747)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-17.pth.tar', 90.69400630914826)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00         8\n",
      "   macro avg       1.00      1.00      1.00         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Train: 20 [   0/588 (  0%)]  Loss: 0.03031 (0.0303)  Time: 0.885s,    9.04/s  (0.885s,    9.04/s)  LR: 7.813e-04  \n",
      "Conf Mat:\n",
      " [[1 0 0]\n",
      " [0 3 0]\n",
      " [0 0 4]]\n",
      "Data: 0.692 (0.692)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       117\n",
      "           1       0.97      0.96      0.97       149\n",
      "           2       0.95      0.99      0.97       142\n",
      "\n",
      "    accuracy                           0.96       408\n",
      "   macro avg       0.96      0.96      0.96       408\n",
      "weighted avg       0.96      0.96      0.96       408\n",
      "\n",
      "Train: 20 [  50/588 (  9%)]  Loss: 0.004450 (0.0789)  Time: 0.256s,   31.25/s  (0.244s,   32.79/s)  LR: 7.813e-04  \n",
      "Conf Mat:\n",
      " [[110   3   1]\n",
      " [  3 143   1]\n",
      " [  4   3 140]]\n",
      "Data: 0.019 (0.034)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       226\n",
      "           1       0.98      0.97      0.98       304\n",
      "           2       0.96      0.99      0.98       278\n",
      "\n",
      "    accuracy                           0.97       808\n",
      "   macro avg       0.97      0.97      0.97       808\n",
      "weighted avg       0.97      0.97      0.97       808\n",
      "\n",
      "Train: 20 [ 100/588 ( 17%)]  Loss: 0.01152 (0.0699)  Time: 0.267s,   29.95/s  (0.226s,   35.44/s)  LR: 7.813e-04  \n",
      "Conf Mat:\n",
      " [[212   4   1]\n",
      " [  6 296   1]\n",
      " [  8   4 276]]\n",
      "Data: 0.031 (0.024)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       333\n",
      "           1       0.98      0.98      0.98       442\n",
      "           2       0.96      0.99      0.98       433\n",
      "\n",
      "    accuracy                           0.97      1208\n",
      "   macro avg       0.97      0.97      0.97      1208\n",
      "weighted avg       0.97      0.97      0.97      1208\n",
      "\n",
      "Train: 20 [ 150/588 ( 26%)]  Loss: 0.2810 (0.0608)  Time: 0.221s,   36.17/s  (0.225s,   35.48/s)  LR: 7.813e-04  \n",
      "Conf Mat:\n",
      " [[314   4   1]\n",
      " [  8 432   2]\n",
      " [ 11   6 430]]\n",
      "Data: 0.034 (0.022)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96       440\n",
      "           1       0.97      0.98      0.98       589\n",
      "           2       0.96      0.99      0.98       579\n",
      "\n",
      "    accuracy                           0.97      1608\n",
      "   macro avg       0.97      0.97      0.97      1608\n",
      "weighted avg       0.97      0.97      0.97      1608\n",
      "\n",
      "Train: 20 [ 200/588 ( 34%)]  Loss: 0.03200 (0.0608)  Time: 0.215s,   37.21/s  (0.226s,   35.47/s)  LR: 7.813e-04  \n",
      "Conf Mat:\n",
      " [[411   6   2]\n",
      " [ 12 576   3]\n",
      " [ 17   7 574]]\n",
      "Data: 0.019 (0.021)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96       535\n",
      "           1       0.97      0.97      0.97       748\n",
      "           2       0.96      0.99      0.97       725\n",
      "\n",
      "    accuracy                           0.97      2008\n",
      "   macro avg       0.97      0.97      0.97      2008\n",
      "weighted avg       0.97      0.97      0.97      2008\n",
      "\n",
      "Train: 20 [ 250/588 ( 43%)]  Loss: 0.006248 (0.0633)  Time: 0.258s,   30.97/s  (0.223s,   35.85/s)  LR: 7.813e-04  \n",
      "Conf Mat:\n",
      " [[499   8   2]\n",
      " [ 16 727   3]\n",
      " [ 20  13 720]]\n",
      "Data: 0.030 (0.020)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       642\n",
      "           1       0.97      0.97      0.97       895\n",
      "           2       0.96      0.99      0.98       871\n",
      "\n",
      "    accuracy                           0.97      2408\n",
      "   macro avg       0.97      0.97      0.97      2408\n",
      "weighted avg       0.97      0.97      0.97      2408\n",
      "\n",
      "Train: 20 [ 300/588 ( 51%)]  Loss: 0.3292 (0.0633)  Time: 0.202s,   39.55/s  (0.221s,   36.12/s)  LR: 7.813e-04  \n",
      "Conf Mat:\n",
      " [[602  10   2]\n",
      " [ 19 868   4]\n",
      " [ 21  17 865]]\n",
      "Data: 0.015 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       738\n",
      "           1       0.98      0.97      0.97      1055\n",
      "           2       0.95      0.99      0.97      1015\n",
      "\n",
      "    accuracy                           0.97      2808\n",
      "   macro avg       0.97      0.97      0.97      2808\n",
      "weighted avg       0.97      0.97      0.97      2808\n",
      "\n",
      "Train: 20 [ 350/588 ( 60%)]  Loss: 0.07296 (0.0695)  Time: 0.207s,   38.58/s  (0.222s,   35.98/s)  LR: 7.813e-04  \n",
      "Conf Mat:\n",
      " [[ 692   11    5]\n",
      " [  20 1022    5]\n",
      " [  26   22 1005]]\n",
      "Data: 0.013 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95       860\n",
      "           1       0.97      0.97      0.97      1181\n",
      "           2       0.95      0.99      0.97      1167\n",
      "\n",
      "    accuracy                           0.97      3208\n",
      "   macro avg       0.97      0.96      0.97      3208\n",
      "weighted avg       0.97      0.97      0.97      3208\n",
      "\n",
      "Train: 20 [ 400/588 ( 68%)]  Loss: 0.01628 (0.0693)  Time: 0.267s,   29.95/s  (0.222s,   36.00/s)  LR: 7.813e-04  \n",
      "Conf Mat:\n",
      " [[ 802   12    6]\n",
      " [  25 1147    6]\n",
      " [  33   22 1155]]\n",
      "Data: 0.026 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96       977\n",
      "           1       0.97      0.97      0.97      1348\n",
      "           2       0.96      0.99      0.97      1283\n",
      "\n",
      "    accuracy                           0.97      3608\n",
      "   macro avg       0.97      0.97      0.97      3608\n",
      "weighted avg       0.97      0.97      0.97      3608\n",
      "\n",
      "Train: 20 [ 450/588 ( 77%)]  Loss: 0.001664 (0.0680)  Time: 0.237s,   33.81/s  (0.220s,   36.38/s)  LR: 7.813e-04  \n",
      "Conf Mat:\n",
      " [[ 912   13    6]\n",
      " [  30 1311    6]\n",
      " [  35   24 1271]]\n",
      "Data: 0.025 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96      1077\n",
      "           1       0.97      0.97      0.97      1503\n",
      "           2       0.96      0.99      0.97      1428\n",
      "\n",
      "    accuracy                           0.97      4008\n",
      "   macro avg       0.97      0.97      0.97      4008\n",
      "weighted avg       0.97      0.97      0.97      4008\n",
      "\n",
      "Train: 20 [ 500/588 ( 85%)]  Loss: 0.08024 (0.0668)  Time: 0.203s,   39.42/s  (0.221s,   36.27/s)  LR: 7.813e-04  \n",
      "Conf Mat:\n",
      " [[1006   14    6]\n",
      " [  33 1462    7]\n",
      " [  38   27 1415]]\n",
      "Data: 0.013 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96      1186\n",
      "           1       0.97      0.97      0.97      1649\n",
      "           2       0.96      0.99      0.97      1573\n",
      "\n",
      "    accuracy                           0.97      4408\n",
      "   macro avg       0.97      0.97      0.97      4408\n",
      "weighted avg       0.97      0.97      0.97      4408\n",
      "\n",
      "Train: 20 [ 550/588 ( 94%)]  Loss: 0.003456 (0.0674)  Time: 0.225s,   35.63/s  (0.221s,   36.16/s)  LR: 7.813e-04  \n",
      "Conf Mat:\n",
      " [[1108   15    6]\n",
      " [  36 1603    8]\n",
      " [  42   31 1559]]\n",
      "Data: 0.028 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96      1255\n",
      "           1       0.97      0.97      0.97      1779\n",
      "           2       0.96      0.99      0.97      1670\n",
      "\n",
      "    accuracy                           0.97      4704\n",
      "   macro avg       0.97      0.97      0.97      4704\n",
      "weighted avg       0.97      0.97      0.97      4704\n",
      "\n",
      "Train: 20 [ 587/588 (100%)]  Loss: 0.006772 (0.0674)  Time: 0.188s,   42.59/s  (0.220s,   36.38/s)  LR: 7.813e-04  \n",
      "Conf Mat:\n",
      " [[1171   16    6]\n",
      " [  40 1731    9]\n",
      " [  44   32 1655]]\n",
      "Data: 0.000 (0.017)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         8\n",
      "   macro avg       0.33      0.33      0.33         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Test: [   0/79]  Time: 1.243 (1.243)  Loss:  0.5521 (0.5521)  \n",
      "Conf Mat:\n",
      " [[8 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       369\n",
      "           1       0.69      0.97      0.81        39\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       408\n",
      "   macro avg       0.56      0.63      0.59       408\n",
      "weighted avg       0.97      0.93      0.95       408\n",
      "\n",
      "Test: [  50/79]  Time: 0.066 (0.187)  Loss:  0.5594 (0.6195)  \n",
      "Conf Mat:\n",
      " [[342   1   0]\n",
      " [ 17  38   0]\n",
      " [ 10   0   0]]\n",
      "Acc@1: 100.0000 (93.1373)  Acc@5: 100.0000 (100.0000)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       369\n",
      "           1       0.88      0.88      0.88       169\n",
      "           2       0.89      0.95      0.92        96\n",
      "\n",
      "    accuracy                           0.92       634\n",
      "   macro avg       0.91      0.92      0.91       634\n",
      "weighted avg       0.92      0.92      0.92       634\n",
      "\n",
      "Test: [  79/79]  Time: 0.014 (0.166)  Loss:  0.5518 (0.6319)  \n",
      "Conf Mat:\n",
      " [[342  19   2]\n",
      " [ 17 149   3]\n",
      " [ 10   1  91]]\n",
      "Acc@1: 100.0000 (91.7981)  Acc@5: 100.0000 (100.0000)\n",
      "Current checkpoints:\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-18.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-19.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-11.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-15.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-20.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-13.pth.tar', 91.6403785488959)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-12.pth.tar', 91.4826498422713)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-8.pth.tar', 91.32492113564669)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-16.pth.tar', 91.32492113564669)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-14.pth.tar', 91.00946372239747)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       1.00      1.00      1.00         5\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         8\n",
      "   macro avg       0.67      0.67      0.67         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Train: 21 [   0/588 (  0%)]  Loss: 0.02476 (0.0248)  Time: 0.834s,    9.59/s  (0.834s,    9.59/s)  LR: 6.441e-04  \n",
      "Conf Mat:\n",
      " [[0 0 0]\n",
      " [0 3 0]\n",
      " [0 0 5]]\n",
      "Data: 0.634 (0.634)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97       112\n",
      "           1       0.97      1.00      0.98       153\n",
      "           2       0.99      0.99      0.99       143\n",
      "\n",
      "    accuracy                           0.98       408\n",
      "   macro avg       0.98      0.98      0.98       408\n",
      "weighted avg       0.98      0.98      0.98       408\n",
      "\n",
      "Train: 21 [  50/588 (  9%)]  Loss: 0.0002601 (0.0353)  Time: 0.199s,   40.17/s  (0.251s,   31.82/s)  LR: 6.441e-04  \n",
      "Conf Mat:\n",
      " [[106   0   0]\n",
      " [  4 153   1]\n",
      " [  2   0 142]]\n",
      "Data: 0.011 (0.044)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97       213\n",
      "           1       0.98      0.98      0.98       298\n",
      "           2       0.97      1.00      0.98       297\n",
      "\n",
      "    accuracy                           0.98       808\n",
      "   macro avg       0.98      0.97      0.98       808\n",
      "weighted avg       0.98      0.98      0.98       808\n",
      "\n",
      "Train: 21 [ 100/588 ( 17%)]  Loss: 0.04098 (0.0516)  Time: 0.227s,   35.18/s  (0.240s,   33.34/s)  LR: 6.441e-04  \n",
      "Conf Mat:\n",
      " [[201   2   0]\n",
      " [  6 293   1]\n",
      " [  6   3 296]]\n",
      "Data: 0.018 (0.032)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       317\n",
      "           1       0.98      0.97      0.97       447\n",
      "           2       0.96      0.99      0.98       444\n",
      "\n",
      "    accuracy                           0.97      1208\n",
      "   macro avg       0.98      0.97      0.97      1208\n",
      "weighted avg       0.97      0.97      0.97      1208\n",
      "\n",
      "Train: 21 [ 150/588 ( 26%)]  Loss: 0.1032 (0.0716)  Time: 0.254s,   31.51/s  (0.229s,   34.89/s)  LR: 6.441e-04  \n",
      "Conf Mat:\n",
      " [[301   4   0]\n",
      " [  7 435   4]\n",
      " [  9   8 440]]\n",
      "Data: 0.017 (0.025)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       409\n",
      "           1       0.98      0.97      0.98       607\n",
      "           2       0.97      0.99      0.98       592\n",
      "\n",
      "    accuracy                           0.98      1608\n",
      "   macro avg       0.98      0.97      0.97      1608\n",
      "weighted avg       0.98      0.98      0.98      1608\n",
      "\n",
      "Train: 21 [ 200/588 ( 34%)]  Loss: 0.01671 (0.0687)  Time: 0.194s,   41.16/s  (0.227s,   35.18/s)  LR: 6.441e-04  \n",
      "Conf Mat:\n",
      " [[391   7   0]\n",
      " [  8 589   4]\n",
      " [ 10  11 588]]\n",
      "Data: 0.006 (0.023)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       508\n",
      "           1       0.98      0.98      0.98       752\n",
      "           2       0.97      0.99      0.98       748\n",
      "\n",
      "    accuracy                           0.98      2008\n",
      "   macro avg       0.98      0.97      0.97      2008\n",
      "weighted avg       0.98      0.98      0.98      2008\n",
      "\n",
      "Train: 21 [ 250/588 ( 43%)]  Loss: 0.06470 (0.0646)  Time: 0.190s,   42.02/s  (0.228s,   35.14/s)  LR: 6.441e-04  \n",
      "Conf Mat:\n",
      " [[481   7   0]\n",
      " [ 14 734   4]\n",
      " [ 13  11 744]]\n",
      "Data: 0.004 (0.022)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       610\n",
      "           1       0.98      0.97      0.98       915\n",
      "           2       0.96      0.99      0.98       883\n",
      "\n",
      "    accuracy                           0.97      2408\n",
      "   macro avg       0.98      0.97      0.97      2408\n",
      "weighted avg       0.97      0.97      0.97      2408\n",
      "\n",
      "Train: 21 [ 300/588 ( 51%)]  Loss: 0.03957 (0.0656)  Time: 0.267s,   29.96/s  (0.226s,   35.37/s)  LR: 6.441e-04  \n",
      "Conf Mat:\n",
      " [[578   8   0]\n",
      " [ 15 892   6]\n",
      " [ 17  15 877]]\n",
      "Data: 0.017 (0.021)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       718\n",
      "           1       0.98      0.97      0.98      1059\n",
      "           2       0.97      0.99      0.98      1031\n",
      "\n",
      "    accuracy                           0.97      2808\n",
      "   macro avg       0.98      0.97      0.97      2808\n",
      "weighted avg       0.97      0.97      0.97      2808\n",
      "\n",
      "Train: 21 [ 350/588 ( 60%)]  Loss: 0.01028 (0.0639)  Time: 0.197s,   40.51/s  (0.223s,   35.87/s)  LR: 6.441e-04  \n",
      "Conf Mat:\n",
      " [[ 681    9    0]\n",
      " [  18 1032    7]\n",
      " [  19   18 1024]]\n",
      "Data: 0.010 (0.020)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97       851\n",
      "           1       0.98      0.97      0.97      1189\n",
      "           2       0.96      0.99      0.98      1168\n",
      "\n",
      "    accuracy                           0.97      3208\n",
      "   macro avg       0.98      0.97      0.97      3208\n",
      "weighted avg       0.97      0.97      0.97      3208\n",
      "\n",
      "Train: 21 [ 400/588 ( 68%)]  Loss: 0.2697 (0.0646)  Time: 0.215s,   37.12/s  (0.224s,   35.67/s)  LR: 6.441e-04  \n",
      "Conf Mat:\n",
      " [[ 804    9    0]\n",
      " [  22 1158    7]\n",
      " [  25   22 1161]]\n",
      "Data: 0.017 (0.020)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       939\n",
      "           1       0.98      0.97      0.98      1352\n",
      "           2       0.96      0.99      0.98      1317\n",
      "\n",
      "    accuracy                           0.97      3608\n",
      "   macro avg       0.97      0.97      0.97      3608\n",
      "weighted avg       0.97      0.97      0.97      3608\n",
      "\n",
      "Train: 21 [ 450/588 ( 77%)]  Loss: 0.1113 (0.0633)  Time: 0.197s,   40.66/s  (0.225s,   35.63/s)  LR: 6.441e-04  \n",
      "Conf Mat:\n",
      " [[ 885   12    0]\n",
      " [  24 1317    7]\n",
      " [  30   23 1310]]\n",
      "Data: 0.006 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96      1058\n",
      "           1       0.98      0.98      0.98      1505\n",
      "           2       0.96      1.00      0.98      1445\n",
      "\n",
      "    accuracy                           0.97      4008\n",
      "   macro avg       0.97      0.97      0.97      4008\n",
      "weighted avg       0.97      0.97      0.97      4008\n",
      "\n",
      "Train: 21 [ 500/588 ( 85%)]  Loss: 0.007355 (0.0622)  Time: 0.283s,   28.28/s  (0.223s,   35.85/s)  LR: 6.441e-04  \n",
      "Conf Mat:\n",
      " [[ 993   12    0]\n",
      " [  28 1470    7]\n",
      " [  37   23 1438]]\n",
      "Data: 0.033 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96      1176\n",
      "           1       0.98      0.98      0.98      1660\n",
      "           2       0.96      1.00      0.98      1572\n",
      "\n",
      "    accuracy                           0.97      4408\n",
      "   macro avg       0.97      0.97      0.97      4408\n",
      "weighted avg       0.97      0.97      0.97      4408\n",
      "\n",
      "Train: 21 [ 550/588 ( 94%)]  Loss: 0.03810 (0.0617)  Time: 0.210s,   38.13/s  (0.222s,   36.03/s)  LR: 6.441e-04  \n",
      "Conf Mat:\n",
      " [[1100   12    0]\n",
      " [  33 1625    7]\n",
      " [  43   23 1565]]\n",
      "Data: 0.016 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96      1254\n",
      "           1       0.98      0.98      0.98      1779\n",
      "           2       0.96      1.00      0.98      1671\n",
      "\n",
      "    accuracy                           0.97      4704\n",
      "   macro avg       0.98      0.97      0.97      4704\n",
      "weighted avg       0.97      0.97      0.97      4704\n",
      "\n",
      "Train: 21 [ 587/588 (100%)]  Loss: 0.002370 (0.0600)  Time: 0.186s,   42.92/s  (0.223s,   35.93/s)  LR: 6.441e-04  \n",
      "Conf Mat:\n",
      " [[1175   13    0]\n",
      " [  33 1742    8]\n",
      " [  46   24 1663]]\n",
      "Data: 0.000 (0.018)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         8\n",
      "   macro avg       0.33      0.33      0.33         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Test: [   0/79]  Time: 0.728 (0.728)  Loss:  0.5525 (0.5525)  \n",
      "Conf Mat:\n",
      " [[8 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96       369\n",
      "           1       0.67      1.00      0.80        39\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       408\n",
      "   macro avg       0.56      0.64      0.59       408\n",
      "weighted avg       0.97      0.93      0.94       408\n",
      "\n",
      "Test: [  50/79]  Time: 0.073 (0.147)  Loss:  0.5538 (0.6229)  \n",
      "Conf Mat:\n",
      " [[339   0   0]\n",
      " [ 19  39   0]\n",
      " [ 11   0   0]]\n",
      "Acc@1: 100.0000 (92.6471)  Acc@5: 100.0000 (100.0000)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94       369\n",
      "           1       0.88      0.91      0.89       169\n",
      "           2       0.89      0.95      0.92        96\n",
      "\n",
      "    accuracy                           0.92       634\n",
      "   macro avg       0.91      0.93      0.92       634\n",
      "weighted avg       0.92      0.92      0.92       634\n",
      "\n",
      "Test: [  79/79]  Time: 0.020 (0.161)  Loss:  0.5519 (0.6270)  \n",
      "Conf Mat:\n",
      " [[339  15   2]\n",
      " [ 19 154   3]\n",
      " [ 11   0  91]]\n",
      "Acc@1: 100.0000 (92.1136)  Acc@5: 100.0000 (100.0000)\n",
      "Current checkpoints:\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-18.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-19.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-21.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-11.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-15.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-20.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-13.pth.tar', 91.6403785488959)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-12.pth.tar', 91.4826498422713)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-8.pth.tar', 91.32492113564669)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-16.pth.tar', 91.32492113564669)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         8\n",
      "   macro avg       1.00      1.00      1.00         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Train: 22 [   0/588 (  0%)]  Loss: 0.01852 (0.0185)  Time: 0.969s,    8.26/s  (0.969s,    8.26/s)  LR: 5.170e-04  \n",
      "Conf Mat:\n",
      " [[3 0 0]\n",
      " [0 2 0]\n",
      " [0 0 3]]\n",
      "Data: 0.751 (0.751)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       115\n",
      "           1       0.99      0.97      0.98       147\n",
      "           2       0.96      1.00      0.98       146\n",
      "\n",
      "    accuracy                           0.98       408\n",
      "   macro avg       0.98      0.98      0.98       408\n",
      "weighted avg       0.98      0.98      0.98       408\n",
      "\n",
      "Train: 22 [  50/588 (  9%)]  Loss: 0.01240 (0.0475)  Time: 0.237s,   33.78/s  (0.223s,   35.92/s)  LR: 5.170e-04  \n",
      "Conf Mat:\n",
      " [[111   0   0]\n",
      " [  2 143   0]\n",
      " [  2   4 146]]\n",
      "Data: 0.019 (0.029)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       231\n",
      "           1       0.98      0.98      0.98       313\n",
      "           2       0.96      0.99      0.97       264\n",
      "\n",
      "    accuracy                           0.98       808\n",
      "   macro avg       0.98      0.98      0.98       808\n",
      "weighted avg       0.98      0.98      0.98       808\n",
      "\n",
      "Train: 22 [ 100/588 ( 17%)]  Loss: 0.004324 (0.0550)  Time: 0.217s,   36.85/s  (0.224s,   35.74/s)  LR: 5.170e-04  \n",
      "Conf Mat:\n",
      " [[221   1   0]\n",
      " [  4 306   2]\n",
      " [  6   6 262]]\n",
      "Data: 0.021 (0.023)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97       346\n",
      "           1       0.97      0.98      0.98       454\n",
      "           2       0.96      1.00      0.98       408\n",
      "\n",
      "    accuracy                           0.97      1208\n",
      "   macro avg       0.98      0.97      0.97      1208\n",
      "weighted avg       0.97      0.97      0.97      1208\n",
      "\n",
      "Train: 22 [ 150/588 ( 26%)]  Loss: 0.02950 (0.0560)  Time: 0.208s,   38.37/s  (0.226s,   35.38/s)  LR: 5.170e-04  \n",
      "Conf Mat:\n",
      " [[326   2   0]\n",
      " [ 10 445   2]\n",
      " [ 10   7 406]]\n",
      "Data: 0.013 (0.022)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       440\n",
      "           1       0.97      0.97      0.97       595\n",
      "           2       0.96      0.99      0.98       573\n",
      "\n",
      "    accuracy                           0.97      1608\n",
      "   macro avg       0.98      0.97      0.97      1608\n",
      "weighted avg       0.97      0.97      0.97      1608\n",
      "\n",
      "Train: 22 [ 200/588 ( 34%)]  Loss: 0.08235 (0.0599)  Time: 0.289s,   27.69/s  (0.224s,   35.66/s)  LR: 5.170e-04  \n",
      "Conf Mat:\n",
      " [[417   3   1]\n",
      " [ 13 579   2]\n",
      " [ 10  13 570]]\n",
      "Data: 0.027 (0.020)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       554\n",
      "           1       0.97      0.98      0.98       738\n",
      "           2       0.96      0.99      0.98       716\n",
      "\n",
      "    accuracy                           0.98      2008\n",
      "   macro avg       0.98      0.97      0.97      2008\n",
      "weighted avg       0.98      0.98      0.98      2008\n",
      "\n",
      "Train: 22 [ 250/588 ( 43%)]  Loss: 0.2528 (0.0579)  Time: 0.215s,   37.27/s  (0.221s,   36.13/s)  LR: 5.170e-04  \n",
      "Conf Mat:\n",
      " [[525   3   2]\n",
      " [ 17 721   2]\n",
      " [ 12  14 712]]\n",
      "Data: 0.013 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97       660\n",
      "           1       0.98      0.98      0.98       895\n",
      "           2       0.96      0.99      0.98       853\n",
      "\n",
      "    accuracy                           0.97      2408\n",
      "   macro avg       0.98      0.97      0.97      2408\n",
      "weighted avg       0.97      0.97      0.97      2408\n",
      "\n",
      "Train: 22 [ 300/588 ( 51%)]  Loss: 0.007685 (0.0566)  Time: 0.201s,   39.72/s  (0.222s,   35.96/s)  LR: 5.170e-04  \n",
      "Conf Mat:\n",
      " [[623   4   3]\n",
      " [ 19 876   2]\n",
      " [ 18  15 848]]\n",
      "Data: 0.013 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       751\n",
      "           1       0.98      0.98      0.98      1039\n",
      "           2       0.96      1.00      0.98      1018\n",
      "\n",
      "    accuracy                           0.97      2808\n",
      "   macro avg       0.98      0.97      0.97      2808\n",
      "weighted avg       0.97      0.97      0.97      2808\n",
      "\n",
      "Train: 22 [ 350/588 ( 60%)]  Loss: 0.5020 (0.0568)  Time: 0.207s,   38.58/s  (0.223s,   35.89/s)  LR: 5.170e-04  \n",
      "Conf Mat:\n",
      " [[ 708    7    3]\n",
      " [  22 1014    2]\n",
      " [  21   18 1013]]\n",
      "Data: 0.012 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       865\n",
      "           1       0.98      0.98      0.98      1178\n",
      "           2       0.96      0.99      0.98      1165\n",
      "\n",
      "    accuracy                           0.97      3208\n",
      "   macro avg       0.98      0.97      0.97      3208\n",
      "weighted avg       0.97      0.97      0.97      3208\n",
      "\n",
      "Train: 22 [ 400/588 ( 68%)]  Loss: 0.003631 (0.0558)  Time: 0.305s,   26.23/s  (0.221s,   36.22/s)  LR: 5.170e-04  \n",
      "Conf Mat:\n",
      " [[ 815    8    3]\n",
      " [  26 1151    3]\n",
      " [  24   19 1159]]\n",
      "Data: 0.022 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       965\n",
      "           1       0.98      0.98      0.98      1336\n",
      "           2       0.97      0.99      0.98      1307\n",
      "\n",
      "    accuracy                           0.97      3608\n",
      "   macro avg       0.98      0.97      0.97      3608\n",
      "weighted avg       0.97      0.97      0.97      3608\n",
      "\n",
      "Train: 22 [ 450/588 ( 77%)]  Loss: 0.1804 (0.0563)  Time: 0.200s,   40.04/s  (0.220s,   36.29/s)  LR: 5.170e-04  \n",
      "Conf Mat:\n",
      " [[ 910    9    4]\n",
      " [  29 1307    4]\n",
      " [  26   20 1299]]\n",
      "Data: 0.012 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96      1065\n",
      "           1       0.97      0.98      0.98      1502\n",
      "           2       0.97      0.99      0.98      1441\n",
      "\n",
      "    accuracy                           0.97      4008\n",
      "   macro avg       0.97      0.97      0.97      4008\n",
      "weighted avg       0.97      0.97      0.97      4008\n",
      "\n",
      "Train: 22 [ 500/588 ( 85%)]  Loss: 0.0005253 (0.0573)  Time: 0.203s,   39.45/s  (0.221s,   36.17/s)  LR: 5.170e-04  \n",
      "Conf Mat:\n",
      " [[1004   10    5]\n",
      " [  35 1468    5]\n",
      " [  26   24 1431]]\n",
      "Data: 0.016 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96      1185\n",
      "           1       0.97      0.98      0.97      1647\n",
      "           2       0.97      0.99      0.98      1576\n",
      "\n",
      "    accuracy                           0.97      4408\n",
      "   macro avg       0.97      0.97      0.97      4408\n",
      "weighted avg       0.97      0.97      0.97      4408\n",
      "\n",
      "Train: 22 [ 550/588 ( 94%)]  Loss: 0.04906 (0.0568)  Time: 0.275s,   29.12/s  (0.221s,   36.22/s)  LR: 5.170e-04  \n",
      "Conf Mat:\n",
      " [[1115   11    5]\n",
      " [  42 1610    5]\n",
      " [  28   26 1566]]\n",
      "Data: 0.031 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1255\n",
      "           1       0.97      0.98      0.98      1778\n",
      "           2       0.97      0.99      0.98      1671\n",
      "\n",
      "    accuracy                           0.97      4704\n",
      "   macro avg       0.97      0.97      0.97      4704\n",
      "weighted avg       0.97      0.97      0.97      4704\n",
      "\n",
      "Train: 22 [ 587/588 (100%)]  Loss: 0.007680 (0.0566)  Time: 0.186s,   42.90/s  (0.220s,   36.44/s)  LR: 5.170e-04  \n",
      "Conf Mat:\n",
      " [[1180   13    5]\n",
      " [  44 1739    6]\n",
      " [  31   26 1660]]\n",
      "Data: 0.000 (0.017)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         8\n",
      "   macro avg       0.33      0.33      0.33         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Test: [   0/79]  Time: 0.758 (0.758)  Loss:  0.5517 (0.5517)  \n",
      "Conf Mat:\n",
      " [[8 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       369\n",
      "           1       0.73      0.97      0.84        39\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       408\n",
      "   macro avg       0.58      0.64      0.60       408\n",
      "weighted avg       0.97      0.94      0.96       408\n",
      "\n",
      "Test: [  50/79]  Time: 0.067 (0.186)  Loss:  0.5623 (0.6093)  \n",
      "Conf Mat:\n",
      " [[347   1   0]\n",
      " [ 14  38   0]\n",
      " [  8   0   0]]\n",
      "Acc@1: 100.0000 (94.3627)  Acc@5: 100.0000 (100.0000)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       369\n",
      "           1       0.90      0.86      0.88       169\n",
      "           2       0.92      0.95      0.93        96\n",
      "\n",
      "    accuracy                           0.92       634\n",
      "   macro avg       0.92      0.92      0.92       634\n",
      "weighted avg       0.92      0.92      0.92       634\n",
      "\n",
      "Test: [  79/79]  Time: 0.015 (0.164)  Loss:  0.5518 (0.6276)  \n",
      "Conf Mat:\n",
      " [[347  23   2]\n",
      " [ 14 146   3]\n",
      " [  8   0  91]]\n",
      "Acc@1: 100.0000 (92.1136)  Acc@5: 100.0000 (100.0000)\n",
      "Current checkpoints:\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-18.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-19.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-21.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-22.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-11.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-15.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-20.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-13.pth.tar', 91.6403785488959)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-12.pth.tar', 91.4826498422713)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-8.pth.tar', 91.32492113564669)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       1.00      1.00      1.00         5\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         8\n",
      "   macro avg       0.67      0.67      0.67         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Train: 23 [   0/588 (  0%)]  Loss: 0.02712 (0.0271)  Time: 0.864s,    9.26/s  (0.864s,    9.26/s)  LR: 4.013e-04  \n",
      "Conf Mat:\n",
      " [[0 0 0]\n",
      " [0 3 0]\n",
      " [0 0 5]]\n",
      "Data: 0.667 (0.667)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97       118\n",
      "           1       0.96      0.97      0.96       147\n",
      "           2       0.95      0.98      0.96       143\n",
      "\n",
      "    accuracy                           0.96       408\n",
      "   macro avg       0.97      0.96      0.96       408\n",
      "weighted avg       0.96      0.96      0.96       408\n",
      "\n",
      "Train: 23 [  50/588 (  9%)]  Loss: 0.1122 (0.0667)  Time: 0.223s,   35.90/s  (0.244s,   32.81/s)  LR: 4.013e-04  \n",
      "Conf Mat:\n",
      " [[111   1   0]\n",
      " [  3 142   3]\n",
      " [  4   4 140]]\n",
      "Data: 0.018 (0.033)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       214\n",
      "           1       0.98      0.97      0.97       296\n",
      "           2       0.94      0.99      0.96       298\n",
      "\n",
      "    accuracy                           0.97       808\n",
      "   macro avg       0.97      0.96      0.96       808\n",
      "weighted avg       0.97      0.97      0.97       808\n",
      "\n",
      "Train: 23 [ 100/588 ( 17%)]  Loss: 0.09657 (0.0721)  Time: 0.290s,   27.61/s  (0.228s,   35.15/s)  LR: 4.013e-04  \n",
      "Conf Mat:\n",
      " [[198   2   0]\n",
      " [  3 288   4]\n",
      " [ 13   6 294]]\n",
      "Data: 0.024 (0.023)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       318\n",
      "           1       0.98      0.97      0.98       451\n",
      "           2       0.95      0.99      0.97       439\n",
      "\n",
      "    accuracy                           0.97      1208\n",
      "   macro avg       0.97      0.97      0.97      1208\n",
      "weighted avg       0.97      0.97      0.97      1208\n",
      "\n",
      "Train: 23 [ 150/588 ( 26%)]  Loss: 0.01254 (0.0623)  Time: 0.209s,   38.20/s  (0.224s,   35.78/s)  LR: 4.013e-04  \n",
      "Conf Mat:\n",
      " [[299   4   1]\n",
      " [  5 439   4]\n",
      " [ 14   8 434]]\n",
      "Data: 0.015 (0.021)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96       408\n",
      "           1       0.98      0.96      0.97       606\n",
      "           2       0.96      0.99      0.97       594\n",
      "\n",
      "    accuracy                           0.97      1608\n",
      "   macro avg       0.97      0.96      0.97      1608\n",
      "weighted avg       0.97      0.97      0.97      1608\n",
      "\n",
      "Train: 23 [ 200/588 ( 34%)]  Loss: 0.006221 (0.0661)  Time: 0.197s,   40.64/s  (0.224s,   35.67/s)  LR: 4.013e-04  \n",
      "Conf Mat:\n",
      " [[384  11   1]\n",
      " [  9 583   5]\n",
      " [ 15  12 588]]\n",
      "Data: 0.006 (0.021)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       508\n",
      "           1       0.97      0.97      0.97       763\n",
      "           2       0.96      0.99      0.98       737\n",
      "\n",
      "    accuracy                           0.97      2008\n",
      "   macro avg       0.97      0.97      0.97      2008\n",
      "weighted avg       0.97      0.97      0.97      2008\n",
      "\n",
      "Train: 23 [ 250/588 ( 43%)]  Loss: 0.008768 (0.0614)  Time: 0.246s,   32.52/s  (0.224s,   35.64/s)  LR: 4.013e-04  \n",
      "Conf Mat:\n",
      " [[476  11   1]\n",
      " [ 14 740   5]\n",
      " [ 18  12 731]]\n",
      "Data: 0.029 (0.021)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       616\n",
      "           1       0.97      0.97      0.97       925\n",
      "           2       0.96      0.99      0.98       867\n",
      "\n",
      "    accuracy                           0.97      2408\n",
      "   macro avg       0.97      0.97      0.97      2408\n",
      "weighted avg       0.97      0.97      0.97      2408\n",
      "\n",
      "Train: 23 [ 300/588 ( 51%)]  Loss: 0.06004 (0.0645)  Time: 0.209s,   38.28/s  (0.221s,   36.23/s)  LR: 4.013e-04  \n",
      "Conf Mat:\n",
      " [[576  11   1]\n",
      " [ 20 899   6]\n",
      " [ 20  15 860]]\n",
      "Data: 0.010 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       726\n",
      "           1       0.97      0.97      0.97      1066\n",
      "           2       0.96      0.99      0.98      1016\n",
      "\n",
      "    accuracy                           0.97      2808\n",
      "   macro avg       0.97      0.97      0.97      2808\n",
      "weighted avg       0.97      0.97      0.97      2808\n",
      "\n",
      "Train: 23 [ 350/588 ( 60%)]  Loss: 0.003100 (0.0642)  Time: 0.203s,   39.32/s  (0.222s,   36.12/s)  LR: 4.013e-04  \n",
      "Conf Mat:\n",
      " [[ 682   11    1]\n",
      " [  23 1037    8]\n",
      " [  21   18 1007]]\n",
      "Data: 0.016 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       847\n",
      "           1       0.97      0.97      0.97      1214\n",
      "           2       0.96      0.99      0.98      1147\n",
      "\n",
      "    accuracy                           0.97      3208\n",
      "   macro avg       0.97      0.97      0.97      3208\n",
      "weighted avg       0.97      0.97      0.97      3208\n",
      "\n",
      "Train: 23 [ 400/588 ( 68%)]  Loss: 0.09652 (0.0655)  Time: 0.212s,   37.82/s  (0.222s,   36.00/s)  LR: 4.013e-04  \n",
      "Conf Mat:\n",
      " [[ 795   13    3]\n",
      " [  29 1182    8]\n",
      " [  23   19 1136]]\n",
      "Data: 0.014 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96       949\n",
      "           1       0.97      0.98      0.97      1374\n",
      "           2       0.96      0.99      0.98      1285\n",
      "\n",
      "    accuracy                           0.97      3608\n",
      "   macro avg       0.97      0.97      0.97      3608\n",
      "weighted avg       0.97      0.97      0.97      3608\n",
      "\n",
      "Train: 23 [ 450/588 ( 77%)]  Loss: 0.01849 (0.0639)  Time: 0.210s,   38.14/s  (0.221s,   36.26/s)  LR: 4.013e-04  \n",
      "Conf Mat:\n",
      " [[ 886   14    3]\n",
      " [  36 1340    8]\n",
      " [  27   20 1274]]\n",
      "Data: 0.018 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96      1054\n",
      "           1       0.97      0.98      0.97      1519\n",
      "           2       0.97      0.99      0.98      1435\n",
      "\n",
      "    accuracy                           0.97      4008\n",
      "   macro avg       0.97      0.97      0.97      4008\n",
      "weighted avg       0.97      0.97      0.97      4008\n",
      "\n",
      "Train: 23 [ 500/588 ( 85%)]  Loss: 0.01199 (0.0613)  Time: 0.204s,   39.19/s  (0.220s,   36.37/s)  LR: 4.013e-04  \n",
      "Conf Mat:\n",
      " [[ 985   14    3]\n",
      " [  40 1485    8]\n",
      " [  29   20 1424]]\n",
      "Data: 0.006 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1171\n",
      "           1       0.97      0.98      0.97      1673\n",
      "           2       0.96      0.99      0.98      1564\n",
      "\n",
      "    accuracy                           0.97      4408\n",
      "   macro avg       0.97      0.97      0.97      4408\n",
      "weighted avg       0.97      0.97      0.97      4408\n",
      "\n",
      "Train: 23 [ 550/588 ( 94%)]  Loss: 0.09041 (0.0613)  Time: 0.204s,   39.18/s  (0.221s,   36.25/s)  LR: 4.013e-04  \n",
      "Conf Mat:\n",
      " [[1095   16    3]\n",
      " [  42 1633    8]\n",
      " [  34   24 1553]]\n",
      "Data: 0.014 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1254\n",
      "           1       0.97      0.98      0.97      1779\n",
      "           2       0.96      0.99      0.98      1671\n",
      "\n",
      "    accuracy                           0.97      4704\n",
      "   macro avg       0.97      0.97      0.97      4704\n",
      "weighted avg       0.97      0.97      0.97      4704\n",
      "\n",
      "Train: 23 [ 587/588 (100%)]  Loss: 0.1414 (0.0619)  Time: 0.189s,   42.36/s  (0.219s,   36.46/s)  LR: 4.013e-04  \n",
      "Conf Mat:\n",
      " [[1173   16    3]\n",
      " [  44 1735    8]\n",
      " [  37   28 1660]]\n",
      "Data: 0.000 (0.018)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         8\n",
      "   macro avg       0.33      0.33      0.33         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Test: [   0/79]  Time: 1.322 (1.322)  Loss:  0.5518 (0.5518)  \n",
      "Conf Mat:\n",
      " [[8 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       369\n",
      "           1       0.75      0.97      0.84        39\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.95       408\n",
      "   macro avg       0.58      0.64      0.60       408\n",
      "weighted avg       0.97      0.95      0.96       408\n",
      "\n",
      "Test: [  50/79]  Time: 0.066 (0.170)  Loss:  0.5549 (0.6108)  \n",
      "Conf Mat:\n",
      " [[348   1   0]\n",
      " [ 13  38   0]\n",
      " [  8   0   0]]\n",
      "Acc@1: 100.0000 (94.6078)  Acc@5: 100.0000 (100.0000)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       369\n",
      "           1       0.90      0.88      0.89       169\n",
      "           2       0.92      0.95      0.93        96\n",
      "\n",
      "    accuracy                           0.93       634\n",
      "   macro avg       0.92      0.92      0.92       634\n",
      "weighted avg       0.93      0.93      0.93       634\n",
      "\n",
      "Test: [  79/79]  Time: 0.015 (0.154)  Loss:  0.5520 (0.6260)  \n",
      "Conf Mat:\n",
      " [[348  21   2]\n",
      " [ 13 148   3]\n",
      " [  8   0  91]]\n",
      "Acc@1: 100.0000 (92.5868)  Acc@5: 100.0000 (100.0000)\n",
      "Current checkpoints:\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-23.pth.tar', 92.58675078864353)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-18.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-19.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-21.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-22.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-11.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-15.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-20.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-13.pth.tar', 91.6403785488959)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-12.pth.tar', 91.4826498422713)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         8\n",
      "   macro avg       1.00      1.00      1.00         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Train: 24 [   0/588 (  0%)]  Loss: 0.003721 (0.00372)  Time: 0.773s,   10.35/s  (0.773s,   10.35/s)  LR: 2.984e-04  \n",
      "Conf Mat:\n",
      " [[3 0 0]\n",
      " [0 2 0]\n",
      " [0 0 3]]\n",
      "Data: 0.576 (0.576)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       107\n",
      "           1       0.98      0.97      0.97       176\n",
      "           2       0.96      0.99      0.98       125\n",
      "\n",
      "    accuracy                           0.97       408\n",
      "   macro avg       0.97      0.97      0.97       408\n",
      "weighted avg       0.97      0.97      0.97       408\n",
      "\n",
      "Train: 24 [  50/588 (  9%)]  Loss: 0.03072 (0.0733)  Time: 0.197s,   40.61/s  (0.251s,   31.86/s)  LR: 2.984e-04  \n",
      "Conf Mat:\n",
      " [[102   2   1]\n",
      " [  4 170   0]\n",
      " [  1   4 124]]\n",
      "Data: 0.006 (0.045)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       211\n",
      "           1       0.98      0.96      0.97       328\n",
      "           2       0.97      0.99      0.98       269\n",
      "\n",
      "    accuracy                           0.97       808\n",
      "   macro avg       0.97      0.97      0.97       808\n",
      "weighted avg       0.97      0.97      0.97       808\n",
      "\n",
      "Train: 24 [ 100/588 ( 17%)]  Loss: 0.01619 (0.0639)  Time: 0.218s,   36.67/s  (0.239s,   33.52/s)  LR: 2.984e-04  \n",
      "Conf Mat:\n",
      " [[202   6   1]\n",
      " [  6 316   1]\n",
      " [  3   6 267]]\n",
      "Data: 0.021 (0.032)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       320\n",
      "           1       0.98      0.96      0.97       477\n",
      "           2       0.97      1.00      0.98       411\n",
      "\n",
      "    accuracy                           0.97      1208\n",
      "   macro avg       0.97      0.97      0.97      1208\n",
      "weighted avg       0.97      0.97      0.97      1208\n",
      "\n",
      "Train: 24 [ 150/588 ( 26%)]  Loss: 0.002191 (0.0569)  Time: 0.266s,   30.03/s  (0.230s,   34.73/s)  LR: 2.984e-04  \n",
      "Conf Mat:\n",
      " [[308   7   1]\n",
      " [  8 460   1]\n",
      " [  4  10 409]]\n",
      "Data: 0.029 (0.027)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       433\n",
      "           1       0.98      0.97      0.97       622\n",
      "           2       0.97      0.99      0.98       553\n",
      "\n",
      "    accuracy                           0.98      1608\n",
      "   macro avg       0.98      0.98      0.98      1608\n",
      "weighted avg       0.98      0.98      0.98      1608\n",
      "\n",
      "Train: 24 [ 200/588 ( 34%)]  Loss: 0.01782 (0.0560)  Time: 0.196s,   40.85/s  (0.227s,   35.27/s)  LR: 2.984e-04  \n",
      "Conf Mat:\n",
      " [[418   9   2]\n",
      " [ 10 602   2]\n",
      " [  5  11 549]]\n",
      "Data: 0.006 (0.024)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       539\n",
      "           1       0.98      0.97      0.97       773\n",
      "           2       0.97      0.99      0.98       696\n",
      "\n",
      "    accuracy                           0.97      2008\n",
      "   macro avg       0.97      0.97      0.97      2008\n",
      "weighted avg       0.97      0.97      0.97      2008\n",
      "\n",
      "Train: 24 [ 250/588 ( 43%)]  Loss: 0.02185 (0.0550)  Time: 0.196s,   40.91/s  (0.226s,   35.36/s)  LR: 2.984e-04  \n",
      "Conf Mat:\n",
      " [[515  12   2]\n",
      " [ 16 749   2]\n",
      " [  8  12 692]]\n",
      "Data: 0.006 (0.023)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       645\n",
      "           1       0.98      0.97      0.97       917\n",
      "           2       0.97      1.00      0.98       846\n",
      "\n",
      "    accuracy                           0.98      2408\n",
      "   macro avg       0.98      0.97      0.97      2408\n",
      "weighted avg       0.98      0.98      0.98      2408\n",
      "\n",
      "Train: 24 [ 300/588 ( 51%)]  Loss: 0.006230 (0.0540)  Time: 0.283s,   28.24/s  (0.226s,   35.43/s)  LR: 2.984e-04  \n",
      "Conf Mat:\n",
      " [[618  15   2]\n",
      " [ 17 889   2]\n",
      " [ 10  13 842]]\n",
      "Data: 0.026 (0.022)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96       745\n",
      "           1       0.98      0.97      0.98      1088\n",
      "           2       0.97      0.99      0.98       975\n",
      "\n",
      "    accuracy                           0.98      2808\n",
      "   macro avg       0.97      0.97      0.97      2808\n",
      "weighted avg       0.98      0.98      0.98      2808\n",
      "\n",
      "Train: 24 [ 350/588 ( 60%)]  Loss: 0.006148 (0.0539)  Time: 0.220s,   36.41/s  (0.223s,   35.90/s)  LR: 2.984e-04  \n",
      "Conf Mat:\n",
      " [[ 711   16    2]\n",
      " [  20 1057    3]\n",
      " [  14   15  970]]\n",
      "Data: 0.021 (0.020)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96       854\n",
      "           1       0.97      0.97      0.97      1239\n",
      "           2       0.97      1.00      0.98      1115\n",
      "\n",
      "    accuracy                           0.97      3208\n",
      "   macro avg       0.97      0.97      0.97      3208\n",
      "weighted avg       0.97      0.97      0.97      3208\n",
      "\n",
      "Train: 24 [ 400/588 ( 68%)]  Loss: 0.2933 (0.0550)  Time: 0.194s,   41.22/s  (0.223s,   35.86/s)  LR: 2.984e-04  \n",
      "Conf Mat:\n",
      " [[ 811   17    2]\n",
      " [  29 1204    3]\n",
      " [  14   18 1110]]\n",
      "Data: 0.006 (0.020)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96       946\n",
      "           1       0.98      0.97      0.97      1394\n",
      "           2       0.97      0.99      0.98      1268\n",
      "\n",
      "    accuracy                           0.97      3608\n",
      "   macro avg       0.97      0.97      0.97      3608\n",
      "weighted avg       0.97      0.97      0.97      3608\n",
      "\n",
      "Train: 24 [ 450/588 ( 77%)]  Loss: 0.4348 (0.0552)  Time: 0.197s,   40.52/s  (0.223s,   35.81/s)  LR: 2.984e-04  \n",
      "Conf Mat:\n",
      " [[ 900   20    3]\n",
      " [  30 1354    4]\n",
      " [  16   20 1261]]\n",
      "Data: 0.010 (0.020)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1060\n",
      "           1       0.97      0.97      0.97      1533\n",
      "           2       0.97      0.99      0.98      1415\n",
      "\n",
      "    accuracy                           0.97      4008\n",
      "   macro avg       0.97      0.97      0.97      4008\n",
      "weighted avg       0.97      0.97      0.97      4008\n",
      "\n",
      "Train: 24 [ 500/588 ( 85%)]  Loss: 0.1267 (0.0553)  Time: 0.257s,   31.09/s  (0.222s,   35.96/s)  LR: 2.984e-04  \n",
      "Conf Mat:\n",
      " [[1005   22    4]\n",
      " [  36 1489    4]\n",
      " [  19   22 1407]]\n",
      "Data: 0.031 (0.020)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1174\n",
      "           1       0.97      0.97      0.97      1672\n",
      "           2       0.97      0.99      0.98      1562\n",
      "\n",
      "    accuracy                           0.97      4408\n",
      "   macro avg       0.97      0.97      0.97      4408\n",
      "weighted avg       0.97      0.97      0.97      4408\n",
      "\n",
      "Train: 24 [ 550/588 ( 94%)]  Loss: 0.01974 (0.0553)  Time: 0.199s,   40.14/s  (0.221s,   36.20/s)  LR: 2.984e-04  \n",
      "Conf Mat:\n",
      " [[1114   23    4]\n",
      " [  39 1624    5]\n",
      " [  21   25 1553]]\n",
      "Data: 0.006 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1254\n",
      "           1       0.97      0.97      0.97      1780\n",
      "           2       0.97      0.99      0.98      1670\n",
      "\n",
      "    accuracy                           0.97      4704\n",
      "   macro avg       0.97      0.97      0.97      4704\n",
      "weighted avg       0.97      0.97      0.97      4704\n",
      "\n",
      "Train: 24 [ 587/588 (100%)]  Loss: 0.04128 (0.0561)  Time: 0.188s,   42.60/s  (0.222s,   36.07/s)  LR: 2.984e-04  \n",
      "Conf Mat:\n",
      " [[1186   24    4]\n",
      " [  44 1731    5]\n",
      " [  24   25 1661]]\n",
      "Data: 0.000 (0.019)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         8\n",
      "   macro avg       0.33      0.33      0.33         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Test: [   0/79]  Time: 0.805 (0.805)  Loss:  0.5520 (0.5520)  \n",
      "Conf Mat:\n",
      " [[8 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97       369\n",
      "           1       0.72      0.97      0.83        39\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       408\n",
      "   macro avg       0.57      0.64      0.60       408\n",
      "weighted avg       0.97      0.94      0.95       408\n",
      "\n",
      "Test: [  50/79]  Time: 0.060 (0.142)  Loss:  0.5585 (0.6133)  \n",
      "Conf Mat:\n",
      " [[345   1   0]\n",
      " [ 15  38   0]\n",
      " [  9   0   0]]\n",
      "Acc@1: 100.0000 (93.8725)  Acc@5: 100.0000 (100.0000)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94       369\n",
      "           1       0.89      0.88      0.89       169\n",
      "           2       0.91      0.95      0.93        96\n",
      "\n",
      "    accuracy                           0.92       634\n",
      "   macro avg       0.91      0.92      0.92       634\n",
      "weighted avg       0.92      0.92      0.92       634\n",
      "\n",
      "Test: [  79/79]  Time: 0.017 (0.162)  Loss:  0.5524 (0.6274)  \n",
      "Conf Mat:\n",
      " [[345  20   2]\n",
      " [ 15 149   3]\n",
      " [  9   0  91]]\n",
      "Acc@1: 100.0000 (92.2713)  Acc@5: 100.0000 (100.0000)\n",
      "Current checkpoints:\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-23.pth.tar', 92.58675078864353)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-24.pth.tar', 92.27129337539432)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-18.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-19.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-21.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-22.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-11.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-15.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-20.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-13.pth.tar', 91.6403785488959)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00         8\n",
      "   macro avg       1.00      1.00      1.00         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Train: 25 [   0/588 (  0%)]  Loss: 0.006540 (0.00654)  Time: 0.752s,   10.64/s  (0.752s,   10.64/s)  LR: 2.093e-04  \n",
      "Conf Mat:\n",
      " [[2 0 0]\n",
      " [0 2 0]\n",
      " [0 0 4]]\n",
      "Data: 0.551 (0.551)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       100\n",
      "           1       0.96      0.97      0.97       159\n",
      "           2       0.97      0.98      0.98       149\n",
      "\n",
      "    accuracy                           0.97       408\n",
      "   macro avg       0.97      0.96      0.96       408\n",
      "weighted avg       0.97      0.97      0.97       408\n",
      "\n",
      "Train: 25 [  50/588 (  9%)]  Loss: 0.08408 (0.0833)  Time: 0.263s,   30.44/s  (0.219s,   36.49/s)  LR: 2.093e-04  \n",
      "Conf Mat:\n",
      " [[ 94   3   1]\n",
      " [  4 154   2]\n",
      " [  2   2 146]]\n",
      "Data: 0.024 (0.024)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96       209\n",
      "           1       0.97      0.98      0.97       334\n",
      "           2       0.97      0.98      0.98       265\n",
      "\n",
      "    accuracy                           0.97       808\n",
      "   macro avg       0.97      0.97      0.97       808\n",
      "weighted avg       0.97      0.97      0.97       808\n",
      "\n",
      "Train: 25 [ 100/588 ( 17%)]  Loss: 0.009736 (0.0633)  Time: 0.202s,   39.65/s  (0.221s,   36.16/s)  LR: 2.093e-04  \n",
      "Conf Mat:\n",
      " [[197   3   3]\n",
      " [  8 327   2]\n",
      " [  4   4 260]]\n",
      "Data: 0.010 (0.020)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       299\n",
      "           1       0.98      0.97      0.97       483\n",
      "           2       0.96      0.99      0.97       426\n",
      "\n",
      "    accuracy                           0.97      1208\n",
      "   macro avg       0.97      0.96      0.97      1208\n",
      "weighted avg       0.97      0.97      0.97      1208\n",
      "\n",
      "Train: 25 [ 150/588 ( 26%)]  Loss: 0.1121 (0.0590)  Time: 0.193s,   41.53/s  (0.223s,   35.80/s)  LR: 2.093e-04  \n",
      "Conf Mat:\n",
      " [[279   5   3]\n",
      " [ 10 470   2]\n",
      " [ 10   8 421]]\n",
      "Data: 0.006 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96       403\n",
      "           1       0.98      0.97      0.98       632\n",
      "           2       0.96      0.99      0.98       573\n",
      "\n",
      "    accuracy                           0.97      1608\n",
      "   macro avg       0.97      0.97      0.97      1608\n",
      "weighted avg       0.97      0.97      0.97      1608\n",
      "\n",
      "Train: 25 [ 200/588 ( 34%)]  Loss: 0.02986 (0.0555)  Time: 0.244s,   32.76/s  (0.221s,   36.14/s)  LR: 2.093e-04  \n",
      "Conf Mat:\n",
      " [[379   8   3]\n",
      " [ 10 615   2]\n",
      " [ 14   9 568]]\n",
      "Data: 0.024 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96       513\n",
      "           1       0.98      0.97      0.98       776\n",
      "           2       0.96      0.99      0.98       719\n",
      "\n",
      "    accuracy                           0.97      2008\n",
      "   macro avg       0.97      0.97      0.97      2008\n",
      "weighted avg       0.97      0.97      0.97      2008\n",
      "\n",
      "Train: 25 [ 250/588 ( 43%)]  Loss: 0.001799 (0.0544)  Time: 0.203s,   39.41/s  (0.220s,   36.40/s)  LR: 2.093e-04  \n",
      "Conf Mat:\n",
      " [[484  11   3]\n",
      " [ 12 752   2]\n",
      " [ 17  13 714]]\n",
      "Data: 0.012 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       627\n",
      "           1       0.98      0.97      0.98       929\n",
      "           2       0.96      0.99      0.98       852\n",
      "\n",
      "    accuracy                           0.97      2408\n",
      "   macro avg       0.97      0.97      0.97      2408\n",
      "weighted avg       0.97      0.97      0.97      2408\n",
      "\n",
      "Train: 25 [ 300/588 ( 51%)]  Loss: 0.03577 (0.0543)  Time: 0.201s,   39.82/s  (0.221s,   36.17/s)  LR: 2.093e-04  \n",
      "Conf Mat:\n",
      " [[593  13   3]\n",
      " [ 15 901   2]\n",
      " [ 19  15 847]]\n",
      "Data: 0.015 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       733\n",
      "           1       0.98      0.97      0.98      1076\n",
      "           2       0.96      0.99      0.98       999\n",
      "\n",
      "    accuracy                           0.97      2808\n",
      "   macro avg       0.97      0.97      0.97      2808\n",
      "weighted avg       0.97      0.97      0.97      2808\n",
      "\n",
      "Train: 25 [ 350/588 ( 60%)]  Loss: 0.1429 (0.0525)  Time: 0.199s,   40.13/s  (0.222s,   36.03/s)  LR: 2.093e-04  \n",
      "Conf Mat:\n",
      " [[ 691   13    4]\n",
      " [  21 1047    3]\n",
      " [  21   16  992]]\n",
      "Data: 0.014 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       844\n",
      "           1       0.98      0.97      0.98      1223\n",
      "           2       0.96      0.99      0.98      1141\n",
      "\n",
      "    accuracy                           0.97      3208\n",
      "   macro avg       0.97      0.97      0.97      3208\n",
      "weighted avg       0.97      0.97      0.97      3208\n",
      "\n",
      "Train: 25 [ 400/588 ( 68%)]  Loss: 0.04702 (0.0538)  Time: 0.303s,   26.43/s  (0.220s,   36.30/s)  LR: 2.093e-04  \n",
      "Conf Mat:\n",
      " [[ 795   14    4]\n",
      " [  24 1192    3]\n",
      " [  25   17 1134]]\n",
      "Data: 0.072 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       952\n",
      "           1       0.98      0.98      0.98      1368\n",
      "           2       0.97      0.99      0.98      1288\n",
      "\n",
      "    accuracy                           0.97      3608\n",
      "   macro avg       0.97      0.97      0.97      3608\n",
      "weighted avg       0.97      0.97      0.97      3608\n",
      "\n",
      "Train: 25 [ 450/588 ( 77%)]  Loss: 0.04876 (0.0520)  Time: 0.192s,   41.57/s  (0.220s,   36.39/s)  LR: 2.093e-04  \n",
      "Conf Mat:\n",
      " [[ 897   14    4]\n",
      " [  27 1336    3]\n",
      " [  28   18 1281]]\n",
      "Data: 0.005 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1056\n",
      "           1       0.98      0.97      0.98      1514\n",
      "           2       0.96      0.99      0.98      1438\n",
      "\n",
      "    accuracy                           0.97      4008\n",
      "   macro avg       0.97      0.97      0.97      4008\n",
      "weighted avg       0.97      0.97      0.97      4008\n",
      "\n",
      "Train: 25 [ 500/588 ( 85%)]  Loss: 0.3722 (0.0521)  Time: 0.211s,   37.85/s  (0.221s,   36.28/s)  LR: 2.093e-04  \n",
      "Conf Mat:\n",
      " [[ 998   17    4]\n",
      " [  28 1475    4]\n",
      " [  30   22 1430]]\n",
      "Data: 0.017 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1169\n",
      "           1       0.98      0.97      0.98      1673\n",
      "           2       0.96      0.99      0.98      1566\n",
      "\n",
      "    accuracy                           0.97      4408\n",
      "   macro avg       0.97      0.97      0.97      4408\n",
      "weighted avg       0.97      0.97      0.97      4408\n",
      "\n",
      "Train: 25 [ 550/588 ( 94%)]  Loss: 0.005823 (0.0532)  Time: 0.273s,   29.33/s  (0.220s,   36.32/s)  LR: 2.093e-04  \n",
      "Conf Mat:\n",
      " [[1104   21    4]\n",
      " [  30 1628    4]\n",
      " [  35   24 1558]]\n",
      "Data: 0.023 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1254\n",
      "           1       0.98      0.97      0.98      1780\n",
      "           2       0.96      0.99      0.98      1670\n",
      "\n",
      "    accuracy                           0.97      4704\n",
      "   macro avg       0.97      0.97      0.97      4704\n",
      "weighted avg       0.97      0.97      0.97      4704\n",
      "\n",
      "Train: 25 [ 587/588 (100%)]  Loss: 0.008549 (0.0531)  Time: 0.187s,   42.78/s  (0.219s,   36.51/s)  LR: 2.093e-04  \n",
      "Conf Mat:\n",
      " [[1185   22    4]\n",
      " [  33 1733    5]\n",
      " [  36   25 1661]]\n",
      "Data: 0.000 (0.017)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         8\n",
      "   macro avg       0.33      0.33      0.33         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Test: [   0/79]  Time: 0.769 (0.769)  Loss:  0.5520 (0.5520)  \n",
      "Conf Mat:\n",
      " [[8 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96       369\n",
      "           1       0.63      0.97      0.77        39\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92       408\n",
      "   macro avg       0.54      0.63      0.57       408\n",
      "weighted avg       0.96      0.92      0.94       408\n",
      "\n",
      "Test: [  50/79]  Time: 0.071 (0.187)  Loss:  0.5522 (0.6267)  \n",
      "Conf Mat:\n",
      " [[339   1   0]\n",
      " [ 22  38   0]\n",
      " [  8   0   0]]\n",
      "Acc@1: 100.0000 (92.4020)  Acc@5: 100.0000 (100.0000)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94       369\n",
      "           1       0.86      0.91      0.89       169\n",
      "           2       0.92      0.95      0.93        96\n",
      "\n",
      "    accuracy                           0.92       634\n",
      "   macro avg       0.91      0.93      0.92       634\n",
      "weighted avg       0.92      0.92      0.92       634\n",
      "\n",
      "Test: [  79/79]  Time: 0.014 (0.166)  Loss:  0.5528 (0.6304)  \n",
      "Conf Mat:\n",
      " [[339  15   2]\n",
      " [ 22 154   3]\n",
      " [  8   0  91]]\n",
      "Acc@1: 100.0000 (92.1136)  Acc@5: 100.0000 (100.0000)\n",
      "Current checkpoints:\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-23.pth.tar', 92.58675078864353)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-24.pth.tar', 92.27129337539432)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-18.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-19.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-21.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-22.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-25.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-11.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-15.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-20.pth.tar', 91.7981072555205)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         8\n",
      "   macro avg       1.00      1.00      1.00         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Train: 26 [   0/588 (  0%)]  Loss: 0.002653 (0.00265)  Time: 0.813s,    9.84/s  (0.813s,    9.84/s)  LR: 1.351e-04  \n",
      "Conf Mat:\n",
      " [[3 0 0]\n",
      " [0 3 0]\n",
      " [0 0 2]]\n",
      "Data: 0.620 (0.620)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97       111\n",
      "           1       0.96      0.99      0.97       136\n",
      "           2       0.98      0.99      0.98       161\n",
      "\n",
      "    accuracy                           0.98       408\n",
      "   macro avg       0.98      0.97      0.97       408\n",
      "weighted avg       0.98      0.98      0.98       408\n",
      "\n",
      "Train: 26 [  50/588 (  9%)]  Loss: 0.03780 (0.0591)  Time: 0.224s,   35.72/s  (0.242s,   33.01/s)  LR: 1.351e-04  \n",
      "Conf Mat:\n",
      " [[105   0   0]\n",
      " [  4 134   2]\n",
      " [  2   2 159]]\n",
      "Data: 0.025 (0.031)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       210\n",
      "           1       0.98      0.98      0.98       292\n",
      "           2       0.98      0.99      0.98       306\n",
      "\n",
      "    accuracy                           0.98       808\n",
      "   macro avg       0.98      0.98      0.98       808\n",
      "weighted avg       0.98      0.98      0.98       808\n",
      "\n",
      "Train: 26 [ 100/588 ( 17%)]  Loss: 0.09555 (0.0494)  Time: 0.275s,   29.07/s  (0.227s,   35.23/s)  LR: 1.351e-04  \n",
      "Conf Mat:\n",
      " [[201   2   1]\n",
      " [  5 287   2]\n",
      " [  4   3 303]]\n",
      "Data: 0.028 (0.023)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       326\n",
      "           1       0.98      0.98      0.98       438\n",
      "           2       0.98      0.99      0.98       444\n",
      "\n",
      "    accuracy                           0.98      1208\n",
      "   macro avg       0.98      0.98      0.98      1208\n",
      "weighted avg       0.98      0.98      0.98      1208\n",
      "\n",
      "Train: 26 [ 150/588 ( 26%)]  Loss: 0.0009271 (0.0498)  Time: 0.196s,   40.86/s  (0.225s,   35.62/s)  LR: 1.351e-04  \n",
      "Conf Mat:\n",
      " [[312   2   1]\n",
      " [  8 431   2]\n",
      " [  6   5 441]]\n",
      "Data: 0.006 (0.020)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       435\n",
      "           1       0.98      0.98      0.98       591\n",
      "           2       0.97      0.99      0.98       582\n",
      "\n",
      "    accuracy                           0.98      1608\n",
      "   macro avg       0.98      0.98      0.98      1608\n",
      "weighted avg       0.98      0.98      0.98      1608\n",
      "\n",
      "Train: 26 [ 200/588 ( 34%)]  Loss: 0.002400 (0.0495)  Time: 0.198s,   40.43/s  (0.225s,   35.56/s)  LR: 1.351e-04  \n",
      "Conf Mat:\n",
      " [[415   2   2]\n",
      " [ 12 580   2]\n",
      " [  8   9 578]]\n",
      "Data: 0.010 (0.020)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       546\n",
      "           1       0.98      0.98      0.98       749\n",
      "           2       0.97      0.99      0.98       713\n",
      "\n",
      "    accuracy                           0.98      2008\n",
      "   macro avg       0.98      0.98      0.98      2008\n",
      "weighted avg       0.98      0.98      0.98      2008\n",
      "\n",
      "Train: 26 [ 250/588 ( 43%)]  Loss: 0.003283 (0.0527)  Time: 0.273s,   29.34/s  (0.224s,   35.78/s)  LR: 1.351e-04  \n",
      "Conf Mat:\n",
      " [[521   3   2]\n",
      " [ 14 734   2]\n",
      " [ 11  12 709]]\n",
      "Data: 0.027 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       633\n",
      "           1       0.98      0.98      0.98       911\n",
      "           2       0.97      1.00      0.98       864\n",
      "\n",
      "    accuracy                           0.98      2408\n",
      "   macro avg       0.98      0.98      0.98      2408\n",
      "weighted avg       0.98      0.98      0.98      2408\n",
      "\n",
      "Train: 26 [ 300/588 ( 51%)]  Loss: 0.01769 (0.0489)  Time: 0.196s,   40.72/s  (0.221s,   36.26/s)  LR: 1.351e-04  \n",
      "Conf Mat:\n",
      " [[605   4   2]\n",
      " [ 16 894   2]\n",
      " [ 12  13 860]]\n",
      "Data: 0.012 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       730\n",
      "           1       0.98      0.98      0.98      1060\n",
      "           2       0.97      1.00      0.98      1018\n",
      "\n",
      "    accuracy                           0.98      2808\n",
      "   macro avg       0.98      0.98      0.98      2808\n",
      "weighted avg       0.98      0.98      0.98      2808\n",
      "\n",
      "Train: 26 [ 350/588 ( 60%)]  Loss: 0.004504 (0.0476)  Time: 0.203s,   39.48/s  (0.221s,   36.14/s)  LR: 1.351e-04  \n",
      "Conf Mat:\n",
      " [[ 695    5    2]\n",
      " [  19 1040    2]\n",
      " [  16   15 1014]]\n",
      "Data: 0.012 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       837\n",
      "           1       0.98      0.98      0.98      1210\n",
      "           2       0.97      1.00      0.98      1161\n",
      "\n",
      "    accuracy                           0.98      3208\n",
      "   macro avg       0.98      0.98      0.98      3208\n",
      "weighted avg       0.98      0.98      0.98      3208\n",
      "\n",
      "Train: 26 [ 400/588 ( 68%)]  Loss: 0.08690 (0.0477)  Time: 0.243s,   32.98/s  (0.222s,   36.05/s)  LR: 1.351e-04  \n",
      "Conf Mat:\n",
      " [[ 795    6    2]\n",
      " [  24 1188    2]\n",
      " [  18   16 1157]]\n",
      "Data: 0.047 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97       936\n",
      "           1       0.98      0.98      0.98      1366\n",
      "           2       0.97      0.99      0.98      1306\n",
      "\n",
      "    accuracy                           0.98      3608\n",
      "   macro avg       0.98      0.98      0.98      3608\n",
      "weighted avg       0.98      0.98      0.98      3608\n",
      "\n",
      "Train: 26 [ 450/588 ( 77%)]  Loss: 0.02723 (0.0497)  Time: 0.258s,   31.01/s  (0.221s,   36.22/s)  LR: 1.351e-04  \n",
      "Conf Mat:\n",
      " [[ 891    9    5]\n",
      " [  26 1339    2]\n",
      " [  19   18 1299]]\n",
      "Data: 0.020 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1063\n",
      "           1       0.98      0.98      0.98      1518\n",
      "           2       0.97      0.99      0.98      1427\n",
      "\n",
      "    accuracy                           0.98      4008\n",
      "   macro avg       0.98      0.98      0.98      4008\n",
      "weighted avg       0.98      0.98      0.98      4008\n",
      "\n",
      "Train: 26 [ 500/588 ( 85%)]  Loss: 0.05029 (0.0492)  Time: 0.200s,   39.91/s  (0.220s,   36.34/s)  LR: 1.351e-04  \n",
      "Conf Mat:\n",
      " [[1011   10    6]\n",
      " [  31 1487    2]\n",
      " [  21   21 1419]]\n",
      "Data: 0.012 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      1175\n",
      "           1       0.98      0.98      0.98      1668\n",
      "           2       0.97      0.99      0.98      1565\n",
      "\n",
      "    accuracy                           0.98      4408\n",
      "   macro avg       0.98      0.98      0.98      4408\n",
      "weighted avg       0.98      0.98      0.98      4408\n",
      "\n",
      "Train: 26 [ 550/588 ( 94%)]  Loss: 0.006228 (0.0497)  Time: 0.193s,   41.39/s  (0.221s,   36.22/s)  LR: 1.351e-04  \n",
      "Conf Mat:\n",
      " [[1116   10    6]\n",
      " [  36 1636    2]\n",
      " [  23   22 1557]]\n",
      "Data: 0.006 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1254\n",
      "           1       0.98      0.98      0.98      1780\n",
      "           2       0.97      0.99      0.98      1670\n",
      "\n",
      "    accuracy                           0.98      4704\n",
      "   macro avg       0.98      0.97      0.98      4704\n",
      "weighted avg       0.98      0.98      0.98      4704\n",
      "\n",
      "Train: 26 [ 587/588 (100%)]  Loss: 0.02143 (0.0508)  Time: 0.190s,   42.14/s  (0.220s,   36.44/s)  LR: 1.351e-04  \n",
      "Conf Mat:\n",
      " [[1192   12    7]\n",
      " [  38 1744    3]\n",
      " [  24   24 1660]]\n",
      "Data: 0.000 (0.017)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         8\n",
      "   macro avg       0.33      0.33      0.33         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Test: [   0/79]  Time: 1.099 (1.099)  Loss:  0.5519 (0.5519)  \n",
      "Conf Mat:\n",
      " [[8 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.95       369\n",
      "           1       0.62      0.97      0.76        39\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92       408\n",
      "   macro avg       0.54      0.63      0.57       408\n",
      "weighted avg       0.96      0.92      0.94       408\n",
      "\n",
      "Test: [  50/79]  Time: 0.063 (0.164)  Loss:  0.5530 (0.6309)  \n",
      "Conf Mat:\n",
      " [[338   1   0]\n",
      " [ 23  38   0]\n",
      " [  8   0   0]]\n",
      "Acc@1: 100.0000 (92.1569)  Acc@5: 100.0000 (100.0000)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93       369\n",
      "           1       0.86      0.92      0.89       169\n",
      "           2       0.92      0.95      0.93        96\n",
      "\n",
      "    accuracy                           0.92       634\n",
      "   macro avg       0.91      0.93      0.92       634\n",
      "weighted avg       0.92      0.92      0.92       634\n",
      "\n",
      "Test: [  79/79]  Time: 0.015 (0.150)  Loss:  0.5523 (0.6299)  \n",
      "Conf Mat:\n",
      " [[338  14   2]\n",
      " [ 23 155   3]\n",
      " [  8   0  91]]\n",
      "Acc@1: 100.0000 (92.1136)  Acc@5: 100.0000 (100.0000)\n",
      "Current checkpoints:\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-23.pth.tar', 92.58675078864353)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-24.pth.tar', 92.27129337539432)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-18.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-19.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-21.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-22.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-25.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-26.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-11.pth.tar', 91.7981072555205)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-15.pth.tar', 91.7981072555205)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00         8\n",
      "   macro avg       1.00      1.00      1.00         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Train: 27 [   0/588 (  0%)]  Loss: 0.002290 (0.00229)  Time: 0.798s,   10.03/s  (0.798s,   10.03/s)  LR: 7.647e-05  \n",
      "Conf Mat:\n",
      " [[1 0 0]\n",
      " [0 2 0]\n",
      " [0 0 5]]\n",
      "Data: 0.580 (0.580)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       107\n",
      "           1       0.97      0.98      0.97       142\n",
      "           2       0.97      0.99      0.98       159\n",
      "\n",
      "    accuracy                           0.98       408\n",
      "   macro avg       0.98      0.97      0.97       408\n",
      "weighted avg       0.98      0.98      0.98       408\n",
      "\n",
      "Train: 27 [  50/588 (  9%)]  Loss: 0.001745 (0.0504)  Time: 0.200s,   39.98/s  (0.249s,   32.11/s)  LR: 7.647e-05  \n",
      "Conf Mat:\n",
      " [[101   0   0]\n",
      " [  4 139   1]\n",
      " [  2   3 158]]\n",
      "Data: 0.006 (0.040)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       210\n",
      "           1       0.96      0.98      0.97       305\n",
      "           2       0.96      0.99      0.98       293\n",
      "\n",
      "    accuracy                           0.97       808\n",
      "   macro avg       0.98      0.97      0.97       808\n",
      "weighted avg       0.97      0.97      0.97       808\n",
      "\n",
      "Train: 27 [ 100/588 ( 17%)]  Loss: 0.003526 (0.0506)  Time: 0.222s,   36.11/s  (0.239s,   33.54/s)  LR: 7.647e-05  \n",
      "Conf Mat:\n",
      " [[195   0   0]\n",
      " [  9 300   2]\n",
      " [  6   5 291]]\n",
      "Data: 0.023 (0.030)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       319\n",
      "           1       0.97      0.98      0.98       456\n",
      "           2       0.96      0.99      0.98       433\n",
      "\n",
      "    accuracy                           0.97      1208\n",
      "   macro avg       0.98      0.97      0.97      1208\n",
      "weighted avg       0.97      0.97      0.97      1208\n",
      "\n",
      "Train: 27 [ 150/588 ( 26%)]  Loss: 0.1033 (0.0519)  Time: 0.302s,   26.52/s  (0.228s,   35.02/s)  LR: 7.647e-05  \n",
      "Conf Mat:\n",
      " [[297   1   0]\n",
      " [ 11 448   3]\n",
      " [ 11   7 430]]\n",
      "Data: 0.035 (0.024)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       419\n",
      "           1       0.97      0.97      0.97       622\n",
      "           2       0.96      0.99      0.98       567\n",
      "\n",
      "    accuracy                           0.97      1608\n",
      "   macro avg       0.97      0.97      0.97      1608\n",
      "weighted avg       0.97      0.97      0.97      1608\n",
      "\n",
      "Train: 27 [ 200/588 ( 34%)]  Loss: 0.1235 (0.0507)  Time: 0.201s,   39.81/s  (0.226s,   35.37/s)  LR: 7.647e-05  \n",
      "Conf Mat:\n",
      " [[394   7   0]\n",
      " [ 13 605   3]\n",
      " [ 12  10 564]]\n",
      "Data: 0.012 (0.022)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       527\n",
      "           1       0.98      0.97      0.97       769\n",
      "           2       0.96      0.99      0.98       712\n",
      "\n",
      "    accuracy                           0.97      2008\n",
      "   macro avg       0.97      0.97      0.97      2008\n",
      "weighted avg       0.97      0.97      0.97      2008\n",
      "\n",
      "Train: 27 [ 250/588 ( 43%)]  Loss: 0.2096 (0.0507)  Time: 0.195s,   41.05/s  (0.227s,   35.29/s)  LR: 7.647e-05  \n",
      "Conf Mat:\n",
      " [[497   8   1]\n",
      " [ 15 748   3]\n",
      " [ 15  13 708]]\n",
      "Data: 0.006 (0.022)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       615\n",
      "           1       0.98      0.97      0.98       929\n",
      "           2       0.96      1.00      0.98       864\n",
      "\n",
      "    accuracy                           0.97      2408\n",
      "   macro avg       0.97      0.97      0.97      2408\n",
      "weighted avg       0.97      0.97      0.97      2408\n",
      "\n",
      "Train: 27 [ 300/588 ( 51%)]  Loss: 0.01388 (0.0516)  Time: 0.265s,   30.19/s  (0.225s,   35.53/s)  LR: 7.647e-05  \n",
      "Conf Mat:\n",
      " [[581   9   1]\n",
      " [ 17 904   3]\n",
      " [ 17  16 860]]\n",
      "Data: 0.027 (0.020)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       734\n",
      "           1       0.98      0.97      0.98      1067\n",
      "           2       0.96      1.00      0.98      1007\n",
      "\n",
      "    accuracy                           0.97      2808\n",
      "   macro avg       0.97      0.97      0.97      2808\n",
      "weighted avg       0.97      0.97      0.97      2808\n",
      "\n",
      "Train: 27 [ 350/588 ( 60%)]  Loss: 0.04340 (0.0532)  Time: 0.212s,   37.66/s  (0.223s,   35.91/s)  LR: 7.647e-05  \n",
      "Conf Mat:\n",
      " [[ 692   10    1]\n",
      " [  20 1039    3]\n",
      " [  22   18 1003]]\n",
      "Data: 0.012 (0.020)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       857\n",
      "           1       0.98      0.97      0.98      1206\n",
      "           2       0.96      1.00      0.98      1145\n",
      "\n",
      "    accuracy                           0.97      3208\n",
      "   macro avg       0.98      0.97      0.97      3208\n",
      "weighted avg       0.97      0.97      0.97      3208\n",
      "\n",
      "Train: 27 [ 400/588 ( 68%)]  Loss: 0.01253 (0.0528)  Time: 0.202s,   39.67/s  (0.223s,   35.83/s)  LR: 7.647e-05  \n",
      "Conf Mat:\n",
      " [[ 808   10    1]\n",
      " [  23 1175    3]\n",
      " [  26   21 1141]]\n",
      "Data: 0.016 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       968\n",
      "           1       0.98      0.97      0.98      1358\n",
      "           2       0.96      1.00      0.98      1282\n",
      "\n",
      "    accuracy                           0.97      3608\n",
      "   macro avg       0.98      0.97      0.97      3608\n",
      "weighted avg       0.97      0.97      0.97      3608\n",
      "\n",
      "Train: 27 [ 450/588 ( 77%)]  Loss: 0.001329 (0.0515)  Time: 0.222s,   36.03/s  (0.224s,   35.75/s)  LR: 7.647e-05  \n",
      "Conf Mat:\n",
      " [[ 915   12    1]\n",
      " [  23 1322    3]\n",
      " [  30   24 1278]]\n",
      "Data: 0.016 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96      1071\n",
      "           1       0.98      0.97      0.98      1521\n",
      "           2       0.96      1.00      0.98      1416\n",
      "\n",
      "    accuracy                           0.97      4008\n",
      "   macro avg       0.97      0.97      0.97      4008\n",
      "weighted avg       0.97      0.97      0.97      4008\n",
      "\n",
      "Train: 27 [ 500/588 ( 85%)]  Loss: 0.003309 (0.0529)  Time: 0.269s,   29.74/s  (0.223s,   35.93/s)  LR: 7.647e-05  \n",
      "Conf Mat:\n",
      " [[1011   13    1]\n",
      " [  27 1480    6]\n",
      " [  33   28 1409]]\n",
      "Data: 0.017 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      1180\n",
      "           1       0.98      0.97      0.98      1660\n",
      "           2       0.96      1.00      0.98      1568\n",
      "\n",
      "    accuracy                           0.97      4408\n",
      "   macro avg       0.97      0.97      0.97      4408\n",
      "weighted avg       0.97      0.97      0.97      4408\n",
      "\n",
      "Train: 27 [ 550/588 ( 94%)]  Loss: 0.004032 (0.0534)  Time: 0.206s,   38.78/s  (0.221s,   36.12/s)  LR: 7.647e-05  \n",
      "Conf Mat:\n",
      " [[1117   16    1]\n",
      " [  28 1614    6]\n",
      " [  35   30 1561]]\n",
      "Data: 0.012 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1254\n",
      "           1       0.98      0.97      0.97      1779\n",
      "           2       0.96      1.00      0.98      1671\n",
      "\n",
      "    accuracy                           0.97      4704\n",
      "   macro avg       0.97      0.97      0.97      4704\n",
      "weighted avg       0.97      0.97      0.97      4704\n",
      "\n",
      "Train: 27 [ 587/588 (100%)]  Loss: 0.09617 (0.0536)  Time: 0.185s,   43.13/s  (0.222s,   36.04/s)  LR: 7.647e-05  \n",
      "Conf Mat:\n",
      " [[1182   17    1]\n",
      " [  36 1730    6]\n",
      " [  36   32 1664]]\n",
      "Data: 0.000 (0.018)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         8\n",
      "   macro avg       0.33      0.33      0.33         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Test: [   0/79]  Time: 0.761 (0.761)  Loss:  0.5529 (0.5529)  \n",
      "Conf Mat:\n",
      " [[8 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96       369\n",
      "           1       0.67      0.97      0.79        39\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       408\n",
      "   macro avg       0.55      0.63      0.58       408\n",
      "weighted avg       0.97      0.93      0.94       408\n",
      "\n",
      "Test: [  50/79]  Time: 0.065 (0.143)  Loss:  0.5533 (0.6280)  \n",
      "Conf Mat:\n",
      " [[340   1   0]\n",
      " [ 19  38   0]\n",
      " [ 10   0   0]]\n",
      "Acc@1: 100.0000 (92.6471)  Acc@5: 100.0000 (100.0000)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94       369\n",
      "           1       0.88      0.91      0.89       169\n",
      "           2       0.90      0.95      0.92        96\n",
      "\n",
      "    accuracy                           0.92       634\n",
      "   macro avg       0.91      0.93      0.92       634\n",
      "weighted avg       0.92      0.92      0.92       634\n",
      "\n",
      "Test: [  79/79]  Time: 0.015 (0.156)  Loss:  0.5519 (0.6313)  \n",
      "Conf Mat:\n",
      " [[340  15   2]\n",
      " [ 19 154   3]\n",
      " [ 10   0  91]]\n",
      "Acc@1: 100.0000 (92.2713)  Acc@5: 100.0000 (100.0000)\n",
      "Current checkpoints:\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-23.pth.tar', 92.58675078864353)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-24.pth.tar', 92.27129337539432)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-27.pth.tar', 92.27129337539432)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-18.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-19.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-21.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-22.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-25.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-26.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-11.pth.tar', 91.7981072555205)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       1.00      1.00      1.00         1\n",
      "           2       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.88         8\n",
      "   macro avg       0.92      0.92      0.90         8\n",
      "weighted avg       0.91      0.88      0.88         8\n",
      "\n",
      "Train: 28 [   0/588 (  0%)]  Loss: 0.3305 (0.331)  Time: 1.176s,    6.80/s  (1.176s,    6.80/s)  LR: 3.414e-05  \n",
      "Conf Mat:\n",
      " [[3 0 0]\n",
      " [0 1 0]\n",
      " [1 0 3]]\n",
      "Data: 0.931 (0.931)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       119\n",
      "           1       0.98      1.00      0.99       133\n",
      "           2       0.97      1.00      0.99       156\n",
      "\n",
      "    accuracy                           0.98       408\n",
      "   macro avg       0.98      0.98      0.98       408\n",
      "weighted avg       0.98      0.98      0.98       408\n",
      "\n",
      "Train: 28 [  50/588 (  9%)]  Loss: 0.005927 (0.0361)  Time: 0.213s,   37.62/s  (0.226s,   35.44/s)  LR: 3.414e-05  \n",
      "Conf Mat:\n",
      " [[112   0   0]\n",
      " [  3 133   0]\n",
      " [  4   0 156]]\n",
      "Data: 0.016 (0.032)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       216\n",
      "           1       0.97      0.99      0.98       282\n",
      "           2       0.97      1.00      0.98       310\n",
      "\n",
      "    accuracy                           0.98       808\n",
      "   macro avg       0.98      0.97      0.98       808\n",
      "weighted avg       0.98      0.98      0.98       808\n",
      "\n",
      "Train: 28 [ 100/588 ( 17%)]  Loss: 0.08030 (0.0454)  Time: 0.201s,   39.87/s  (0.225s,   35.56/s)  LR: 3.414e-05  \n",
      "Conf Mat:\n",
      " [[202   0   0]\n",
      " [  7 280   1]\n",
      " [  7   2 309]]\n",
      "Data: 0.013 (0.025)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       313\n",
      "           1       0.97      0.99      0.98       429\n",
      "           2       0.98      0.99      0.99       466\n",
      "\n",
      "    accuracy                           0.98      1208\n",
      "   macro avg       0.98      0.98      0.98      1208\n",
      "weighted avg       0.98      0.98      0.98      1208\n",
      "\n",
      "Train: 28 [ 150/588 ( 26%)]  Loss: 0.04826 (0.0462)  Time: 0.216s,   37.09/s  (0.226s,   35.38/s)  LR: 3.414e-05  \n",
      "Conf Mat:\n",
      " [[294   0   0]\n",
      " [ 12 426   3]\n",
      " [  7   3 463]]\n",
      "Data: 0.027 (0.023)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       420\n",
      "           1       0.97      0.99      0.98       584\n",
      "           2       0.97      0.99      0.98       604\n",
      "\n",
      "    accuracy                           0.98      1608\n",
      "   macro avg       0.98      0.97      0.98      1608\n",
      "weighted avg       0.98      0.98      0.98      1608\n",
      "\n",
      "Train: 28 [ 200/588 ( 34%)]  Loss: 0.09787 (0.0494)  Time: 0.226s,   35.41/s  (0.223s,   35.95/s)  LR: 3.414e-05  \n",
      "Conf Mat:\n",
      " [[393   1   0]\n",
      " [ 14 579   5]\n",
      " [ 13   4 599]]\n",
      "Data: 0.022 (0.021)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       531\n",
      "           1       0.97      0.99      0.98       735\n",
      "           2       0.97      0.99      0.98       742\n",
      "\n",
      "    accuracy                           0.98      2008\n",
      "   macro avg       0.98      0.97      0.97      2008\n",
      "weighted avg       0.98      0.98      0.97      2008\n",
      "\n",
      "Train: 28 [ 250/588 ( 43%)]  Loss: 0.007260 (0.0518)  Time: 0.201s,   39.74/s  (0.221s,   36.17/s)  LR: 3.414e-05  \n",
      "Conf Mat:\n",
      " [[497   2   1]\n",
      " [ 17 726   6]\n",
      " [ 17   7 735]]\n",
      "Data: 0.006 (0.020)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       639\n",
      "           1       0.97      0.99      0.98       899\n",
      "           2       0.97      0.99      0.98       870\n",
      "\n",
      "    accuracy                           0.98      2408\n",
      "   macro avg       0.98      0.97      0.98      2408\n",
      "weighted avg       0.98      0.98      0.98      2408\n",
      "\n",
      "Train: 28 [ 300/588 ( 51%)]  Loss: 0.03482 (0.0500)  Time: 0.198s,   40.39/s  (0.222s,   36.01/s)  LR: 3.414e-05  \n",
      "Conf Mat:\n",
      " [[600   2   1]\n",
      " [ 19 888   6]\n",
      " [ 20   9 863]]\n",
      "Data: 0.010 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       733\n",
      "           1       0.98      0.99      0.98      1067\n",
      "           2       0.97      0.99      0.98      1008\n",
      "\n",
      "    accuracy                           0.98      2808\n",
      "   macro avg       0.98      0.97      0.98      2808\n",
      "weighted avg       0.98      0.98      0.98      2808\n",
      "\n",
      "Train: 28 [ 350/588 ( 60%)]  Loss: 0.01310 (0.0474)  Time: 0.255s,   31.34/s  (0.222s,   36.08/s)  LR: 3.414e-05  \n",
      "Conf Mat:\n",
      " [[ 691    2    1]\n",
      " [  21 1055    6]\n",
      " [  21   10 1001]]\n",
      "Data: 0.026 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97       852\n",
      "           1       0.97      0.99      0.98      1222\n",
      "           2       0.97      0.99      0.98      1134\n",
      "\n",
      "    accuracy                           0.98      3208\n",
      "   macro avg       0.98      0.97      0.98      3208\n",
      "weighted avg       0.98      0.98      0.98      3208\n",
      "\n",
      "Train: 28 [ 400/588 ( 68%)]  Loss: 0.03202 (0.0501)  Time: 0.210s,   38.15/s  (0.219s,   36.45/s)  LR: 3.414e-05  \n",
      "Conf Mat:\n",
      " [[ 804    6    1]\n",
      " [  26 1204    7]\n",
      " [  22   12 1126]]\n",
      "Data: 0.014 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       965\n",
      "           1       0.97      0.98      0.98      1361\n",
      "           2       0.97      0.99      0.98      1282\n",
      "\n",
      "    accuracy                           0.98      3608\n",
      "   macro avg       0.98      0.97      0.98      3608\n",
      "weighted avg       0.98      0.98      0.98      3608\n",
      "\n",
      "Train: 28 [ 450/588 ( 77%)]  Loss: 0.03251 (0.0505)  Time: 0.191s,   41.92/s  (0.220s,   36.29/s)  LR: 3.414e-05  \n",
      "Conf Mat:\n",
      " [[ 913    8    2]\n",
      " [  29 1338    8]\n",
      " [  23   15 1272]]\n",
      "Data: 0.005 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97      1069\n",
      "           1       0.97      0.98      0.98      1510\n",
      "           2       0.97      0.99      0.98      1429\n",
      "\n",
      "    accuracy                           0.98      4008\n",
      "   macro avg       0.98      0.97      0.98      4008\n",
      "weighted avg       0.98      0.98      0.98      4008\n",
      "\n",
      "Train: 28 [ 500/588 ( 85%)]  Loss: 0.004972 (0.0508)  Time: 0.203s,   39.48/s  (0.221s,   36.25/s)  LR: 3.414e-05  \n",
      "Conf Mat:\n",
      " [[1010    9    2]\n",
      " [  32 1486    8]\n",
      " [  27   15 1419]]\n",
      "Data: 0.005 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96      1177\n",
      "           1       0.97      0.98      0.98      1668\n",
      "           2       0.97      0.99      0.98      1563\n",
      "\n",
      "    accuracy                           0.98      4408\n",
      "   macro avg       0.98      0.97      0.97      4408\n",
      "weighted avg       0.98      0.98      0.98      4408\n",
      "\n",
      "Train: 28 [ 550/588 ( 94%)]  Loss: 0.02412 (0.0539)  Time: 0.279s,   28.68/s  (0.220s,   36.38/s)  LR: 3.414e-05  \n",
      "Conf Mat:\n",
      " [[1107    9    3]\n",
      " [  39 1642    9]\n",
      " [  31   17 1551]]\n",
      "Data: 0.033 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96      1254\n",
      "           1       0.97      0.98      0.98      1780\n",
      "           2       0.97      0.99      0.98      1670\n",
      "\n",
      "    accuracy                           0.98      4704\n",
      "   macro avg       0.98      0.97      0.97      4704\n",
      "weighted avg       0.98      0.98      0.98      4704\n",
      "\n",
      "Train: 28 [ 587/588 (100%)]  Loss: 0.006288 (0.0535)  Time: 0.187s,   42.78/s  (0.220s,   36.44/s)  LR: 3.414e-05  \n",
      "Conf Mat:\n",
      " [[1179   11    3]\n",
      " [  41 1752    9]\n",
      " [  34   17 1658]]\n",
      "Data: 0.000 (0.017)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         8\n",
      "   macro avg       0.33      0.33      0.33         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Test: [   0/79]  Time: 0.767 (0.767)  Loss:  0.5519 (0.5519)  \n",
      "Conf Mat:\n",
      " [[8 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       369\n",
      "           1       0.70      0.95      0.80        39\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       408\n",
      "   macro avg       0.56      0.63      0.59       408\n",
      "weighted avg       0.97      0.93      0.95       408\n",
      "\n",
      "Test: [  50/79]  Time: 0.078 (0.181)  Loss:  0.5625 (0.6199)  \n",
      "Conf Mat:\n",
      " [[343   2   0]\n",
      " [ 16  37   0]\n",
      " [ 10   0   0]]\n",
      "Acc@1: 100.0000 (93.1373)  Acc@5: 100.0000 (100.0000)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       369\n",
      "           1       0.89      0.87      0.88       169\n",
      "           2       0.90      0.96      0.93        96\n",
      "\n",
      "    accuracy                           0.92       634\n",
      "   macro avg       0.91      0.92      0.91       634\n",
      "weighted avg       0.92      0.92      0.92       634\n",
      "\n",
      "Test: [  79/79]  Time: 0.014 (0.164)  Loss:  0.5517 (0.6313)  \n",
      "Conf Mat:\n",
      " [[343  22   2]\n",
      " [ 16 147   2]\n",
      " [ 10   0  92]]\n",
      "Acc@1: 100.0000 (91.7981)  Acc@5: 100.0000 (100.0000)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         8\n",
      "   macro avg       1.00      1.00      1.00         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Train: 29 [   0/588 (  0%)]  Loss: 0.002132 (0.00213)  Time: 0.753s,   10.62/s  (0.753s,   10.62/s)  LR: 8.560e-06  \n",
      "Conf Mat:\n",
      " [[2 0 0]\n",
      " [0 3 0]\n",
      " [0 0 3]]\n",
      "Data: 0.567 (0.567)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96        96\n",
      "           1       0.98      0.95      0.97       155\n",
      "           2       0.95      0.98      0.97       157\n",
      "\n",
      "    accuracy                           0.97       408\n",
      "   macro avg       0.97      0.96      0.97       408\n",
      "weighted avg       0.97      0.97      0.97       408\n",
      "\n",
      "Train: 29 [  50/588 (  9%)]  Loss: 0.09731 (0.0677)  Time: 0.204s,   39.25/s  (0.238s,   33.54/s)  LR: 8.560e-06  \n",
      "Conf Mat:\n",
      " [[ 92   1   2]\n",
      " [  2 148   1]\n",
      " [  2   6 154]]\n",
      "Data: 0.013 (0.031)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       199\n",
      "           1       0.98      0.97      0.98       316\n",
      "           2       0.96      0.99      0.97       293\n",
      "\n",
      "    accuracy                           0.98       808\n",
      "   macro avg       0.98      0.97      0.97       808\n",
      "weighted avg       0.98      0.98      0.98       808\n",
      "\n",
      "Train: 29 [ 100/588 ( 17%)]  Loss: 0.01270 (0.0516)  Time: 0.226s,   35.44/s  (0.223s,   35.82/s)  LR: 8.560e-06  \n",
      "Conf Mat:\n",
      " [[191   1   2]\n",
      " [  4 307   1]\n",
      " [  4   8 290]]\n",
      "Data: 0.030 (0.023)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       294\n",
      "           1       0.99      0.98      0.98       493\n",
      "           2       0.96      0.99      0.98       421\n",
      "\n",
      "    accuracy                           0.98      1208\n",
      "   macro avg       0.98      0.98      0.98      1208\n",
      "weighted avg       0.98      0.98      0.98      1208\n",
      "\n",
      "Train: 29 [ 150/588 ( 26%)]  Loss: 0.05663 (0.0482)  Time: 0.207s,   38.71/s  (0.224s,   35.77/s)  LR: 8.560e-06  \n",
      "Conf Mat:\n",
      " [[283   1   2]\n",
      " [  5 481   1]\n",
      " [  6  11 418]]\n",
      "Data: 0.018 (0.021)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       402\n",
      "           1       0.99      0.98      0.98       652\n",
      "           2       0.96      0.99      0.98       554\n",
      "\n",
      "    accuracy                           0.98      1608\n",
      "   macro avg       0.98      0.98      0.98      1608\n",
      "weighted avg       0.98      0.98      0.98      1608\n",
      "\n",
      "Train: 29 [ 200/588 ( 34%)]  Loss: 0.1576 (0.0474)  Time: 0.212s,   37.75/s  (0.224s,   35.68/s)  LR: 8.560e-06  \n",
      "Conf Mat:\n",
      " [[384   3   2]\n",
      " [  7 637   1]\n",
      " [ 11  12 551]]\n",
      "Data: 0.022 (0.020)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       525\n",
      "           1       0.99      0.98      0.98       801\n",
      "           2       0.96      1.00      0.98       682\n",
      "\n",
      "    accuracy                           0.98      2008\n",
      "   macro avg       0.98      0.97      0.98      2008\n",
      "weighted avg       0.98      0.98      0.98      2008\n",
      "\n",
      "Train: 29 [ 250/588 ( 43%)]  Loss: 0.01503 (0.0458)  Time: 0.266s,   30.07/s  (0.223s,   35.92/s)  LR: 8.560e-06  \n",
      "Conf Mat:\n",
      " [[498   3   2]\n",
      " [ 10 784   1]\n",
      " [ 17  14 679]]\n",
      "Data: 0.021 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97       641\n",
      "           1       0.98      0.98      0.98       931\n",
      "           2       0.96      1.00      0.98       836\n",
      "\n",
      "    accuracy                           0.98      2408\n",
      "   macro avg       0.98      0.97      0.97      2408\n",
      "weighted avg       0.98      0.98      0.98      2408\n",
      "\n",
      "Train: 29 [ 300/588 ( 51%)]  Loss: 0.03767 (0.0455)  Time: 0.193s,   41.37/s  (0.221s,   36.27/s)  LR: 8.560e-06  \n",
      "Conf Mat:\n",
      " [[605   5   2]\n",
      " [ 13 912   1]\n",
      " [ 23  14 833]]\n",
      "Data: 0.005 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       753\n",
      "           1       0.98      0.98      0.98      1070\n",
      "           2       0.96      0.99      0.98       985\n",
      "\n",
      "    accuracy                           0.98      2808\n",
      "   macro avg       0.98      0.97      0.98      2808\n",
      "weighted avg       0.98      0.98      0.98      2808\n",
      "\n",
      "Train: 29 [ 350/588 ( 60%)]  Loss: 0.0006085 (0.0460)  Time: 0.191s,   41.90/s  (0.222s,   36.11/s)  LR: 8.560e-06  \n",
      "Conf Mat:\n",
      " [[ 714    6    2]\n",
      " [  15 1047    3]\n",
      " [  24   17  980]]\n",
      "Data: 0.005 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       856\n",
      "           1       0.98      0.98      0.98      1235\n",
      "           2       0.96      1.00      0.98      1117\n",
      "\n",
      "    accuracy                           0.98      3208\n",
      "   macro avg       0.98      0.97      0.98      3208\n",
      "weighted avg       0.98      0.98      0.98      3208\n",
      "\n",
      "Train: 29 [ 400/588 ( 68%)]  Loss: 0.04871 (0.0453)  Time: 0.219s,   36.47/s  (0.222s,   36.03/s)  LR: 8.560e-06  \n",
      "Conf Mat:\n",
      " [[ 809    6    2]\n",
      " [  18 1211    3]\n",
      " [  29   18 1112]]\n",
      "Data: 0.015 (0.019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       951\n",
      "           1       0.98      0.98      0.98      1397\n",
      "           2       0.96      1.00      0.98      1260\n",
      "\n",
      "    accuracy                           0.98      3608\n",
      "   macro avg       0.98      0.97      0.97      3608\n",
      "weighted avg       0.98      0.98      0.98      3608\n",
      "\n",
      "Train: 29 [ 450/588 ( 77%)]  Loss: 0.02654 (0.0459)  Time: 0.233s,   34.35/s  (0.220s,   36.38/s)  LR: 8.560e-06  \n",
      "Conf Mat:\n",
      " [[ 900    7    3]\n",
      " [  19 1367    3]\n",
      " [  32   23 1254]]\n",
      "Data: 0.024 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      1062\n",
      "           1       0.98      0.98      0.98      1539\n",
      "           2       0.96      1.00      0.98      1407\n",
      "\n",
      "    accuracy                           0.98      4008\n",
      "   macro avg       0.98      0.97      0.97      4008\n",
      "weighted avg       0.98      0.98      0.98      4008\n",
      "\n",
      "Train: 29 [ 500/588 ( 85%)]  Loss: 0.007345 (0.0469)  Time: 0.201s,   39.73/s  (0.220s,   36.35/s)  LR: 8.560e-06  \n",
      "Conf Mat:\n",
      " [[1004   10    3]\n",
      " [  23 1505    3]\n",
      " [  35   24 1401]]\n",
      "Data: 0.016 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      1181\n",
      "           1       0.98      0.98      0.98      1672\n",
      "           2       0.96      1.00      0.98      1555\n",
      "\n",
      "    accuracy                           0.98      4408\n",
      "   macro avg       0.98      0.97      0.97      4408\n",
      "weighted avg       0.98      0.98      0.98      4408\n",
      "\n",
      "Train: 29 [ 550/588 ( 94%)]  Loss: 0.03915 (0.0503)  Time: 0.197s,   40.59/s  (0.221s,   36.25/s)  LR: 8.560e-06  \n",
      "Conf Mat:\n",
      " [[1117   10    3]\n",
      " [  26 1635    4]\n",
      " [  38   27 1548]]\n",
      "Data: 0.012 (0.018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      1255\n",
      "           1       0.98      0.98      0.98      1780\n",
      "           2       0.96      1.00      0.98      1669\n",
      "\n",
      "    accuracy                           0.98      4704\n",
      "   macro avg       0.98      0.97      0.97      4704\n",
      "weighted avg       0.98      0.98      0.98      4704\n",
      "\n",
      "Train: 29 [ 587/588 (100%)]  Loss: 0.1213 (0.0526)  Time: 0.188s,   42.65/s  (0.219s,   36.48/s)  LR: 8.560e-06  \n",
      "Conf Mat:\n",
      " [[1186   10    3]\n",
      " [  29 1740    4]\n",
      " [  40   30 1662]]\n",
      "Data: 0.000 (0.017)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         8\n",
      "   macro avg       0.33      0.33      0.33         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n",
      "Test: [   0/79]  Time: 1.159 (1.159)  Loss:  0.5520 (0.5520)  \n",
      "Conf Mat:\n",
      " [[8 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       369\n",
      "           1       0.69      0.97      0.81        39\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       408\n",
      "   macro avg       0.56      0.63      0.59       408\n",
      "weighted avg       0.97      0.93      0.95       408\n",
      "\n",
      "Test: [  50/79]  Time: 0.070 (0.181)  Loss:  0.5564 (0.6245)  \n",
      "Conf Mat:\n",
      " [[342   1   0]\n",
      " [ 17  38   0]\n",
      " [ 10   0   0]]\n",
      "Acc@1: 100.0000 (93.1373)  Acc@5: 100.0000 (100.0000)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       369\n",
      "           1       0.88      0.90      0.89       169\n",
      "           2       0.89      0.95      0.92        96\n",
      "\n",
      "    accuracy                           0.92       634\n",
      "   macro avg       0.91      0.92      0.92       634\n",
      "weighted avg       0.92      0.92      0.92       634\n",
      "\n",
      "Test: [  79/79]  Time: 0.015 (0.161)  Loss:  0.5517 (0.6291)  \n",
      "Conf Mat:\n",
      " [[342  16   2]\n",
      " [ 17 152   3]\n",
      " [ 10   1  91]]\n",
      "Acc@1: 100.0000 (92.2713)  Acc@5: 100.0000 (100.0000)\n",
      "Current checkpoints:\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-23.pth.tar', 92.58675078864353)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-24.pth.tar', 92.27129337539432)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-27.pth.tar', 92.27129337539432)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-29.pth.tar', 92.27129337539432)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-18.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-19.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-21.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-22.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-25.pth.tar', 92.11356466876971)\n",
      " ('./output/train/20230504-095358-tf_efficientnet_b0-512/checkpoint-26.pth.tar', 92.11356466876971)\n",
      "\n",
      "*** Best metric: 92.58675078864353 (epoch 23)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!python '/content/pytorch-image-models/val.py' --data-dir '/content/test' --model 'tf_efficientnet_b0' --checkpoint '/content/pytorch-image-models/output/train/20230504-095358-tf_efficientnet_b0-512/model_best.pth.tar' --img-size 512 --batch-size 1 --num-classes 3 --log-freq 1"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qieuIVbl8M0V",
    "outputId": "353a4329-9cdb-4029-d57e-4228bcc049d4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1;30;43mStreaming output truncated to the last 5000 lines.\u001B[0m\n",
      " [ 3  0  0]\n",
      " [ 1  0  0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97        80\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.95        80\n",
      "   macro avg       0.33      0.32      0.32        80\n",
      "weighted avg       1.00      0.95      0.97        80\n",
      "Acc@1: 100.000 ( 95.000)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [  80/317]  Time: 0.044s (0.033s,   30.06/s)  Loss:  1.0052 (0.6069)  \n",
      "Conf Mat:\n",
      " [[76  0  0]\n",
      " [ 4  0  0]\n",
      " [ 1  0  0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        81\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94        81\n",
      "   macro avg       0.33      0.31      0.32        81\n",
      "weighted avg       1.00      0.94      0.97        81\n",
      "Acc@1:   0.000 ( 93.827)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [  81/317]  Time: 0.026s (0.033s,   30.14/s)  Loss:  0.5520 (0.6062)  \n",
      "Conf Mat:\n",
      " [[77  0  0]\n",
      " [ 4  0  0]\n",
      " [ 1  0  0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        82\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94        82\n",
      "   macro avg       0.33      0.31      0.32        82\n",
      "weighted avg       1.00      0.94      0.97        82\n",
      "Acc@1: 100.000 ( 93.902)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [  82/317]  Time: 0.025s (0.033s,   30.23/s)  Loss:  0.5587 (0.6056)  \n",
      "Conf Mat:\n",
      " [[78  0  0]\n",
      " [ 4  0  0]\n",
      " [ 1  0  0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        83\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94        83\n",
      "   macro avg       0.33      0.31      0.32        83\n",
      "weighted avg       1.00      0.94      0.97        83\n",
      "Acc@1: 100.000 ( 93.976)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [  83/317]  Time: 0.063s (0.033s,   29.91/s)  Loss:  1.4032 (0.6151)  \n",
      "Conf Mat:\n",
      " [[78  0  0]\n",
      " [ 5  0  0]\n",
      " [ 1  0  0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        84\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93        84\n",
      "   macro avg       0.33      0.31      0.32        84\n",
      "weighted avg       1.00      0.93      0.96        84\n",
      "Acc@1:   0.000 ( 92.857)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [  84/317]  Time: 0.038s (0.033s,   29.86/s)  Loss:  0.5514 (0.6144)  \n",
      "Conf Mat:\n",
      " [[79  0  0]\n",
      " [ 5  0  0]\n",
      " [ 1  0  0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        85\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93        85\n",
      "   macro avg       0.33      0.31      0.32        85\n",
      "weighted avg       1.00      0.93      0.96        85\n",
      "Acc@1: 100.000 ( 92.941)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [  85/317]  Time: 0.075s (0.034s,   29.44/s)  Loss:  0.5793 (0.6140)  \n",
      "Conf Mat:\n",
      " [[80  0  0]\n",
      " [ 5  0  0]\n",
      " [ 1  0  0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        86\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93        86\n",
      "   macro avg       0.33      0.31      0.32        86\n",
      "weighted avg       1.00      0.93      0.96        86\n",
      "Acc@1: 100.000 ( 93.023)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [  86/317]  Time: 0.057s (0.034s,   29.22/s)  Loss:  0.6131 (0.6139)  \n",
      "Conf Mat:\n",
      " [[81  0  0]\n",
      " [ 5  0  0]\n",
      " [ 1  0  0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        87\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93        87\n",
      "   macro avg       0.33      0.31      0.32        87\n",
      "weighted avg       1.00      0.93      0.96        87\n",
      "Acc@1: 100.000 ( 93.103)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [  87/317]  Time: 0.042s (0.034s,   29.14/s)  Loss:  0.5516 (0.6132)  \n",
      "Conf Mat:\n",
      " [[82  0  0]\n",
      " [ 5  0  0]\n",
      " [ 1  0  0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        88\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93        88\n",
      "   macro avg       0.33      0.31      0.32        88\n",
      "weighted avg       1.00      0.93      0.96        88\n",
      "Acc@1: 100.000 ( 93.182)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [  88/317]  Time: 0.026s (0.034s,   29.22/s)  Loss:  0.5521 (0.6125)  \n",
      "Conf Mat:\n",
      " [[83  0  0]\n",
      " [ 5  0  0]\n",
      " [ 1  0  0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97        89\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93        89\n",
      "   macro avg       0.33      0.31      0.32        89\n",
      "weighted avg       1.00      0.93      0.97        89\n",
      "Acc@1: 100.000 ( 93.258)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [  89/317]  Time: 0.070s (0.035s,   28.89/s)  Loss:  0.5531 (0.6119)  \n",
      "Conf Mat:\n",
      " [[84  0  0]\n",
      " [ 5  0  0]\n",
      " [ 1  0  0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97        90\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93        90\n",
      "   macro avg       0.33      0.31      0.32        90\n",
      "weighted avg       1.00      0.93      0.97        90\n",
      "Acc@1: 100.000 ( 93.333)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [  90/317]  Time: 0.036s (0.035s,   28.87/s)  Loss:  0.5685 (0.6114)  \n",
      "Conf Mat:\n",
      " [[85  0  0]\n",
      " [ 5  0  0]\n",
      " [ 1  0  0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97        91\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93        91\n",
      "   macro avg       0.33      0.31      0.32        91\n",
      "weighted avg       1.00      0.93      0.97        91\n",
      "Acc@1: 100.000 ( 93.407)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [  91/317]  Time: 0.055s (0.035s,   28.69/s)  Loss:  0.5519 (0.6108)  \n",
      "Conf Mat:\n",
      " [[86  0  0]\n",
      " [ 5  0  0]\n",
      " [ 1  0  0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97        92\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93        92\n",
      "   macro avg       0.33      0.31      0.32        92\n",
      "weighted avg       1.00      0.93      0.97        92\n",
      "Acc@1: 100.000 ( 93.478)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [  92/317]  Time: 0.072s (0.035s,   28.37/s)  Loss:  0.5516 (0.6101)  \n",
      "Conf Mat:\n",
      " [[87  0  0]\n",
      " [ 5  0  0]\n",
      " [ 1  0  0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        93\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94        93\n",
      "   macro avg       0.33      0.31      0.32        93\n",
      "weighted avg       1.00      0.94      0.97        93\n",
      "Acc@1: 100.000 ( 93.548)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [  93/317]  Time: 0.049s (0.035s,   28.25/s)  Loss:  0.5517 (0.6095)  \n",
      "Conf Mat:\n",
      " [[88  0  0]\n",
      " [ 5  0  0]\n",
      " [ 1  0  0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        94\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94        94\n",
      "   macro avg       0.33      0.31      0.32        94\n",
      "weighted avg       1.00      0.94      0.97        94\n",
      "Acc@1: 100.000 ( 93.617)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [  94/317]  Time: 0.026s (0.035s,   28.33/s)  Loss:  0.5515 (0.6089)  \n",
      "Conf Mat:\n",
      " [[89  0  0]\n",
      " [ 5  0  0]\n",
      " [ 1  0  0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        95\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94        95\n",
      "   macro avg       0.33      0.31      0.32        95\n",
      "weighted avg       1.00      0.94      0.97        95\n",
      "Acc@1: 100.000 ( 93.684)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [  95/317]  Time: 0.054s (0.035s,   28.18/s)  Loss:  0.5515 (0.6083)  \n",
      "Conf Mat:\n",
      " [[90  0  0]\n",
      " [ 5  0  0]\n",
      " [ 1  0  0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        96\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94        96\n",
      "   macro avg       0.33      0.31      0.32        96\n",
      "weighted avg       1.00      0.94      0.97        96\n",
      "Acc@1: 100.000 ( 93.750)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [  96/317]  Time: 0.067s (0.036s,   27.92/s)  Loss:  0.5515 (0.6077)  \n",
      "Conf Mat:\n",
      " [[91  0  0]\n",
      " [ 5  0  0]\n",
      " [ 1  0  0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        97\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94        97\n",
      "   macro avg       0.33      0.31      0.32        97\n",
      "weighted avg       1.00      0.94      0.97        97\n",
      "Acc@1: 100.000 ( 93.814)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [  97/317]  Time: 0.053s (0.036s,   27.78/s)  Loss:  0.5516 (0.6071)  \n",
      "Conf Mat:\n",
      " [[92  0  0]\n",
      " [ 5  0  0]\n",
      " [ 1  0  0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        98\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94        98\n",
      "   macro avg       0.33      0.31      0.32        98\n",
      "weighted avg       1.00      0.94      0.97        98\n",
      "Acc@1: 100.000 ( 93.878)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [  98/317]  Time: 0.044s (0.036s,   27.71/s)  Loss:  0.5521 (0.6066)  \n",
      "Conf Mat:\n",
      " [[93  0  0]\n",
      " [ 5  0  0]\n",
      " [ 1  0  0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        99\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94        99\n",
      "   macro avg       0.33      0.31      0.32        99\n",
      "weighted avg       1.00      0.94      0.97        99\n",
      "Acc@1: 100.000 ( 93.939)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [  99/317]  Time: 0.047s (0.036s,   27.63/s)  Loss:  0.5531 (0.6060)  \n",
      "Conf Mat:\n",
      " [[94  0  0]\n",
      " [ 5  0  0]\n",
      " [ 1  0  0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       100\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       100\n",
      "   macro avg       0.33      0.31      0.32       100\n",
      "weighted avg       1.00      0.94      0.97       100\n",
      "Acc@1: 100.000 ( 94.000)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 100/317]  Time: 0.059s (0.036s,   27.45/s)  Loss:  0.5523 (0.6055)  \n",
      "Conf Mat:\n",
      " [[95  0  0]\n",
      " [ 5  0  0]\n",
      " [ 1  0  0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       101\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       101\n",
      "   macro avg       0.33      0.31      0.32       101\n",
      "weighted avg       1.00      0.94      0.97       101\n",
      "Acc@1: 100.000 ( 94.059)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 101/317]  Time: 0.062s (0.037s,   27.27/s)  Loss:  0.5523 (0.6050)  \n",
      "Conf Mat:\n",
      " [[96  0  0]\n",
      " [ 5  0  0]\n",
      " [ 1  0  0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       102\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       102\n",
      "   macro avg       0.33      0.31      0.32       102\n",
      "weighted avg       1.00      0.94      0.97       102\n",
      "Acc@1: 100.000 ( 94.118)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 102/317]  Time: 0.057s (0.037s,   27.12/s)  Loss:  0.6036 (0.6050)  \n",
      "Conf Mat:\n",
      " [[97  0  0]\n",
      " [ 5  0  0]\n",
      " [ 1  0  0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       103\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       103\n",
      "   macro avg       0.33      0.31      0.32       103\n",
      "weighted avg       1.00      0.94      0.97       103\n",
      "Acc@1: 100.000 ( 94.175)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 103/317]  Time: 0.049s (0.037s,   27.04/s)  Loss:  0.5629 (0.6046)  \n",
      "Conf Mat:\n",
      " [[98  0  0]\n",
      " [ 5  0  0]\n",
      " [ 1  0  0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       104\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       104\n",
      "   macro avg       0.33      0.31      0.32       104\n",
      "weighted avg       1.00      0.94      0.97       104\n",
      "Acc@1: 100.000 ( 94.231)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 104/317]  Time: 0.045s (0.037s,   26.98/s)  Loss:  0.5517 (0.6041)  \n",
      "Conf Mat:\n",
      " [[99  0  0]\n",
      " [ 5  0  0]\n",
      " [ 1  0  0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       105\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       105\n",
      "   macro avg       0.33      0.31      0.32       105\n",
      "weighted avg       1.00      0.94      0.97       105\n",
      "Acc@1: 100.000 ( 94.286)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 105/317]  Time: 0.064s (0.037s,   26.80/s)  Loss:  0.6087 (0.6041)  \n",
      "Conf Mat:\n",
      " [[100   0   0]\n",
      " [  5   0   0]\n",
      " [  1   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       106\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       106\n",
      "   macro avg       0.33      0.31      0.32       106\n",
      "weighted avg       1.00      0.94      0.97       106\n",
      "Acc@1: 100.000 ( 94.340)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 106/317]  Time: 0.058s (0.038s,   26.66/s)  Loss:  0.5516 (0.6036)  \n",
      "Conf Mat:\n",
      " [[101   0   0]\n",
      " [  5   0   0]\n",
      " [  1   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       107\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       107\n",
      "   macro avg       0.33      0.31      0.32       107\n",
      "weighted avg       1.00      0.94      0.97       107\n",
      "Acc@1: 100.000 ( 94.393)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 107/317]  Time: 0.035s (0.037s,   26.67/s)  Loss:  0.5515 (0.6031)  \n",
      "Conf Mat:\n",
      " [[102   0   0]\n",
      " [  5   0   0]\n",
      " [  1   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       108\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       108\n",
      "   macro avg       0.33      0.31      0.32       108\n",
      "weighted avg       1.00      0.94      0.97       108\n",
      "Acc@1: 100.000 ( 94.444)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 108/317]  Time: 0.051s (0.038s,   26.58/s)  Loss:  0.5557 (0.6027)  \n",
      "Conf Mat:\n",
      " [[103   0   0]\n",
      " [  5   0   0]\n",
      " [  1   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       109\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       109\n",
      "   macro avg       0.33      0.31      0.32       109\n",
      "weighted avg       1.00      0.94      0.97       109\n",
      "Acc@1: 100.000 ( 94.495)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 109/317]  Time: 0.029s (0.038s,   26.64/s)  Loss:  0.5518 (0.6022)  \n",
      "Conf Mat:\n",
      " [[104   0   0]\n",
      " [  5   0   0]\n",
      " [  1   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97       110\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.95       110\n",
      "   macro avg       0.33      0.32      0.32       110\n",
      "weighted avg       1.00      0.95      0.97       110\n",
      "Acc@1: 100.000 ( 94.545)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 110/317]  Time: 0.049s (0.038s,   26.57/s)  Loss:  1.1616 (0.6073)  \n",
      "Conf Mat:\n",
      " [[104   0   0]\n",
      " [  5   0   0]\n",
      " [  2   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       111\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       111\n",
      "   macro avg       0.33      0.31      0.32       111\n",
      "weighted avg       1.00      0.94      0.97       111\n",
      "Acc@1:   0.000 ( 93.694)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 111/317]  Time: 0.044s (0.038s,   26.53/s)  Loss:  0.6862 (0.6080)  \n",
      "Conf Mat:\n",
      " [[105   0   0]\n",
      " [  5   0   0]\n",
      " [  2   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       112\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       112\n",
      "   macro avg       0.33      0.31      0.32       112\n",
      "weighted avg       1.00      0.94      0.97       112\n",
      "Acc@1: 100.000 ( 93.750)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 112/317]  Time: 0.075s (0.038s,   26.30/s)  Loss:  0.5551 (0.6075)  \n",
      "Conf Mat:\n",
      " [[106   0   0]\n",
      " [  5   0   0]\n",
      " [  2   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       113\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       113\n",
      "   macro avg       0.33      0.31      0.32       113\n",
      "weighted avg       1.00      0.94      0.97       113\n",
      "Acc@1: 100.000 ( 93.805)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 113/317]  Time: 0.044s (0.038s,   26.26/s)  Loss:  0.6380 (0.6078)  \n",
      "Conf Mat:\n",
      " [[107   0   0]\n",
      " [  5   0   0]\n",
      " [  2   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       114\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.33      0.31      0.32       114\n",
      "weighted avg       1.00      0.94      0.97       114\n",
      "Acc@1: 100.000 ( 93.860)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 114/317]  Time: 0.067s (0.038s,   26.09/s)  Loss:  0.5898 (0.6076)  \n",
      "Conf Mat:\n",
      " [[108   0   0]\n",
      " [  5   0   0]\n",
      " [  2   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       115\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       115\n",
      "   macro avg       0.33      0.31      0.32       115\n",
      "weighted avg       1.00      0.94      0.97       115\n",
      "Acc@1: 100.000 ( 93.913)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 115/317]  Time: 0.038s (0.038s,   26.09/s)  Loss:  1.3999 (0.6145)  \n",
      "Conf Mat:\n",
      " [[108   0   0]\n",
      " [  5   0   0]\n",
      " [  3   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       116\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       116\n",
      "   macro avg       0.33      0.31      0.32       116\n",
      "weighted avg       1.00      0.93      0.96       116\n",
      "Acc@1:   0.000 ( 93.103)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 116/317]  Time: 0.045s (0.038s,   26.05/s)  Loss:  0.5526 (0.6139)  \n",
      "Conf Mat:\n",
      " [[109   0   0]\n",
      " [  5   0   0]\n",
      " [  3   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       117\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       117\n",
      "   macro avg       0.33      0.31      0.32       117\n",
      "weighted avg       1.00      0.93      0.96       117\n",
      "Acc@1: 100.000 ( 93.162)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 117/317]  Time: 0.065s (0.039s,   25.90/s)  Loss:  0.5527 (0.6134)  \n",
      "Conf Mat:\n",
      " [[110   0   0]\n",
      " [  5   0   0]\n",
      " [  3   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       118\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       118\n",
      "   macro avg       0.33      0.31      0.32       118\n",
      "weighted avg       1.00      0.93      0.96       118\n",
      "Acc@1: 100.000 ( 93.220)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 118/317]  Time: 0.036s (0.039s,   25.91/s)  Loss:  0.5515 (0.6129)  \n",
      "Conf Mat:\n",
      " [[111   0   0]\n",
      " [  5   0   0]\n",
      " [  3   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97       119\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       119\n",
      "   macro avg       0.33      0.31      0.32       119\n",
      "weighted avg       1.00      0.93      0.97       119\n",
      "Acc@1: 100.000 ( 93.277)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 119/317]  Time: 0.059s (0.039s,   25.80/s)  Loss:  0.8286 (0.6147)  \n",
      "Conf Mat:\n",
      " [[112   0   0]\n",
      " [  5   0   0]\n",
      " [  3   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97       120\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       120\n",
      "   macro avg       0.33      0.31      0.32       120\n",
      "weighted avg       1.00      0.93      0.97       120\n",
      "Acc@1: 100.000 ( 93.333)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 120/317]  Time: 0.069s (0.039s,   25.63/s)  Loss:  0.5552 (0.6142)  \n",
      "Conf Mat:\n",
      " [[113   0   0]\n",
      " [  5   0   0]\n",
      " [  3   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97       121\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       121\n",
      "   macro avg       0.33      0.31      0.32       121\n",
      "weighted avg       1.00      0.93      0.97       121\n",
      "Acc@1: 100.000 ( 93.388)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 121/317]  Time: 0.059s (0.039s,   25.52/s)  Loss:  0.5515 (0.6137)  \n",
      "Conf Mat:\n",
      " [[114   0   0]\n",
      " [  5   0   0]\n",
      " [  3   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97       122\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       122\n",
      "   macro avg       0.33      0.31      0.32       122\n",
      "weighted avg       1.00      0.93      0.97       122\n",
      "Acc@1: 100.000 ( 93.443)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 122/317]  Time: 0.051s (0.039s,   25.46/s)  Loss:  0.6223 (0.6138)  \n",
      "Conf Mat:\n",
      " [[115   0   0]\n",
      " [  5   0   0]\n",
      " [  3   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97       123\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       123\n",
      "   macro avg       0.33      0.31      0.32       123\n",
      "weighted avg       1.00      0.93      0.97       123\n",
      "Acc@1: 100.000 ( 93.496)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 123/317]  Time: 0.078s (0.040s,   25.26/s)  Loss:  0.5515 (0.6133)  \n",
      "Conf Mat:\n",
      " [[116   0   0]\n",
      " [  5   0   0]\n",
      " [  3   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       124\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       124\n",
      "   macro avg       0.33      0.31      0.32       124\n",
      "weighted avg       1.00      0.94      0.97       124\n",
      "Acc@1: 100.000 ( 93.548)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 124/317]  Time: 0.045s (0.040s,   25.23/s)  Loss:  0.5515 (0.6128)  \n",
      "Conf Mat:\n",
      " [[117   0   0]\n",
      " [  5   0   0]\n",
      " [  3   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       125\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       125\n",
      "   macro avg       0.33      0.31      0.32       125\n",
      "weighted avg       1.00      0.94      0.97       125\n",
      "Acc@1: 100.000 ( 93.600)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 125/317]  Time: 0.071s (0.040s,   25.07/s)  Loss:  0.5515 (0.6123)  \n",
      "Conf Mat:\n",
      " [[118   0   0]\n",
      " [  5   0   0]\n",
      " [  3   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       126\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       126\n",
      "   macro avg       0.33      0.31      0.32       126\n",
      "weighted avg       1.00      0.94      0.97       126\n",
      "Acc@1: 100.000 ( 93.651)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 126/317]  Time: 0.058s (0.040s,   24.98/s)  Loss:  0.6168 (0.6123)  \n",
      "Conf Mat:\n",
      " [[119   0   0]\n",
      " [  5   0   0]\n",
      " [  3   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       127\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       127\n",
      "   macro avg       0.33      0.31      0.32       127\n",
      "weighted avg       1.00      0.94      0.97       127\n",
      "Acc@1: 100.000 ( 93.701)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 127/317]  Time: 0.042s (0.040s,   24.97/s)  Loss:  0.5516 (0.6118)  \n",
      "Conf Mat:\n",
      " [[120   0   0]\n",
      " [  5   0   0]\n",
      " [  3   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       128\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       128\n",
      "   macro avg       0.33      0.31      0.32       128\n",
      "weighted avg       1.00      0.94      0.97       128\n",
      "Acc@1: 100.000 ( 93.750)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 128/317]  Time: 0.027s (0.040s,   25.03/s)  Loss:  0.5515 (0.6114)  \n",
      "Conf Mat:\n",
      " [[121   0   0]\n",
      " [  5   0   0]\n",
      " [  3   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       129\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       129\n",
      "   macro avg       0.33      0.31      0.32       129\n",
      "weighted avg       1.00      0.94      0.97       129\n",
      "Acc@1: 100.000 ( 93.798)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 129/317]  Time: 0.079s (0.040s,   24.84/s)  Loss:  0.5514 (0.6109)  \n",
      "Conf Mat:\n",
      " [[122   0   0]\n",
      " [  5   0   0]\n",
      " [  3   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       130\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       130\n",
      "   macro avg       0.33      0.31      0.32       130\n",
      "weighted avg       1.00      0.94      0.97       130\n",
      "Acc@1: 100.000 ( 93.846)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 130/317]  Time: 0.069s (0.040s,   24.71/s)  Loss:  0.5520 (0.6105)  \n",
      "Conf Mat:\n",
      " [[123   0   0]\n",
      " [  5   0   0]\n",
      " [  3   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       131\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       131\n",
      "   macro avg       0.33      0.31      0.32       131\n",
      "weighted avg       1.00      0.94      0.97       131\n",
      "Acc@1: 100.000 ( 93.893)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 131/317]  Time: 0.038s (0.040s,   24.72/s)  Loss:  0.5515 (0.6100)  \n",
      "Conf Mat:\n",
      " [[124   0   0]\n",
      " [  5   0   0]\n",
      " [  3   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       132\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       132\n",
      "   macro avg       0.33      0.31      0.32       132\n",
      "weighted avg       1.00      0.94      0.97       132\n",
      "Acc@1: 100.000 ( 93.939)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 132/317]  Time: 0.029s (0.040s,   24.77/s)  Loss:  1.3882 (0.6159)  \n",
      "Conf Mat:\n",
      " [[124   0   0]\n",
      " [  5   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       133\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       133\n",
      "   macro avg       0.33      0.31      0.32       133\n",
      "weighted avg       1.00      0.93      0.96       133\n",
      "Acc@1:   0.000 ( 93.233)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 133/317]  Time: 0.054s (0.040s,   24.71/s)  Loss:  1.4068 (0.6218)  \n",
      "Conf Mat:\n",
      " [[124   0   0]\n",
      " [  6   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       134\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       134\n",
      "   macro avg       0.33      0.31      0.32       134\n",
      "weighted avg       1.00      0.93      0.96       134\n",
      "Acc@1:   0.000 ( 92.537)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 134/317]  Time: 0.057s (0.041s,   24.64/s)  Loss:  0.5674 (0.6214)  \n",
      "Conf Mat:\n",
      " [[125   0   0]\n",
      " [  6   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       135\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       135\n",
      "   macro avg       0.33      0.31      0.32       135\n",
      "weighted avg       1.00      0.93      0.96       135\n",
      "Acc@1: 100.000 ( 92.593)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 135/317]  Time: 0.048s (0.041s,   24.61/s)  Loss:  0.5619 (0.6209)  \n",
      "Conf Mat:\n",
      " [[126   0   0]\n",
      " [  6   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       136\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       136\n",
      "   macro avg       0.33      0.31      0.32       136\n",
      "weighted avg       1.00      0.93      0.96       136\n",
      "Acc@1: 100.000 ( 92.647)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 136/317]  Time: 0.041s (0.041s,   24.60/s)  Loss:  0.5514 (0.6204)  \n",
      "Conf Mat:\n",
      " [[127   0   0]\n",
      " [  6   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       137\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.33      0.31      0.32       137\n",
      "weighted avg       1.00      0.93      0.96       137\n",
      "Acc@1: 100.000 ( 92.701)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 137/317]  Time: 0.058s (0.041s,   24.53/s)  Loss:  0.5514 (0.6199)  \n",
      "Conf Mat:\n",
      " [[128   0   0]\n",
      " [  6   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       138\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       138\n",
      "   macro avg       0.33      0.31      0.32       138\n",
      "weighted avg       1.00      0.93      0.96       138\n",
      "Acc@1: 100.000 ( 92.754)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 138/317]  Time: 0.057s (0.041s,   24.46/s)  Loss:  0.5989 (0.6198)  \n",
      "Conf Mat:\n",
      " [[129   0   0]\n",
      " [  6   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       139\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       139\n",
      "   macro avg       0.33      0.31      0.32       139\n",
      "weighted avg       1.00      0.93      0.96       139\n",
      "Acc@1: 100.000 ( 92.806)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 139/317]  Time: 0.058s (0.041s,   24.39/s)  Loss:  0.5514 (0.6193)  \n",
      "Conf Mat:\n",
      " [[130   0   0]\n",
      " [  6   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       140\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       140\n",
      "   macro avg       0.33      0.31      0.32       140\n",
      "weighted avg       1.00      0.93      0.96       140\n",
      "Acc@1: 100.000 ( 92.857)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 140/317]  Time: 0.040s (0.041s,   24.39/s)  Loss:  0.5543 (0.6188)  \n",
      "Conf Mat:\n",
      " [[131   0   0]\n",
      " [  6   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       141\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       141\n",
      "   macro avg       0.33      0.31      0.32       141\n",
      "weighted avg       1.00      0.93      0.96       141\n",
      "Acc@1: 100.000 ( 92.908)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 141/317]  Time: 0.047s (0.041s,   24.36/s)  Loss:  0.5517 (0.6183)  \n",
      "Conf Mat:\n",
      " [[132   0   0]\n",
      " [  6   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       142\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       142\n",
      "   macro avg       0.33      0.31      0.32       142\n",
      "weighted avg       1.00      0.93      0.96       142\n",
      "Acc@1: 100.000 ( 92.958)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 142/317]  Time: 0.053s (0.041s,   24.31/s)  Loss:  0.6486 (0.6186)  \n",
      "Conf Mat:\n",
      " [[133   0   0]\n",
      " [  6   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       143\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       143\n",
      "   macro avg       0.33      0.31      0.32       143\n",
      "weighted avg       1.00      0.93      0.96       143\n",
      "Acc@1: 100.000 ( 93.007)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 143/317]  Time: 0.055s (0.041s,   24.26/s)  Loss:  0.5514 (0.6181)  \n",
      "Conf Mat:\n",
      " [[134   0   0]\n",
      " [  6   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       144\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       144\n",
      "   macro avg       0.33      0.31      0.32       144\n",
      "weighted avg       1.00      0.93      0.96       144\n",
      "Acc@1: 100.000 ( 93.056)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 144/317]  Time: 0.052s (0.041s,   24.22/s)  Loss:  0.5515 (0.6176)  \n",
      "Conf Mat:\n",
      " [[135   0   0]\n",
      " [  6   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       145\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       145\n",
      "   macro avg       0.33      0.31      0.32       145\n",
      "weighted avg       1.00      0.93      0.96       145\n",
      "Acc@1: 100.000 ( 93.103)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 145/317]  Time: 0.046s (0.041s,   24.19/s)  Loss:  0.5611 (0.6172)  \n",
      "Conf Mat:\n",
      " [[136   0   0]\n",
      " [  6   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       146\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       146\n",
      "   macro avg       0.33      0.31      0.32       146\n",
      "weighted avg       1.00      0.93      0.96       146\n",
      "Acc@1: 100.000 ( 93.151)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 146/317]  Time: 0.064s (0.041s,   24.11/s)  Loss:  0.5515 (0.6168)  \n",
      "Conf Mat:\n",
      " [[137   0   0]\n",
      " [  6   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       147\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       147\n",
      "   macro avg       0.33      0.31      0.32       147\n",
      "weighted avg       1.00      0.93      0.96       147\n",
      "Acc@1: 100.000 ( 93.197)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 147/317]  Time: 0.054s (0.042s,   24.06/s)  Loss:  0.5515 (0.6164)  \n",
      "Conf Mat:\n",
      " [[138   0   0]\n",
      " [  6   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97       148\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       148\n",
      "   macro avg       0.33      0.31      0.32       148\n",
      "weighted avg       1.00      0.93      0.97       148\n",
      "Acc@1: 100.000 ( 93.243)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 148/317]  Time: 0.033s (0.042s,   24.09/s)  Loss:  0.5515 (0.6159)  \n",
      "Conf Mat:\n",
      " [[139   0   0]\n",
      " [  6   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97       149\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       149\n",
      "   macro avg       0.33      0.31      0.32       149\n",
      "weighted avg       1.00      0.93      0.97       149\n",
      "Acc@1: 100.000 ( 93.289)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 149/317]  Time: 0.042s (0.042s,   24.09/s)  Loss:  0.5515 (0.6155)  \n",
      "Conf Mat:\n",
      " [[140   0   0]\n",
      " [  6   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97       150\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       150\n",
      "   macro avg       0.33      0.31      0.32       150\n",
      "weighted avg       1.00      0.93      0.97       150\n",
      "Acc@1: 100.000 ( 93.333)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 150/317]  Time: 0.041s (0.042s,   24.09/s)  Loss:  0.5515 (0.6151)  \n",
      "Conf Mat:\n",
      " [[141   0   0]\n",
      " [  6   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97       151\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       151\n",
      "   macro avg       0.33      0.31      0.32       151\n",
      "weighted avg       1.00      0.93      0.97       151\n",
      "Acc@1: 100.000 ( 93.377)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 151/317]  Time: 0.070s (0.042s,   23.98/s)  Loss:  0.5521 (0.6146)  \n",
      "Conf Mat:\n",
      " [[142   0   0]\n",
      " [  6   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97       152\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       152\n",
      "   macro avg       0.33      0.31      0.32       152\n",
      "weighted avg       1.00      0.93      0.97       152\n",
      "Acc@1: 100.000 ( 93.421)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 152/317]  Time: 0.046s (0.042s,   23.97/s)  Loss:  1.0315 (0.6174)  \n",
      "Conf Mat:\n",
      " [[142   0   0]\n",
      " [  7   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       153\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       153\n",
      "   macro avg       0.33      0.31      0.32       153\n",
      "weighted avg       1.00      0.93      0.96       153\n",
      "Acc@1:   0.000 ( 92.810)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 153/317]  Time: 0.071s (0.042s,   23.86/s)  Loss:  0.5514 (0.6169)  \n",
      "Conf Mat:\n",
      " [[143   0   0]\n",
      " [  7   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       154\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       154\n",
      "   macro avg       0.33      0.31      0.32       154\n",
      "weighted avg       1.00      0.93      0.96       154\n",
      "Acc@1: 100.000 ( 92.857)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 154/317]  Time: 0.071s (0.042s,   23.75/s)  Loss:  0.5518 (0.6165)  \n",
      "Conf Mat:\n",
      " [[144   0   0]\n",
      " [  7   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       155\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       155\n",
      "   macro avg       0.33      0.31      0.32       155\n",
      "weighted avg       1.00      0.93      0.96       155\n",
      "Acc@1: 100.000 ( 92.903)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 155/317]  Time: 0.057s (0.042s,   23.70/s)  Loss:  0.5516 (0.6161)  \n",
      "Conf Mat:\n",
      " [[145   0   0]\n",
      " [  7   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       156\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       156\n",
      "   macro avg       0.33      0.31      0.32       156\n",
      "weighted avg       1.00      0.93      0.96       156\n",
      "Acc@1: 100.000 ( 92.949)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 156/317]  Time: 0.040s (0.042s,   23.71/s)  Loss:  0.5515 (0.6157)  \n",
      "Conf Mat:\n",
      " [[146   0   0]\n",
      " [  7   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       157\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       157\n",
      "   macro avg       0.33      0.31      0.32       157\n",
      "weighted avg       1.00      0.93      0.96       157\n",
      "Acc@1: 100.000 ( 92.994)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 157/317]  Time: 0.037s (0.042s,   23.72/s)  Loss:  0.5518 (0.6153)  \n",
      "Conf Mat:\n",
      " [[147   0   0]\n",
      " [  7   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       158\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       158\n",
      "   macro avg       0.33      0.31      0.32       158\n",
      "weighted avg       1.00      0.93      0.96       158\n",
      "Acc@1: 100.000 ( 93.038)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 158/317]  Time: 0.072s (0.042s,   23.62/s)  Loss:  0.5515 (0.6149)  \n",
      "Conf Mat:\n",
      " [[148   0   0]\n",
      " [  7   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       159\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       159\n",
      "   macro avg       0.33      0.31      0.32       159\n",
      "weighted avg       1.00      0.93      0.96       159\n",
      "Acc@1: 100.000 ( 93.082)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 159/317]  Time: 0.059s (0.042s,   23.56/s)  Loss:  0.5515 (0.6145)  \n",
      "Conf Mat:\n",
      " [[149   0   0]\n",
      " [  7   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       160\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       160\n",
      "   macro avg       0.33      0.31      0.32       160\n",
      "weighted avg       1.00      0.93      0.96       160\n",
      "Acc@1: 100.000 ( 93.125)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 160/317]  Time: 0.043s (0.042s,   23.56/s)  Loss:  0.5689 (0.6142)  \n",
      "Conf Mat:\n",
      " [[150   0   0]\n",
      " [  7   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       161\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       161\n",
      "   macro avg       0.33      0.31      0.32       161\n",
      "weighted avg       1.00      0.93      0.96       161\n",
      "Acc@1: 100.000 ( 93.168)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 161/317]  Time: 0.043s (0.042s,   23.56/s)  Loss:  0.5515 (0.6138)  \n",
      "Conf Mat:\n",
      " [[151   0   0]\n",
      " [  7   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       162\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       162\n",
      "   macro avg       0.33      0.31      0.32       162\n",
      "weighted avg       1.00      0.93      0.96       162\n",
      "Acc@1: 100.000 ( 93.210)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 162/317]  Time: 0.041s (0.042s,   23.56/s)  Loss:  0.5604 (0.6135)  \n",
      "Conf Mat:\n",
      " [[152   0   0]\n",
      " [  7   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97       163\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       163\n",
      "   macro avg       0.33      0.31      0.32       163\n",
      "weighted avg       1.00      0.93      0.97       163\n",
      "Acc@1: 100.000 ( 93.252)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 163/317]  Time: 0.063s (0.043s,   23.50/s)  Loss:  0.5515 (0.6131)  \n",
      "Conf Mat:\n",
      " [[153   0   0]\n",
      " [  7   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97       164\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       164\n",
      "   macro avg       0.33      0.31      0.32       164\n",
      "weighted avg       1.00      0.93      0.97       164\n",
      "Acc@1: 100.000 ( 93.293)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 164/317]  Time: 0.063s (0.043s,   23.43/s)  Loss:  1.1001 (0.6161)  \n",
      "Conf Mat:\n",
      " [[153   0   0]\n",
      " [  8   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       165\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       165\n",
      "   macro avg       0.33      0.31      0.32       165\n",
      "weighted avg       1.00      0.93      0.96       165\n",
      "Acc@1:   0.000 ( 92.727)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 165/317]  Time: 0.029s (0.043s,   23.47/s)  Loss:  0.5515 (0.6157)  \n",
      "Conf Mat:\n",
      " [[154   0   0]\n",
      " [  8   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       166\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       166\n",
      "   macro avg       0.33      0.31      0.32       166\n",
      "weighted avg       1.00      0.93      0.96       166\n",
      "Acc@1: 100.000 ( 92.771)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 166/317]  Time: 0.068s (0.043s,   23.39/s)  Loss:  0.5521 (0.6153)  \n",
      "Conf Mat:\n",
      " [[155   0   0]\n",
      " [  8   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       167\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       167\n",
      "   macro avg       0.33      0.31      0.32       167\n",
      "weighted avg       1.00      0.93      0.96       167\n",
      "Acc@1: 100.000 ( 92.814)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 167/317]  Time: 0.042s (0.043s,   23.39/s)  Loss:  0.5515 (0.6149)  \n",
      "Conf Mat:\n",
      " [[156   0   0]\n",
      " [  8   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       168\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       168\n",
      "   macro avg       0.33      0.31      0.32       168\n",
      "weighted avg       1.00      0.93      0.96       168\n",
      "Acc@1: 100.000 ( 92.857)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 168/317]  Time: 0.062s (0.043s,   23.33/s)  Loss:  0.5515 (0.6145)  \n",
      "Conf Mat:\n",
      " [[157   0   0]\n",
      " [  8   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       169\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       169\n",
      "   macro avg       0.33      0.31      0.32       169\n",
      "weighted avg       1.00      0.93      0.96       169\n",
      "Acc@1: 100.000 ( 92.899)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 169/317]  Time: 0.043s (0.043s,   23.33/s)  Loss:  1.0924 (0.6174)  \n",
      "Conf Mat:\n",
      " [[157   0   0]\n",
      " [  9   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96       170\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92       170\n",
      "   macro avg       0.33      0.31      0.32       170\n",
      "weighted avg       1.00      0.92      0.96       170\n",
      "Acc@1:   0.000 ( 92.353)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 170/317]  Time: 0.062s (0.043s,   23.27/s)  Loss:  0.5515 (0.6170)  \n",
      "Conf Mat:\n",
      " [[158   0   0]\n",
      " [  9   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96       171\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92       171\n",
      "   macro avg       0.33      0.31      0.32       171\n",
      "weighted avg       1.00      0.92      0.96       171\n",
      "Acc@1: 100.000 ( 92.398)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 171/317]  Time: 0.041s (0.043s,   23.27/s)  Loss:  0.5519 (0.6166)  \n",
      "Conf Mat:\n",
      " [[159   0   0]\n",
      " [  9   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96       172\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92       172\n",
      "   macro avg       0.33      0.31      0.32       172\n",
      "weighted avg       1.00      0.92      0.96       172\n",
      "Acc@1: 100.000 ( 92.442)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 172/317]  Time: 0.056s (0.043s,   23.23/s)  Loss:  0.5516 (0.6162)  \n",
      "Conf Mat:\n",
      " [[160   0   0]\n",
      " [  9   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96       173\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92       173\n",
      "   macro avg       0.33      0.31      0.32       173\n",
      "weighted avg       1.00      0.92      0.96       173\n",
      "Acc@1: 100.000 ( 92.486)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 173/317]  Time: 0.042s (0.043s,   23.24/s)  Loss:  0.5515 (0.6158)  \n",
      "Conf Mat:\n",
      " [[161   0   0]\n",
      " [  9   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       174\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       174\n",
      "   macro avg       0.33      0.31      0.32       174\n",
      "weighted avg       1.00      0.93      0.96       174\n",
      "Acc@1: 100.000 ( 92.529)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 174/317]  Time: 0.037s (0.043s,   23.25/s)  Loss:  0.5521 (0.6155)  \n",
      "Conf Mat:\n",
      " [[162   0   0]\n",
      " [  9   0   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       175\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       175\n",
      "   macro avg       0.33      0.31      0.32       175\n",
      "weighted avg       1.00      0.93      0.96       175\n",
      "Acc@1: 100.000 ( 92.571)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 175/317]  Time: 0.048s (0.043s,   23.24/s)  Loss:  0.5554 (0.6151)  \n",
      "Conf Mat:\n",
      " [[162   0   0]\n",
      " [  9   1   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       175\n",
      "           1       0.10      1.00      0.18         1\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       176\n",
      "   macro avg       0.37      0.64      0.38       176\n",
      "weighted avg       0.99      0.93      0.96       176\n",
      "Acc@1: 100.000 ( 92.614)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 176/317]  Time: 0.055s (0.043s,   23.20/s)  Loss:  0.5514 (0.6148)  \n",
      "Conf Mat:\n",
      " [[162   0   0]\n",
      " [  9   2   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       175\n",
      "           1       0.18      1.00      0.31         2\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       177\n",
      "   macro avg       0.39      0.64      0.42       177\n",
      "weighted avg       0.99      0.93      0.95       177\n",
      "Acc@1: 100.000 ( 92.655)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 177/317]  Time: 0.048s (0.043s,   23.19/s)  Loss:  0.5514 (0.6144)  \n",
      "Conf Mat:\n",
      " [[162   0   0]\n",
      " [  9   3   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       175\n",
      "           1       0.25      1.00      0.40         3\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       178\n",
      "   macro avg       0.42      0.64      0.45       178\n",
      "weighted avg       0.99      0.93      0.95       178\n",
      "Acc@1: 100.000 ( 92.697)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 178/317]  Time: 0.038s (0.043s,   23.21/s)  Loss:  0.5515 (0.6141)  \n",
      "Conf Mat:\n",
      " [[162   0   0]\n",
      " [  9   4   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       175\n",
      "           1       0.31      1.00      0.47         4\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       179\n",
      "   macro avg       0.44      0.64      0.48       179\n",
      "weighted avg       0.98      0.93      0.95       179\n",
      "Acc@1: 100.000 ( 92.737)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 179/317]  Time: 0.054s (0.043s,   23.17/s)  Loss:  0.5515 (0.6137)  \n",
      "Conf Mat:\n",
      " [[162   0   0]\n",
      " [  9   5   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       175\n",
      "           1       0.36      1.00      0.53         5\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       180\n",
      "   macro avg       0.45      0.64      0.50       180\n",
      "weighted avg       0.98      0.93      0.95       180\n",
      "Acc@1: 100.000 ( 92.778)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 180/317]  Time: 0.045s (0.043s,   23.17/s)  Loss:  0.5514 (0.6134)  \n",
      "Conf Mat:\n",
      " [[162   0   0]\n",
      " [  9   6   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       175\n",
      "           1       0.40      1.00      0.57         6\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       181\n",
      "   macro avg       0.47      0.64      0.51       181\n",
      "weighted avg       0.98      0.93      0.95       181\n",
      "Acc@1: 100.000 ( 92.818)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 181/317]  Time: 0.066s (0.043s,   23.10/s)  Loss:  0.6796 (0.6137)  \n",
      "Conf Mat:\n",
      " [[162   0   0]\n",
      " [  9   7   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       175\n",
      "           1       0.44      1.00      0.61         7\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       182\n",
      "   macro avg       0.48      0.64      0.52       182\n",
      "weighted avg       0.98      0.93      0.95       182\n",
      "Acc@1: 100.000 ( 92.857)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 182/317]  Time: 0.058s (0.043s,   23.06/s)  Loss:  0.5531 (0.6134)  \n",
      "Conf Mat:\n",
      " [[162   0   0]\n",
      " [  9   8   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       175\n",
      "           1       0.47      1.00      0.64         8\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       183\n",
      "   macro avg       0.49      0.64      0.53       183\n",
      "weighted avg       0.98      0.93      0.95       183\n",
      "Acc@1: 100.000 ( 92.896)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 183/317]  Time: 0.049s (0.043s,   23.04/s)  Loss:  0.5515 (0.6131)  \n",
      "Conf Mat:\n",
      " [[162   0   0]\n",
      " [  9   9   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       175\n",
      "           1       0.50      1.00      0.67         9\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       184\n",
      "   macro avg       0.50      0.64      0.54       184\n",
      "weighted avg       0.98      0.93      0.95       184\n",
      "Acc@1: 100.000 ( 92.935)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 184/317]  Time: 0.058s (0.043s,   23.00/s)  Loss:  0.5514 (0.6127)  \n",
      "Conf Mat:\n",
      " [[162   0   0]\n",
      " [  9  10   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       175\n",
      "           1       0.53      1.00      0.69        10\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       185\n",
      "   macro avg       0.51      0.64      0.55       185\n",
      "weighted avg       0.97      0.93      0.95       185\n",
      "Acc@1: 100.000 ( 92.973)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 185/317]  Time: 0.045s (0.043s,   22.99/s)  Loss:  0.5515 (0.6124)  \n",
      "Conf Mat:\n",
      " [[162   0   0]\n",
      " [  9  11   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       175\n",
      "           1       0.55      1.00      0.71        11\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       186\n",
      "   macro avg       0.52      0.64      0.56       186\n",
      "weighted avg       0.97      0.93      0.95       186\n",
      "Acc@1: 100.000 ( 93.011)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 186/317]  Time: 0.039s (0.043s,   23.00/s)  Loss:  0.6535 (0.6126)  \n",
      "Conf Mat:\n",
      " [[162   0   0]\n",
      " [  9  12   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       175\n",
      "           1       0.57      1.00      0.73        12\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       187\n",
      "   macro avg       0.52      0.64      0.56       187\n",
      "weighted avg       0.97      0.93      0.95       187\n",
      "Acc@1: 100.000 ( 93.048)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 187/317]  Time: 0.038s (0.043s,   23.02/s)  Loss:  0.5515 (0.6123)  \n",
      "Conf Mat:\n",
      " [[162   0   0]\n",
      " [  9  13   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       175\n",
      "           1       0.59      1.00      0.74        13\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       188\n",
      "   macro avg       0.53      0.64      0.57       188\n",
      "weighted avg       0.97      0.93      0.95       188\n",
      "Acc@1: 100.000 ( 93.085)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 188/317]  Time: 0.032s (0.043s,   23.05/s)  Loss:  0.5515 (0.6120)  \n",
      "Conf Mat:\n",
      " [[162   0   0]\n",
      " [  9  14   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       175\n",
      "           1       0.61      1.00      0.76        14\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       189\n",
      "   macro avg       0.54      0.64      0.57       189\n",
      "weighted avg       0.97      0.93      0.95       189\n",
      "Acc@1: 100.000 ( 93.122)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 189/317]  Time: 0.065s (0.043s,   22.99/s)  Loss:  0.5524 (0.6117)  \n",
      "Conf Mat:\n",
      " [[162   0   0]\n",
      " [  9  15   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       175\n",
      "           1       0.62      1.00      0.77        15\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       190\n",
      "   macro avg       0.54      0.64      0.58       190\n",
      "weighted avg       0.97      0.93      0.95       190\n",
      "Acc@1: 100.000 ( 93.158)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 190/317]  Time: 0.033s (0.043s,   23.02/s)  Loss:  0.5516 (0.6114)  \n",
      "Conf Mat:\n",
      " [[162   0   0]\n",
      " [  9  16   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       175\n",
      "           1       0.64      1.00      0.78        16\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       191\n",
      "   macro avg       0.55      0.64      0.58       191\n",
      "weighted avg       0.97      0.93      0.95       191\n",
      "Acc@1: 100.000 ( 93.194)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 191/317]  Time: 0.030s (0.043s,   23.06/s)  Loss:  0.5514 (0.6110)  \n",
      "Conf Mat:\n",
      " [[162   0   0]\n",
      " [  9  17   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       175\n",
      "           1       0.65      1.00      0.79        17\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       192\n",
      "   macro avg       0.55      0.64      0.58       192\n",
      "weighted avg       0.97      0.93      0.95       192\n",
      "Acc@1: 100.000 ( 93.229)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 192/317]  Time: 0.029s (0.043s,   23.10/s)  Loss:  0.5515 (0.6107)  \n",
      "Conf Mat:\n",
      " [[162   0   0]\n",
      " [  9  18   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       175\n",
      "           1       0.67      1.00      0.80        18\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       193\n",
      "   macro avg       0.56      0.64      0.59       193\n",
      "weighted avg       0.97      0.93      0.95       193\n",
      "Acc@1: 100.000 ( 93.264)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 193/317]  Time: 0.036s (0.043s,   23.12/s)  Loss:  0.7806 (0.6116)  \n",
      "Conf Mat:\n",
      " [[162   0   0]\n",
      " [  9  19   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       175\n",
      "           1       0.68      1.00      0.81        19\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       194\n",
      "   macro avg       0.56      0.64      0.59       194\n",
      "weighted avg       0.97      0.93      0.95       194\n",
      "Acc@1: 100.000 ( 93.299)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 194/317]  Time: 0.029s (0.043s,   23.16/s)  Loss:  0.5514 (0.6113)  \n",
      "Conf Mat:\n",
      " [[162   0   0]\n",
      " [  9  20   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       175\n",
      "           1       0.69      1.00      0.82        20\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       195\n",
      "   macro avg       0.56      0.64      0.59       195\n",
      "weighted avg       0.97      0.93      0.95       195\n",
      "Acc@1: 100.000 ( 93.333)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 195/317]  Time: 0.040s (0.043s,   23.17/s)  Loss:  0.5517 (0.6110)  \n",
      "Conf Mat:\n",
      " [[162   0   0]\n",
      " [  9  21   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       175\n",
      "           1       0.70      1.00      0.82        21\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       196\n",
      "   macro avg       0.57      0.64      0.59       196\n",
      "weighted avg       0.97      0.93      0.95       196\n",
      "Acc@1: 100.000 ( 93.367)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 196/317]  Time: 0.027s (0.043s,   23.21/s)  Loss:  1.4429 (0.6152)  \n",
      "Conf Mat:\n",
      " [[162   1   0]\n",
      " [  9  21   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       175\n",
      "           1       0.70      0.95      0.81        22\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       197\n",
      "   macro avg       0.56      0.63      0.59       197\n",
      "weighted avg       0.96      0.93      0.94       197\n",
      "Acc@1:   0.000 ( 92.893)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 197/317]  Time: 0.059s (0.043s,   23.17/s)  Loss:  0.5890 (0.6151)  \n",
      "Conf Mat:\n",
      " [[162   1   0]\n",
      " [  9  22   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       175\n",
      "           1       0.71      0.96      0.81        23\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       198\n",
      "   macro avg       0.57      0.63      0.59       198\n",
      "weighted avg       0.96      0.93      0.94       198\n",
      "Acc@1: 100.000 ( 92.929)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 198/317]  Time: 0.036s (0.043s,   23.19/s)  Loss:  0.5514 (0.6148)  \n",
      "Conf Mat:\n",
      " [[162   1   0]\n",
      " [  9  23   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       175\n",
      "           1       0.72      0.96      0.82        24\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       199\n",
      "   macro avg       0.57      0.63      0.59       199\n",
      "weighted avg       0.96      0.93      0.94       199\n",
      "Acc@1: 100.000 ( 92.965)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 199/317]  Time: 0.031s (0.043s,   23.22/s)  Loss:  0.5514 (0.6145)  \n",
      "Conf Mat:\n",
      " [[162   1   0]\n",
      " [  9  24   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       175\n",
      "           1       0.73      0.96      0.83        25\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       200\n",
      "   macro avg       0.57      0.63      0.60       200\n",
      "weighted avg       0.96      0.93      0.94       200\n",
      "Acc@1: 100.000 ( 93.000)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 200/317]  Time: 0.030s (0.043s,   23.26/s)  Loss:  0.5515 (0.6141)  \n",
      "Conf Mat:\n",
      " [[162   1   0]\n",
      " [  9  25   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       175\n",
      "           1       0.74      0.96      0.83        26\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       201\n",
      "   macro avg       0.58      0.63      0.60       201\n",
      "weighted avg       0.96      0.93      0.94       201\n",
      "Acc@1: 100.000 ( 93.035)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 201/317]  Time: 0.027s (0.043s,   23.30/s)  Loss:  0.5514 (0.6138)  \n",
      "Conf Mat:\n",
      " [[162   1   0]\n",
      " [  9  26   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       175\n",
      "           1       0.74      0.96      0.84        27\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       202\n",
      "   macro avg       0.58      0.63      0.60       202\n",
      "weighted avg       0.96      0.93      0.94       202\n",
      "Acc@1: 100.000 ( 93.069)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 202/317]  Time: 0.030s (0.043s,   23.34/s)  Loss:  1.3169 (0.6173)  \n",
      "Conf Mat:\n",
      " [[162   2   0]\n",
      " [  9  26   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       175\n",
      "           1       0.74      0.93      0.83        28\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       203\n",
      "   macro avg       0.58      0.62      0.59       203\n",
      "weighted avg       0.95      0.93      0.94       203\n",
      "Acc@1:   0.000 ( 92.611)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 203/317]  Time: 0.031s (0.043s,   23.37/s)  Loss:  1.1496 (0.6199)  \n",
      "Conf Mat:\n",
      " [[162   3   0]\n",
      " [  9  26   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95       175\n",
      "           1       0.74      0.90      0.81        29\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92       204\n",
      "   macro avg       0.57      0.61      0.59       204\n",
      "weighted avg       0.95      0.92      0.93       204\n",
      "Acc@1:   0.000 ( 92.157)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 204/317]  Time: 0.031s (0.043s,   23.40/s)  Loss:  0.5670 (0.6196)  \n",
      "Conf Mat:\n",
      " [[162   3   0]\n",
      " [  9  27   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95       175\n",
      "           1       0.75      0.90      0.82        30\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92       205\n",
      "   macro avg       0.58      0.61      0.59       205\n",
      "weighted avg       0.95      0.92      0.93       205\n",
      "Acc@1: 100.000 ( 92.195)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 205/317]  Time: 0.031s (0.043s,   23.43/s)  Loss:  1.3645 (0.6233)  \n",
      "Conf Mat:\n",
      " [[162   4   0]\n",
      " [  9  27   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95       175\n",
      "           1       0.75      0.87      0.81        31\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92       206\n",
      "   macro avg       0.58      0.60      0.59       206\n",
      "weighted avg       0.94      0.92      0.93       206\n",
      "Acc@1:   0.000 ( 91.748)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 206/317]  Time: 0.028s (0.043s,   23.47/s)  Loss:  0.5514 (0.6229)  \n",
      "Conf Mat:\n",
      " [[162   4   0]\n",
      " [  9  28   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95       175\n",
      "           1       0.76      0.88      0.81        32\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92       207\n",
      "   macro avg       0.58      0.60      0.59       207\n",
      "weighted avg       0.94      0.92      0.93       207\n",
      "Acc@1: 100.000 ( 91.787)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 207/317]  Time: 0.043s (0.043s,   23.47/s)  Loss:  1.4894 (0.6271)  \n",
      "Conf Mat:\n",
      " [[162   5   0]\n",
      " [  9  28   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       175\n",
      "           1       0.76      0.85      0.80        33\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       208\n",
      "   macro avg       0.58      0.59      0.58       208\n",
      "weighted avg       0.94      0.91      0.92       208\n",
      "Acc@1:   0.000 ( 91.346)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 208/317]  Time: 0.031s (0.043s,   23.50/s)  Loss:  0.6878 (0.6274)  \n",
      "Conf Mat:\n",
      " [[162   5   0]\n",
      " [  9  29   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       175\n",
      "           1       0.76      0.85      0.81        34\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       209\n",
      "   macro avg       0.58      0.59      0.58       209\n",
      "weighted avg       0.94      0.91      0.92       209\n",
      "Acc@1: 100.000 ( 91.388)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 209/317]  Time: 0.028s (0.042s,   23.53/s)  Loss:  1.0416 (0.6293)  \n",
      "Conf Mat:\n",
      " [[162   6   0]\n",
      " [  9  29   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       175\n",
      "           1       0.76      0.83      0.79        35\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       210\n",
      "   macro avg       0.58      0.58      0.58       210\n",
      "weighted avg       0.93      0.91      0.92       210\n",
      "Acc@1:   0.000 ( 90.952)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 210/317]  Time: 0.040s (0.042s,   23.54/s)  Loss:  0.5514 (0.6290)  \n",
      "Conf Mat:\n",
      " [[162   6   0]\n",
      " [  9  30   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       175\n",
      "           1       0.77      0.83      0.80        36\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       211\n",
      "   macro avg       0.58      0.59      0.58       211\n",
      "weighted avg       0.93      0.91      0.92       211\n",
      "Acc@1: 100.000 ( 90.995)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 211/317]  Time: 0.031s (0.042s,   23.57/s)  Loss:  0.5514 (0.6286)  \n",
      "Conf Mat:\n",
      " [[162   6   0]\n",
      " [  9  31   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       175\n",
      "           1       0.78      0.84      0.81        37\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       212\n",
      "   macro avg       0.58      0.59      0.58       212\n",
      "weighted avg       0.93      0.91      0.92       212\n",
      "Acc@1: 100.000 ( 91.038)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 212/317]  Time: 0.028s (0.042s,   23.61/s)  Loss:  0.5514 (0.6282)  \n",
      "Conf Mat:\n",
      " [[162   6   0]\n",
      " [  9  32   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       175\n",
      "           1       0.78      0.84      0.81        38\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       213\n",
      "   macro avg       0.58      0.59      0.58       213\n",
      "weighted avg       0.93      0.91      0.92       213\n",
      "Acc@1: 100.000 ( 91.080)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 213/317]  Time: 0.049s (0.042s,   23.59/s)  Loss:  0.5515 (0.6279)  \n",
      "Conf Mat:\n",
      " [[162   6   0]\n",
      " [  9  33   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       175\n",
      "           1       0.79      0.85      0.81        39\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       214\n",
      "   macro avg       0.58      0.59      0.59       214\n",
      "weighted avg       0.93      0.91      0.92       214\n",
      "Acc@1: 100.000 ( 91.121)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 214/317]  Time: 0.040s (0.042s,   23.60/s)  Loss:  0.7813 (0.6286)  \n",
      "Conf Mat:\n",
      " [[162   6   0]\n",
      " [  9  34   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       175\n",
      "           1       0.79      0.85      0.82        40\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       215\n",
      "   macro avg       0.58      0.59      0.59       215\n",
      "weighted avg       0.93      0.91      0.92       215\n",
      "Acc@1: 100.000 ( 91.163)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 215/317]  Time: 0.034s (0.042s,   23.62/s)  Loss:  0.5886 (0.6284)  \n",
      "Conf Mat:\n",
      " [[162   6   0]\n",
      " [  9  35   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       175\n",
      "           1       0.80      0.85      0.82        41\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.59      0.59      0.59       216\n",
      "weighted avg       0.93      0.91      0.92       216\n",
      "Acc@1: 100.000 ( 91.204)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 216/317]  Time: 0.033s (0.042s,   23.65/s)  Loss:  0.5529 (0.6281)  \n",
      "Conf Mat:\n",
      " [[162   6   0]\n",
      " [  9  36   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       175\n",
      "           1       0.80      0.86      0.83        42\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       217\n",
      "   macro avg       0.59      0.59      0.59       217\n",
      "weighted avg       0.93      0.91      0.92       217\n",
      "Acc@1: 100.000 ( 91.244)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 217/317]  Time: 0.040s (0.042s,   23.65/s)  Loss:  0.5516 (0.6277)  \n",
      "Conf Mat:\n",
      " [[162   6   0]\n",
      " [  9  37   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       175\n",
      "           1       0.80      0.86      0.83        43\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       218\n",
      "   macro avg       0.59      0.60      0.59       218\n",
      "weighted avg       0.93      0.91      0.92       218\n",
      "Acc@1: 100.000 ( 91.284)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 218/317]  Time: 0.042s (0.042s,   23.65/s)  Loss:  0.5620 (0.6274)  \n",
      "Conf Mat:\n",
      " [[162   6   0]\n",
      " [  9  38   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       175\n",
      "           1       0.81      0.86      0.84        44\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       219\n",
      "   macro avg       0.59      0.60      0.59       219\n",
      "weighted avg       0.93      0.91      0.92       219\n",
      "Acc@1: 100.000 ( 91.324)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 219/317]  Time: 0.032s (0.042s,   23.68/s)  Loss:  0.5537 (0.6271)  \n",
      "Conf Mat:\n",
      " [[162   6   0]\n",
      " [  9  39   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       175\n",
      "           1       0.81      0.87      0.84        45\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       220\n",
      "   macro avg       0.59      0.60      0.59       220\n",
      "weighted avg       0.93      0.91      0.92       220\n",
      "Acc@1: 100.000 ( 91.364)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 220/317]  Time: 0.045s (0.042s,   23.67/s)  Loss:  0.5514 (0.6267)  \n",
      "Conf Mat:\n",
      " [[162   6   0]\n",
      " [  9  40   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       175\n",
      "           1       0.82      0.87      0.84        46\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       221\n",
      "   macro avg       0.59      0.60      0.60       221\n",
      "weighted avg       0.93      0.91      0.92       221\n",
      "Acc@1: 100.000 ( 91.403)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 221/317]  Time: 0.053s (0.042s,   23.65/s)  Loss:  0.5514 (0.6264)  \n",
      "Conf Mat:\n",
      " [[162   6   0]\n",
      " [  9  41   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       175\n",
      "           1       0.82      0.87      0.85        47\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       222\n",
      "   macro avg       0.59      0.60      0.60       222\n",
      "weighted avg       0.93      0.91      0.92       222\n",
      "Acc@1: 100.000 ( 91.441)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 222/317]  Time: 0.029s (0.042s,   23.68/s)  Loss:  1.0337 (0.6282)  \n",
      "Conf Mat:\n",
      " [[162   7   0]\n",
      " [  9  41   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       175\n",
      "           1       0.82      0.85      0.84        48\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       223\n",
      "   macro avg       0.59      0.59      0.59       223\n",
      "weighted avg       0.93      0.91      0.92       223\n",
      "Acc@1:   0.000 ( 91.031)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 223/317]  Time: 0.039s (0.042s,   23.69/s)  Loss:  0.5514 (0.6279)  \n",
      "Conf Mat:\n",
      " [[162   7   0]\n",
      " [  9  42   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       175\n",
      "           1       0.82      0.86      0.84        49\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       224\n",
      "   macro avg       0.59      0.59      0.59       224\n",
      "weighted avg       0.93      0.91      0.92       224\n",
      "Acc@1: 100.000 ( 91.071)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 224/317]  Time: 0.045s (0.042s,   23.68/s)  Loss:  0.5985 (0.6278)  \n",
      "Conf Mat:\n",
      " [[162   7   0]\n",
      " [  9  43   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       175\n",
      "           1       0.83      0.86      0.84        50\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       225\n",
      "   macro avg       0.60      0.60      0.59       225\n",
      "weighted avg       0.93      0.91      0.92       225\n",
      "Acc@1: 100.000 ( 91.111)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 225/317]  Time: 0.051s (0.042s,   23.66/s)  Loss:  0.8874 (0.6289)  \n",
      "Conf Mat:\n",
      " [[162   7   0]\n",
      " [  9  44   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       175\n",
      "           1       0.83      0.86      0.85        51\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       226\n",
      "   macro avg       0.60      0.60      0.60       226\n",
      "weighted avg       0.93      0.91      0.92       226\n",
      "Acc@1: 100.000 ( 91.150)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 226/317]  Time: 0.048s (0.042s,   23.64/s)  Loss:  0.5515 (0.6286)  \n",
      "Conf Mat:\n",
      " [[162   7   0]\n",
      " [  9  45   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       175\n",
      "           1       0.83      0.87      0.85        52\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       227\n",
      "   macro avg       0.60      0.60      0.60       227\n",
      "weighted avg       0.93      0.91      0.92       227\n",
      "Acc@1: 100.000 ( 91.189)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 227/317]  Time: 0.032s (0.042s,   23.67/s)  Loss:  0.5514 (0.6282)  \n",
      "Conf Mat:\n",
      " [[162   7   0]\n",
      " [  9  46   0]\n",
      " [  4   0   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       175\n",
      "           1       0.84      0.87      0.85        53\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       228\n",
      "   macro avg       0.60      0.60      0.60       228\n",
      "weighted avg       0.93      0.91      0.92       228\n",
      "Acc@1: 100.000 ( 91.228)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 228/317]  Time: 0.029s (0.042s,   23.70/s)  Loss:  1.5420 (0.6322)  \n",
      "Conf Mat:\n",
      " [[162   7   0]\n",
      " [  9  46   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       175\n",
      "           1       0.84      0.85      0.84        54\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       229\n",
      "   macro avg       0.60      0.59      0.60       229\n",
      "weighted avg       0.93      0.91      0.92       229\n",
      "Acc@1:   0.000 ( 90.830)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 229/317]  Time: 0.039s (0.042s,   23.71/s)  Loss:  0.5967 (0.6321)  \n",
      "Conf Mat:\n",
      " [[162   7   0]\n",
      " [  9  47   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       175\n",
      "           1       0.84      0.85      0.85        55\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       230\n",
      "   macro avg       0.60      0.59      0.60       230\n",
      "weighted avg       0.93      0.91      0.92       230\n",
      "Acc@1: 100.000 ( 90.870)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 230/317]  Time: 0.028s (0.042s,   23.74/s)  Loss:  0.5782 (0.6318)  \n",
      "Conf Mat:\n",
      " [[162   7   0]\n",
      " [  9  48   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       175\n",
      "           1       0.84      0.86      0.85        56\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       231\n",
      "   macro avg       0.60      0.59      0.60       231\n",
      "weighted avg       0.93      0.91      0.92       231\n",
      "Acc@1: 100.000 ( 90.909)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 231/317]  Time: 0.041s (0.042s,   23.75/s)  Loss:  0.5558 (0.6315)  \n",
      "Conf Mat:\n",
      " [[162   7   0]\n",
      " [  9  49   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       175\n",
      "           1       0.84      0.86      0.85        57\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       232\n",
      "   macro avg       0.60      0.60      0.60       232\n",
      "weighted avg       0.93      0.91      0.92       232\n",
      "Acc@1: 100.000 ( 90.948)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 232/317]  Time: 0.035s (0.042s,   23.77/s)  Loss:  1.4403 (0.6350)  \n",
      "Conf Mat:\n",
      " [[162   8   0]\n",
      " [  9  49   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       175\n",
      "           1       0.84      0.84      0.84        58\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       233\n",
      "   macro avg       0.60      0.59      0.59       233\n",
      "weighted avg       0.93      0.91      0.92       233\n",
      "Acc@1:   0.000 ( 90.558)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 233/317]  Time: 0.027s (0.042s,   23.80/s)  Loss:  1.2606 (0.6376)  \n",
      "Conf Mat:\n",
      " [[162   9   0]\n",
      " [  9  49   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       175\n",
      "           1       0.84      0.83      0.84        59\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       234\n",
      "   macro avg       0.60      0.59      0.59       234\n",
      "weighted avg       0.92      0.90      0.91       234\n",
      "Acc@1:   0.000 ( 90.171)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 234/317]  Time: 0.032s (0.042s,   23.83/s)  Loss:  0.5514 (0.6373)  \n",
      "Conf Mat:\n",
      " [[162   9   0]\n",
      " [  9  50   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       175\n",
      "           1       0.85      0.83      0.84        60\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       235\n",
      "   macro avg       0.60      0.59      0.59       235\n",
      "weighted avg       0.92      0.90      0.91       235\n",
      "Acc@1: 100.000 ( 90.213)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 235/317]  Time: 0.035s (0.042s,   23.84/s)  Loss:  0.5514 (0.6369)  \n",
      "Conf Mat:\n",
      " [[162   9   0]\n",
      " [  9  51   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       175\n",
      "           1       0.85      0.84      0.84        61\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       236\n",
      "   macro avg       0.60      0.59      0.59       236\n",
      "weighted avg       0.92      0.90      0.91       236\n",
      "Acc@1: 100.000 ( 90.254)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 236/317]  Time: 0.030s (0.042s,   23.87/s)  Loss:  0.5514 (0.6366)  \n",
      "Conf Mat:\n",
      " [[162   9   0]\n",
      " [  9  52   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       175\n",
      "           1       0.85      0.84      0.85        62\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       237\n",
      "   macro avg       0.60      0.59      0.59       237\n",
      "weighted avg       0.92      0.90      0.91       237\n",
      "Acc@1: 100.000 ( 90.295)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 237/317]  Time: 0.049s (0.042s,   23.86/s)  Loss:  0.5514 (0.6362)  \n",
      "Conf Mat:\n",
      " [[162   9   0]\n",
      " [  9  53   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       175\n",
      "           1       0.85      0.84      0.85        63\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       238\n",
      "   macro avg       0.60      0.59      0.59       238\n",
      "weighted avg       0.92      0.90      0.91       238\n",
      "Acc@1: 100.000 ( 90.336)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 238/317]  Time: 0.029s (0.042s,   23.89/s)  Loss:  0.5523 (0.6358)  \n",
      "Conf Mat:\n",
      " [[162   9   0]\n",
      " [  9  54   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       175\n",
      "           1       0.86      0.84      0.85        64\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       239\n",
      "   macro avg       0.60      0.59      0.60       239\n",
      "weighted avg       0.92      0.90      0.91       239\n",
      "Acc@1: 100.000 ( 90.377)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 239/317]  Time: 0.032s (0.042s,   23.91/s)  Loss:  0.5521 (0.6355)  \n",
      "Conf Mat:\n",
      " [[162   9   0]\n",
      " [  9  55   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       175\n",
      "           1       0.86      0.85      0.85        65\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       240\n",
      "   macro avg       0.60      0.59      0.60       240\n",
      "weighted avg       0.92      0.90      0.91       240\n",
      "Acc@1: 100.000 ( 90.417)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 240/317]  Time: 0.032s (0.042s,   23.93/s)  Loss:  0.7934 (0.6362)  \n",
      "Conf Mat:\n",
      " [[162   9   0]\n",
      " [  9  56   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       175\n",
      "           1       0.86      0.85      0.85        66\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       241\n",
      "   macro avg       0.60      0.59      0.60       241\n",
      "weighted avg       0.92      0.90      0.91       241\n",
      "Acc@1: 100.000 ( 90.456)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 241/317]  Time: 0.030s (0.042s,   23.96/s)  Loss:  1.3547 (0.6391)  \n",
      "Conf Mat:\n",
      " [[162  10   0]\n",
      " [  9  56   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       175\n",
      "           1       0.86      0.84      0.85        67\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       242\n",
      "   macro avg       0.60      0.59      0.59       242\n",
      "weighted avg       0.92      0.90      0.91       242\n",
      "Acc@1:   0.000 ( 90.083)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 242/317]  Time: 0.032s (0.042s,   23.99/s)  Loss:  1.5075 (0.6427)  \n",
      "Conf Mat:\n",
      " [[162  11   0]\n",
      " [  9  56   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       175\n",
      "           1       0.86      0.82      0.84        68\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       243\n",
      "   macro avg       0.60      0.58      0.59       243\n",
      "weighted avg       0.92      0.90      0.91       243\n",
      "Acc@1:   0.000 ( 89.712)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 243/317]  Time: 0.046s (0.042s,   23.97/s)  Loss:  0.6202 (0.6426)  \n",
      "Conf Mat:\n",
      " [[162  11   0]\n",
      " [  9  57   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       175\n",
      "           1       0.86      0.83      0.84        69\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       244\n",
      "   macro avg       0.60      0.58      0.59       244\n",
      "weighted avg       0.92      0.90      0.91       244\n",
      "Acc@1: 100.000 ( 89.754)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 244/317]  Time: 0.032s (0.042s,   24.00/s)  Loss:  0.5517 (0.6422)  \n",
      "Conf Mat:\n",
      " [[162  11   0]\n",
      " [  9  58   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       175\n",
      "           1       0.87      0.83      0.85        70\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       245\n",
      "   macro avg       0.60      0.58      0.59       245\n",
      "weighted avg       0.92      0.90      0.91       245\n",
      "Acc@1: 100.000 ( 89.796)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 245/317]  Time: 0.038s (0.042s,   24.01/s)  Loss:  0.5516 (0.6419)  \n",
      "Conf Mat:\n",
      " [[162  11   0]\n",
      " [  9  59   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       175\n",
      "           1       0.87      0.83      0.85        71\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       246\n",
      "   macro avg       0.60      0.59      0.59       246\n",
      "weighted avg       0.92      0.90      0.91       246\n",
      "Acc@1: 100.000 ( 89.837)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 246/317]  Time: 0.041s (0.042s,   24.01/s)  Loss:  0.5519 (0.6415)  \n",
      "Conf Mat:\n",
      " [[162  11   0]\n",
      " [  9  60   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       175\n",
      "           1       0.87      0.83      0.85        72\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       247\n",
      "   macro avg       0.60      0.59      0.59       247\n",
      "weighted avg       0.92      0.90      0.91       247\n",
      "Acc@1: 100.000 ( 89.879)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 247/317]  Time: 0.025s (0.042s,   24.05/s)  Loss:  0.5516 (0.6411)  \n",
      "Conf Mat:\n",
      " [[162  11   0]\n",
      " [  9  61   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       175\n",
      "           1       0.87      0.84      0.85        73\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       248\n",
      "   macro avg       0.60      0.59      0.59       248\n",
      "weighted avg       0.92      0.90      0.91       248\n",
      "Acc@1: 100.000 ( 89.919)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 248/317]  Time: 0.056s (0.042s,   24.01/s)  Loss:  0.5514 (0.6408)  \n",
      "Conf Mat:\n",
      " [[162  11   0]\n",
      " [  9  62   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       175\n",
      "           1       0.87      0.84      0.86        74\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       249\n",
      "   macro avg       0.60      0.59      0.60       249\n",
      "weighted avg       0.92      0.90      0.91       249\n",
      "Acc@1: 100.000 ( 89.960)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 249/317]  Time: 0.035s (0.042s,   24.03/s)  Loss:  0.5623 (0.6405)  \n",
      "Conf Mat:\n",
      " [[162  11   0]\n",
      " [  9  63   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       175\n",
      "           1       0.88      0.84      0.86        75\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       250\n",
      "   macro avg       0.60      0.59      0.60       250\n",
      "weighted avg       0.92      0.90      0.91       250\n",
      "Acc@1: 100.000 ( 90.000)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 250/317]  Time: 0.038s (0.042s,   24.04/s)  Loss:  0.5547 (0.6401)  \n",
      "Conf Mat:\n",
      " [[162  11   0]\n",
      " [  9  64   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       175\n",
      "           1       0.88      0.84      0.86        76\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       251\n",
      "   macro avg       0.60      0.59      0.60       251\n",
      "weighted avg       0.92      0.90      0.91       251\n",
      "Acc@1: 100.000 ( 90.040)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 251/317]  Time: 0.044s (0.042s,   24.03/s)  Loss:  0.5540 (0.6398)  \n",
      "Conf Mat:\n",
      " [[162  11   0]\n",
      " [  9  65   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       175\n",
      "           1       0.88      0.84      0.86        77\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       252\n",
      "   macro avg       0.60      0.59      0.60       252\n",
      "weighted avg       0.92      0.90      0.91       252\n",
      "Acc@1: 100.000 ( 90.079)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 252/317]  Time: 0.046s (0.042s,   24.02/s)  Loss:  0.5514 (0.6394)  \n",
      "Conf Mat:\n",
      " [[162  11   0]\n",
      " [  9  66   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       175\n",
      "           1       0.88      0.85      0.86        78\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       253\n",
      "   macro avg       0.61      0.59      0.60       253\n",
      "weighted avg       0.92      0.90      0.91       253\n",
      "Acc@1: 100.000 ( 90.119)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 253/317]  Time: 0.036s (0.042s,   24.04/s)  Loss:  0.6677 (0.6395)  \n",
      "Conf Mat:\n",
      " [[162  11   0]\n",
      " [  9  67   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       175\n",
      "           1       0.88      0.85      0.86        79\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       254\n",
      "   macro avg       0.61      0.59      0.60       254\n",
      "weighted avg       0.92      0.90      0.91       254\n",
      "Acc@1: 100.000 ( 90.157)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 254/317]  Time: 0.034s (0.042s,   24.05/s)  Loss:  0.5514 (0.6392)  \n",
      "Conf Mat:\n",
      " [[162  11   0]\n",
      " [  9  68   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       175\n",
      "           1       0.88      0.85      0.87        80\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       255\n",
      "   macro avg       0.61      0.59      0.60       255\n",
      "weighted avg       0.92      0.90      0.91       255\n",
      "Acc@1: 100.000 ( 90.196)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 255/317]  Time: 0.035s (0.042s,   24.07/s)  Loss:  0.5514 (0.6389)  \n",
      "Conf Mat:\n",
      " [[162  11   0]\n",
      " [  9  69   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       175\n",
      "           1       0.88      0.85      0.87        81\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       256\n",
      "   macro avg       0.61      0.59      0.60       256\n",
      "weighted avg       0.92      0.90      0.91       256\n",
      "Acc@1: 100.000 ( 90.234)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 256/317]  Time: 0.034s (0.042s,   24.09/s)  Loss:  0.5515 (0.6385)  \n",
      "Conf Mat:\n",
      " [[162  11   0]\n",
      " [  9  70   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       175\n",
      "           1       0.89      0.85      0.87        82\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       257\n",
      "   macro avg       0.61      0.59      0.60       257\n",
      "weighted avg       0.92      0.90      0.91       257\n",
      "Acc@1: 100.000 ( 90.272)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 257/317]  Time: 0.042s (0.042s,   24.09/s)  Loss:  0.5516 (0.6382)  \n",
      "Conf Mat:\n",
      " [[162  11   0]\n",
      " [  9  71   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       175\n",
      "           1       0.89      0.86      0.87        83\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       258\n",
      "   macro avg       0.61      0.59      0.60       258\n",
      "weighted avg       0.92      0.90      0.91       258\n",
      "Acc@1: 100.000 ( 90.310)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 258/317]  Time: 0.034s (0.041s,   24.10/s)  Loss:  0.5529 (0.6378)  \n",
      "Conf Mat:\n",
      " [[162  11   0]\n",
      " [  9  72   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       175\n",
      "           1       0.89      0.86      0.87        84\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       259\n",
      "   macro avg       0.61      0.59      0.60       259\n",
      "weighted avg       0.92      0.90      0.91       259\n",
      "Acc@1: 100.000 ( 90.347)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 259/317]  Time: 0.052s (0.042s,   24.08/s)  Loss:  0.5516 (0.6375)  \n",
      "Conf Mat:\n",
      " [[162  11   0]\n",
      " [  9  73   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       175\n",
      "           1       0.89      0.86      0.87        85\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       260\n",
      "   macro avg       0.61      0.59      0.60       260\n",
      "weighted avg       0.92      0.90      0.91       260\n",
      "Acc@1: 100.000 ( 90.385)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 260/317]  Time: 0.030s (0.041s,   24.10/s)  Loss:  0.5521 (0.6372)  \n",
      "Conf Mat:\n",
      " [[162  11   0]\n",
      " [  9  74   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       175\n",
      "           1       0.89      0.86      0.88        86\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       261\n",
      "   macro avg       0.61      0.60      0.60       261\n",
      "weighted avg       0.92      0.90      0.91       261\n",
      "Acc@1: 100.000 ( 90.421)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 261/317]  Time: 0.031s (0.041s,   24.13/s)  Loss:  0.5538 (0.6369)  \n",
      "Conf Mat:\n",
      " [[162  11   0]\n",
      " [  9  75   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       175\n",
      "           1       0.89      0.86      0.88        87\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       262\n",
      "   macro avg       0.61      0.60      0.60       262\n",
      "weighted avg       0.92      0.90      0.91       262\n",
      "Acc@1: 100.000 ( 90.458)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 262/317]  Time: 0.032s (0.041s,   24.15/s)  Loss:  0.5515 (0.6365)  \n",
      "Conf Mat:\n",
      " [[162  11   0]\n",
      " [  9  76   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       175\n",
      "           1       0.89      0.86      0.88        88\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       263\n",
      "   macro avg       0.61      0.60      0.60       263\n",
      "weighted avg       0.92      0.90      0.91       263\n",
      "Acc@1: 100.000 ( 90.494)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 263/317]  Time: 0.056s (0.041s,   24.12/s)  Loss:  0.5520 (0.6362)  \n",
      "Conf Mat:\n",
      " [[162  11   0]\n",
      " [  9  77   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       175\n",
      "           1       0.90      0.87      0.88        89\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       264\n",
      "   macro avg       0.61      0.60      0.60       264\n",
      "weighted avg       0.92      0.91      0.91       264\n",
      "Acc@1: 100.000 ( 90.530)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 264/317]  Time: 0.074s (0.042s,   24.05/s)  Loss:  0.5514 (0.6359)  \n",
      "Conf Mat:\n",
      " [[162  11   0]\n",
      " [  9  78   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       175\n",
      "           1       0.90      0.87      0.88        90\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       265\n",
      "   macro avg       0.61      0.60      0.60       265\n",
      "weighted avg       0.92      0.91      0.91       265\n",
      "Acc@1: 100.000 ( 90.566)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 265/317]  Time: 0.039s (0.042s,   24.05/s)  Loss:  0.5514 (0.6356)  \n",
      "Conf Mat:\n",
      " [[162  11   0]\n",
      " [  9  79   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       175\n",
      "           1       0.90      0.87      0.88        91\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       266\n",
      "   macro avg       0.61      0.60      0.60       266\n",
      "weighted avg       0.92      0.91      0.91       266\n",
      "Acc@1: 100.000 ( 90.602)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 266/317]  Time: 0.030s (0.042s,   24.08/s)  Loss:  0.5514 (0.6353)  \n",
      "Conf Mat:\n",
      " [[162  11   0]\n",
      " [  9  80   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       175\n",
      "           1       0.90      0.87      0.88        92\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       267\n",
      "   macro avg       0.61      0.60      0.61       267\n",
      "weighted avg       0.92      0.91      0.91       267\n",
      "Acc@1: 100.000 ( 90.637)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 267/317]  Time: 0.059s (0.042s,   24.04/s)  Loss:  0.6614 (0.6354)  \n",
      "Conf Mat:\n",
      " [[162  11   0]\n",
      " [  9  81   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       175\n",
      "           1       0.90      0.87      0.89        93\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       268\n",
      "   macro avg       0.61      0.60      0.61       268\n",
      "weighted avg       0.92      0.91      0.92       268\n",
      "Acc@1: 100.000 ( 90.672)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 268/317]  Time: 0.032s (0.042s,   24.06/s)  Loss:  1.5106 (0.6386)  \n",
      "Conf Mat:\n",
      " [[162  12   0]\n",
      " [  9  81   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.90      0.86      0.88        94\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       269\n",
      "   macro avg       0.61      0.60      0.60       269\n",
      "weighted avg       0.92      0.90      0.91       269\n",
      "Acc@1:   0.000 ( 90.335)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 269/317]  Time: 0.039s (0.042s,   24.06/s)  Loss:  1.3213 (0.6412)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  81   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.90      0.85      0.88        95\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       270\n",
      "   macro avg       0.61      0.59      0.60       270\n",
      "weighted avg       0.92      0.90      0.91       270\n",
      "Acc@1:   0.000 ( 90.000)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 270/317]  Time: 0.043s (0.042s,   24.06/s)  Loss:  0.5515 (0.6408)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  82   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.90      0.85      0.88        96\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       271\n",
      "   macro avg       0.61      0.59      0.60       271\n",
      "weighted avg       0.92      0.90      0.91       271\n",
      "Acc@1: 100.000 ( 90.037)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 271/317]  Time: 0.049s (0.042s,   24.04/s)  Loss:  0.5517 (0.6405)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  83   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.90      0.86      0.88        97\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       272\n",
      "   macro avg       0.61      0.59      0.60       272\n",
      "weighted avg       0.92      0.90      0.91       272\n",
      "Acc@1: 100.000 ( 90.074)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 272/317]  Time: 0.028s (0.042s,   24.07/s)  Loss:  0.5514 (0.6402)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  84   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.90      0.86      0.88        98\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       273\n",
      "   macro avg       0.61      0.59      0.60       273\n",
      "weighted avg       0.92      0.90      0.91       273\n",
      "Acc@1: 100.000 ( 90.110)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 273/317]  Time: 0.035s (0.042s,   24.09/s)  Loss:  0.6901 (0.6403)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  85   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.90      0.86      0.88        99\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       274\n",
      "   macro avg       0.61      0.59      0.60       274\n",
      "weighted avg       0.92      0.90      0.91       274\n",
      "Acc@1: 100.000 ( 90.146)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 274/317]  Time: 0.027s (0.041s,   24.12/s)  Loss:  0.5514 (0.6400)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  86   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       100\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       275\n",
      "   macro avg       0.61      0.60      0.60       275\n",
      "weighted avg       0.92      0.90      0.91       275\n",
      "Acc@1: 100.000 ( 90.182)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 275/317]  Time: 0.030s (0.041s,   24.14/s)  Loss:  0.5514 (0.6397)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  87   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       101\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       276\n",
      "   macro avg       0.61      0.60      0.60       276\n",
      "weighted avg       0.92      0.90      0.91       276\n",
      "Acc@1: 100.000 ( 90.217)  Acc@5: 100.000 (100.000)  \n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test: [ 276/317]  Time: 0.032s (0.041s,   24.16/s)  Loss:  0.5514 (0.6394)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1   0]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       277\n",
      "   macro avg       0.61      0.60      0.60       277\n",
      "weighted avg       0.92      0.90      0.91       277\n",
      "Acc@1: 100.000 ( 90.253)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 277/317]  Time: 0.035s (0.041s,   24.18/s)  Loss:  0.5520 (0.6391)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1   1]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.17      1.00      0.29         1\n",
      "\n",
      "    accuracy                           0.90       278\n",
      "   macro avg       0.67      0.93      0.70       278\n",
      "weighted avg       0.92      0.90      0.91       278\n",
      "Acc@1: 100.000 ( 90.288)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 278/317]  Time: 0.033s (0.041s,   24.19/s)  Loss:  0.5555 (0.6388)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1   2]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.29      1.00      0.44         2\n",
      "\n",
      "    accuracy                           0.90       279\n",
      "   macro avg       0.71      0.93      0.75       279\n",
      "weighted avg       0.91      0.90      0.91       279\n",
      "Acc@1: 100.000 ( 90.323)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 279/317]  Time: 0.030s (0.041s,   24.22/s)  Loss:  0.5528 (0.6385)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1   3]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.38      1.00      0.55         3\n",
      "\n",
      "    accuracy                           0.90       280\n",
      "   macro avg       0.74      0.93      0.79       280\n",
      "weighted avg       0.91      0.90      0.91       280\n",
      "Acc@1: 100.000 ( 90.357)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 280/317]  Time: 0.042s (0.041s,   24.22/s)  Loss:  0.5515 (0.6382)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1   4]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.44      1.00      0.62         4\n",
      "\n",
      "    accuracy                           0.90       281\n",
      "   macro avg       0.76      0.93      0.81       281\n",
      "weighted avg       0.91      0.90      0.91       281\n",
      "Acc@1: 100.000 ( 90.391)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 281/317]  Time: 0.034s (0.041s,   24.23/s)  Loss:  0.5514 (0.6378)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1   5]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.50      1.00      0.67         5\n",
      "\n",
      "    accuracy                           0.90       282\n",
      "   macro avg       0.78      0.93      0.83       282\n",
      "weighted avg       0.91      0.90      0.91       282\n",
      "Acc@1: 100.000 ( 90.426)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 282/317]  Time: 0.032s (0.041s,   24.25/s)  Loss:  0.5548 (0.6376)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1   6]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.55      1.00      0.71         6\n",
      "\n",
      "    accuracy                           0.90       283\n",
      "   macro avg       0.79      0.93      0.84       283\n",
      "weighted avg       0.91      0.90      0.91       283\n",
      "Acc@1: 100.000 ( 90.459)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 283/317]  Time: 0.032s (0.041s,   24.27/s)  Loss:  0.5719 (0.6373)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1   7]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.58      1.00      0.74         7\n",
      "\n",
      "    accuracy                           0.90       284\n",
      "   macro avg       0.81      0.93      0.85       284\n",
      "weighted avg       0.91      0.90      0.91       284\n",
      "Acc@1: 100.000 ( 90.493)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 284/317]  Time: 0.033s (0.041s,   24.29/s)  Loss:  0.5515 (0.6370)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1   8]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.62      1.00      0.76         8\n",
      "\n",
      "    accuracy                           0.91       285\n",
      "   macro avg       0.82      0.93      0.86       285\n",
      "weighted avg       0.91      0.91      0.91       285\n",
      "Acc@1: 100.000 ( 90.526)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 285/317]  Time: 0.033s (0.041s,   24.30/s)  Loss:  0.5515 (0.6367)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1   9]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.64      1.00      0.78         9\n",
      "\n",
      "    accuracy                           0.91       286\n",
      "   macro avg       0.83      0.93      0.86       286\n",
      "weighted avg       0.91      0.91      0.91       286\n",
      "Acc@1: 100.000 ( 90.559)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 286/317]  Time: 0.038s (0.041s,   24.31/s)  Loss:  0.5521 (0.6364)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  10]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.67      1.00      0.80        10\n",
      "\n",
      "    accuracy                           0.91       287\n",
      "   macro avg       0.83      0.93      0.87       287\n",
      "weighted avg       0.91      0.91      0.91       287\n",
      "Acc@1: 100.000 ( 90.592)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 287/317]  Time: 0.039s (0.041s,   24.31/s)  Loss:  0.5515 (0.6361)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  11]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.69      1.00      0.81        11\n",
      "\n",
      "    accuracy                           0.91       288\n",
      "   macro avg       0.84      0.93      0.87       288\n",
      "weighted avg       0.91      0.91      0.91       288\n",
      "Acc@1: 100.000 ( 90.625)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 288/317]  Time: 0.032s (0.041s,   24.33/s)  Loss:  0.5516 (0.6358)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  12]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.71      1.00      0.83        12\n",
      "\n",
      "    accuracy                           0.91       289\n",
      "   macro avg       0.85      0.93      0.88       289\n",
      "weighted avg       0.91      0.91      0.91       289\n",
      "Acc@1: 100.000 ( 90.657)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 289/317]  Time: 0.030s (0.041s,   24.35/s)  Loss:  0.5728 (0.6356)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  13]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.72      1.00      0.84        13\n",
      "\n",
      "    accuracy                           0.91       290\n",
      "   macro avg       0.85      0.93      0.88       290\n",
      "weighted avg       0.91      0.91      0.91       290\n",
      "Acc@1: 100.000 ( 90.690)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 290/317]  Time: 0.032s (0.041s,   24.37/s)  Loss:  0.5773 (0.6354)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  14]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.74      1.00      0.85        14\n",
      "\n",
      "    accuracy                           0.91       291\n",
      "   macro avg       0.86      0.93      0.89       291\n",
      "weighted avg       0.91      0.91      0.91       291\n",
      "Acc@1: 100.000 ( 90.722)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 291/317]  Time: 0.032s (0.041s,   24.39/s)  Loss:  0.5515 (0.6351)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  15]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.75      1.00      0.86        15\n",
      "\n",
      "    accuracy                           0.91       292\n",
      "   macro avg       0.86      0.93      0.89       292\n",
      "weighted avg       0.91      0.91      0.91       292\n",
      "Acc@1: 100.000 ( 90.753)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 292/317]  Time: 0.034s (0.041s,   24.40/s)  Loss:  0.5562 (0.6349)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  16]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.76      1.00      0.86        16\n",
      "\n",
      "    accuracy                           0.91       293\n",
      "   macro avg       0.86      0.93      0.89       293\n",
      "weighted avg       0.91      0.91      0.91       293\n",
      "Acc@1: 100.000 ( 90.785)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 293/317]  Time: 0.033s (0.041s,   24.42/s)  Loss:  0.5514 (0.6346)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  17]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.77      1.00      0.87        17\n",
      "\n",
      "    accuracy                           0.91       294\n",
      "   macro avg       0.87      0.93      0.89       294\n",
      "weighted avg       0.91      0.91      0.91       294\n",
      "Acc@1: 100.000 ( 90.816)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 294/317]  Time: 0.041s (0.041s,   24.42/s)  Loss:  0.5514 (0.6343)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  18]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.78      1.00      0.88        18\n",
      "\n",
      "    accuracy                           0.91       295\n",
      "   macro avg       0.87      0.93      0.90       295\n",
      "weighted avg       0.91      0.91      0.91       295\n",
      "Acc@1: 100.000 ( 90.847)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 295/317]  Time: 0.034s (0.041s,   24.43/s)  Loss:  0.6227 (0.6343)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  19]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.79      1.00      0.88        19\n",
      "\n",
      "    accuracy                           0.91       296\n",
      "   macro avg       0.87      0.93      0.90       296\n",
      "weighted avg       0.91      0.91      0.91       296\n",
      "Acc@1: 100.000 ( 90.878)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 296/317]  Time: 0.033s (0.041s,   24.45/s)  Loss:  0.5573 (0.6340)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  20]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.80      1.00      0.89        20\n",
      "\n",
      "    accuracy                           0.91       297\n",
      "   macro avg       0.88      0.93      0.90       297\n",
      "weighted avg       0.91      0.91      0.91       297\n",
      "Acc@1: 100.000 ( 90.909)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 297/317]  Time: 0.031s (0.041s,   24.47/s)  Loss:  0.5604 (0.6338)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  21]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.81      1.00      0.89        21\n",
      "\n",
      "    accuracy                           0.91       298\n",
      "   macro avg       0.88      0.93      0.90       298\n",
      "weighted avg       0.91      0.91      0.91       298\n",
      "Acc@1: 100.000 ( 90.940)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 298/317]  Time: 0.041s (0.041s,   24.47/s)  Loss:  0.5515 (0.6335)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  22]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.81      1.00      0.90        22\n",
      "\n",
      "    accuracy                           0.91       299\n",
      "   macro avg       0.88      0.93      0.90       299\n",
      "weighted avg       0.91      0.91      0.91       299\n",
      "Acc@1: 100.000 ( 90.970)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 299/317]  Time: 0.038s (0.041s,   24.48/s)  Loss:  0.5516 (0.6332)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  23]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.82      1.00      0.90        23\n",
      "\n",
      "    accuracy                           0.91       300\n",
      "   macro avg       0.88      0.93      0.90       300\n",
      "weighted avg       0.91      0.91      0.91       300\n",
      "Acc@1: 100.000 ( 91.000)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 300/317]  Time: 0.048s (0.041s,   24.46/s)  Loss:  0.5524 (0.6329)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  24]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.83      1.00      0.91        24\n",
      "\n",
      "    accuracy                           0.91       301\n",
      "   macro avg       0.89      0.93      0.91       301\n",
      "weighted avg       0.91      0.91      0.91       301\n",
      "Acc@1: 100.000 ( 91.030)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 301/317]  Time: 0.033s (0.041s,   24.48/s)  Loss:  0.5515 (0.6327)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  25]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.83      1.00      0.91        25\n",
      "\n",
      "    accuracy                           0.91       302\n",
      "   macro avg       0.89      0.93      0.91       302\n",
      "weighted avg       0.91      0.91      0.91       302\n",
      "Acc@1: 100.000 ( 91.060)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 302/317]  Time: 0.059s (0.041s,   24.44/s)  Loss:  0.5515 (0.6324)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  26]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.84      1.00      0.91        26\n",
      "\n",
      "    accuracy                           0.91       303\n",
      "   macro avg       0.89      0.93      0.91       303\n",
      "weighted avg       0.91      0.91      0.91       303\n",
      "Acc@1: 100.000 ( 91.089)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 303/317]  Time: 0.051s (0.041s,   24.42/s)  Loss:  0.5527 (0.6321)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  27]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.84      1.00      0.92        27\n",
      "\n",
      "    accuracy                           0.91       304\n",
      "   macro avg       0.89      0.93      0.91       304\n",
      "weighted avg       0.91      0.91      0.91       304\n",
      "Acc@1: 100.000 ( 91.118)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 304/317]  Time: 0.033s (0.041s,   24.44/s)  Loss:  0.5610 (0.6319)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  28]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.85      1.00      0.92        28\n",
      "\n",
      "    accuracy                           0.91       305\n",
      "   macro avg       0.89      0.93      0.91       305\n",
      "weighted avg       0.91      0.91      0.91       305\n",
      "Acc@1: 100.000 ( 91.148)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 305/317]  Time: 0.036s (0.041s,   24.45/s)  Loss:  0.5549 (0.6317)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  29]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.85      1.00      0.92        29\n",
      "\n",
      "    accuracy                           0.91       306\n",
      "   macro avg       0.90      0.93      0.91       306\n",
      "weighted avg       0.91      0.91      0.91       306\n",
      "Acc@1: 100.000 ( 91.176)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 306/317]  Time: 0.037s (0.041s,   24.46/s)  Loss:  0.6105 (0.6316)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  30]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.86      1.00      0.92        30\n",
      "\n",
      "    accuracy                           0.91       307\n",
      "   macro avg       0.90      0.93      0.91       307\n",
      "weighted avg       0.91      0.91      0.91       307\n",
      "Acc@1: 100.000 ( 91.205)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 307/317]  Time: 0.043s (0.041s,   24.45/s)  Loss:  0.5541 (0.6313)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  31]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.86      1.00      0.93        31\n",
      "\n",
      "    accuracy                           0.91       308\n",
      "   macro avg       0.90      0.93      0.91       308\n",
      "weighted avg       0.91      0.91      0.91       308\n",
      "Acc@1: 100.000 ( 91.234)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 308/317]  Time: 0.033s (0.041s,   24.47/s)  Loss:  0.5558 (0.6311)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  32]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.86      1.00      0.93        32\n",
      "\n",
      "    accuracy                           0.91       309\n",
      "   macro avg       0.90      0.93      0.91       309\n",
      "weighted avg       0.91      0.91      0.91       309\n",
      "Acc@1: 100.000 ( 91.262)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 309/317]  Time: 0.023s (0.041s,   24.50/s)  Loss:  0.5572 (0.6308)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  33]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.87      1.00      0.93        33\n",
      "\n",
      "    accuracy                           0.91       310\n",
      "   macro avg       0.90      0.93      0.91       310\n",
      "weighted avg       0.91      0.91      0.91       310\n",
      "Acc@1: 100.000 ( 91.290)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 310/317]  Time: 0.022s (0.041s,   24.54/s)  Loss:  0.5515 (0.6306)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  34]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.87      1.00      0.93        34\n",
      "\n",
      "    accuracy                           0.91       311\n",
      "   macro avg       0.90      0.93      0.91       311\n",
      "weighted avg       0.91      0.91      0.91       311\n",
      "Acc@1: 100.000 ( 91.318)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 311/317]  Time: 0.023s (0.041s,   24.57/s)  Loss:  0.5515 (0.6303)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  35]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.88      1.00      0.93        35\n",
      "\n",
      "    accuracy                           0.91       312\n",
      "   macro avg       0.90      0.93      0.91       312\n",
      "weighted avg       0.91      0.91      0.91       312\n",
      "Acc@1: 100.000 ( 91.346)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 312/317]  Time: 0.023s (0.041s,   24.60/s)  Loss:  0.5515 (0.6301)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  36]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.88      1.00      0.94        36\n",
      "\n",
      "    accuracy                           0.91       313\n",
      "   macro avg       0.90      0.93      0.92       313\n",
      "weighted avg       0.91      0.91      0.91       313\n",
      "Acc@1: 100.000 ( 91.374)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 313/317]  Time: 0.023s (0.041s,   24.64/s)  Loss:  0.5548 (0.6298)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  37]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.88      1.00      0.94        37\n",
      "\n",
      "    accuracy                           0.91       314\n",
      "   macro avg       0.90      0.93      0.92       314\n",
      "weighted avg       0.91      0.91      0.91       314\n",
      "Acc@1: 100.000 ( 91.401)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 314/317]  Time: 0.023s (0.041s,   24.67/s)  Loss:  0.5531 (0.6296)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  38]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.88      1.00      0.94        38\n",
      "\n",
      "    accuracy                           0.91       315\n",
      "   macro avg       0.91      0.93      0.92       315\n",
      "weighted avg       0.91      0.91      0.91       315\n",
      "Acc@1: 100.000 ( 91.429)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 315/317]  Time: 0.024s (0.040s,   24.70/s)  Loss:  0.5515 (0.6294)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  39]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.89      1.00      0.94        39\n",
      "\n",
      "    accuracy                           0.91       316\n",
      "   macro avg       0.91      0.93      0.92       316\n",
      "weighted avg       0.91      0.91      0.91       316\n",
      "Acc@1: 100.000 ( 91.456)  Acc@5: 100.000 (100.000)  \n",
      "Test: [ 316/317]  Time: 0.022s (0.040s,   24.74/s)  Loss:  0.5709 (0.6292)  \n",
      "Conf Mat:\n",
      " [[162  13   0]\n",
      " [  9  88   0]\n",
      " [  4   1  40]]\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       175\n",
      "           1       0.91      0.86      0.88       102\n",
      "           2       0.89      1.00      0.94        40\n",
      "\n",
      "    accuracy                           0.91       317\n",
      "   macro avg       0.91      0.93      0.92       317\n",
      "weighted avg       0.92      0.91      0.91       317\n",
      "Acc@1: 100.000 ( 91.483)  Acc@5: 100.000 (100.000)  \n",
      " * Acc@1 91.483 (8.517) Acc@5 100.000 (0.000)\n",
      "--result\n",
      "{\n",
      "    \"model\": \"tf_efficientnet_b0\",\n",
      "    \"top1\": 91.4826,\n",
      "    \"top1_err\": 8.5174,\n",
      "    \"top5\": 100.0,\n",
      "    \"top5_err\": 0.0,\n",
      "    \"param_count\": 4.01,\n",
      "    \"img_size\": 512,\n",
      "    \"crop_pct\": 0.875,\n",
      "    \"interpolation\": \"bicubic\"\n",
      "}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "XSLXbT43IQc3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}